{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8af48ca1-b6d1-4092-b7b5-037d3c2d7aef"
      },
      "source": [
        "# M4 | Research Investigation Notebook\n",
        "\n",
        "In this notebook, you will do a research investigation of your chosen dataset in teams. You will begin by formally selecting your research question (task 0), then processing your data (task 1), creating a predictive model (task 2), and evaluating your model's results (task 3).\n",
        "\n",
        "Please upload your solved notebook to Moodle (under [Milestone 4 Submission](https://moodle.epfl.ch/mod/assign/view.php?id=1199557)) adding your team name in title, example: `m4-lernnavi-teamname.ipynb`. Please run all cells before submission so we can grade effectively.\n",
        "\n",
        "\n",
        "## Brief overview of Lernnavi\n",
        "[Lernnavi](https://www.lernnavi.ch) is an instrument for promoting part of the basic technical study skills in German and mathematics.\n",
        "\n",
        "Lernnavi's dataset is formatted in three main tables:\n",
        "* *users*: demographic information of users.\n",
        "* *events*: events done by the users in the platform.\n",
        "* *transactions*: question and answer solved by user.\n",
        "\n",
        "You should provide arguments and justifications for all of your design decisions throughout this investigation. You can use your M3 responses as the basis for this discussion."
      ],
      "id": "8af48ca1-b6d1-4092-b7b5-037d3c2d7aef"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHeSzES2JqlI",
        "outputId": "24c7d6eb-a8a0-4693-a2fc-787bcb4509d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "id": "HHeSzES2JqlI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82ea2d32-f0a9-4dc9-bb60-be43399f5b89"
      },
      "outputs": [],
      "source": [
        "# Import the tables of the data set as dataframes.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "DATA_DIR = 'gdrive/My Drive/MLBD - Lernnavi Data' # You many change the directory\n",
        "\n",
        "users = pd.read_csv('{}/users.csv.gz'.format(DATA_DIR))\n",
        "events = pd.read_csv('{}/events.csv.gz'.format(DATA_DIR))\n",
        "transactions = pd.read_csv('{}/transactions.csv.gz'.format(DATA_DIR))"
      ],
      "id": "82ea2d32-f0a9-4dc9-bb60-be43399f5b89"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmGbYMaJ69cF"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn import feature_extraction, model_selection\n",
        "from sklearn.metrics import mean_squared_error, roc_auc_score, balanced_accuracy_score, accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import ParameterGrid, train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf"
      ],
      "id": "JmGbYMaJ69cF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7wZv4LZ69cG"
      },
      "source": [
        "## Task 0: Research Question"
      ],
      "id": "v7wZv4LZ69cG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDMb_Hnd69cG"
      },
      "source": [
        "**Research question:**\n",
        "*Predicting user motivation and retention. E.g., dropout or long pauses prediction, level checks prediction (self-supervised learning)*"
      ],
      "id": "eDMb_Hnd69cG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a77f62b0-1945-48f1-8f22-5f6ebda1db8e"
      },
      "source": [
        "## Task 1: Data Preprocessing\n",
        "\n",
        "In this section, you are asked to preprocess your data in a way that is relevant for the model. Please include 1-2 visualizations of features / data explorations that are related to your downstream prediction task."
      ],
      "id": "a77f62b0-1945-48f1-8f22-5f6ebda1db8e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ps5MLOWJ69cH"
      },
      "outputs": [],
      "source": [
        "# Create date column\n",
        "events['date'] = pd.to_datetime(events['timestamp'], unit='ms')\n",
        "events[\"week\"] = events[\"date\"].dt.isocalendar().week\n",
        "events[\"year\"] = events[\"date\"].dt.year"
      ],
      "id": "Ps5MLOWJ69cH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "bITUfGog69cH",
        "outputId": "81421017-f1df-4aae-816c-a8aede5b753e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-953d2a79-e368-4fbe-8bb1-20b863aeceff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>year</th>\n",
              "      <th>week</th>\n",
              "      <th>num_events</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>387604</td>\n",
              "      <td>2021</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>387604</td>\n",
              "      <td>2021</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>387604</td>\n",
              "      <td>2021</td>\n",
              "      <td>25</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>387604</td>\n",
              "      <td>2021</td>\n",
              "      <td>26</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>387604</td>\n",
              "      <td>2021</td>\n",
              "      <td>31</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27527</th>\n",
              "      <td>404600</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27528</th>\n",
              "      <td>404603</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27529</th>\n",
              "      <td>404604</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27530</th>\n",
              "      <td>404605</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27531</th>\n",
              "      <td>404623</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27532 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-953d2a79-e368-4fbe-8bb1-20b863aeceff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-953d2a79-e368-4fbe-8bb1-20b863aeceff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-953d2a79-e368-4fbe-8bb1-20b863aeceff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       user_id  year  week  num_events\n",
              "0       387604  2021    20           1\n",
              "1       387604  2021    21           1\n",
              "2       387604  2021    25           7\n",
              "3       387604  2021    26          25\n",
              "4       387604  2021    31          12\n",
              "...        ...   ...   ...         ...\n",
              "27527   404600  2022     8          34\n",
              "27528   404603  2022     8         112\n",
              "27529   404604  2022     8          43\n",
              "27530   404605  2022     8          22\n",
              "27531   404623  2022     8          37\n",
              "\n",
              "[27532 rows x 4 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# User activity per week\n",
        "df_weekly = events[[\"user_id\",\"year\",\"week\"]].dropna().groupby([\"user_id\",\"year\",\"week\"]).size().reset_index(name='num_events')\n",
        "df_weekly"
      ],
      "id": "bITUfGog69cH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "d63UGNRN69cI",
        "outputId": "fda6d26f-60fa-417e-ee18-105f215d49f2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-02b9ef53-8ee1-4c6c-9044-4c26114cc8c2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>year</th>\n",
              "      <th>week</th>\n",
              "      <th>num_questions</th>\n",
              "      <th>percentage_correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>387604</td>\n",
              "      <td>2021</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>387604</td>\n",
              "      <td>2021</td>\n",
              "      <td>38</td>\n",
              "      <td>4</td>\n",
              "      <td>0.125000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>387604</td>\n",
              "      <td>2021</td>\n",
              "      <td>39</td>\n",
              "      <td>2</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>387604</td>\n",
              "      <td>2021</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>387604</td>\n",
              "      <td>2021</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18526</th>\n",
              "      <td>404597</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18527</th>\n",
              "      <td>404598</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18528</th>\n",
              "      <td>404599</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18529</th>\n",
              "      <td>404603</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>0.653846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18530</th>\n",
              "      <td>404604</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>0.375000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18531 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02b9ef53-8ee1-4c6c-9044-4c26114cc8c2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02b9ef53-8ee1-4c6c-9044-4c26114cc8c2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02b9ef53-8ee1-4c6c-9044-4c26114cc8c2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       user_id  year  week  num_questions  percentage_correct\n",
              "0       387604  2021    35              1            0.000000\n",
              "1       387604  2021    38              4            0.125000\n",
              "2       387604  2021    39              2            0.750000\n",
              "3       387604  2021    40              1            0.500000\n",
              "4       387604  2021    41              1            0.500000\n",
              "...        ...   ...   ...            ...                 ...\n",
              "18526   404597  2022     8              1            0.500000\n",
              "18527   404598  2022     8              1            1.000000\n",
              "18528   404599  2022     8              1            1.000000\n",
              "18529   404603  2022     8             13            0.653846\n",
              "18530   404604  2022     8              4            0.375000\n",
              "\n",
              "[18531 rows x 5 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Number of questions answered and the evaluations per week\n",
        "all_questions = events[[\"user_id\",\"year\",\"week\",\"action\",\"transaction_token\"]].dropna()\n",
        "all_questions = all_questions[all_questions['action']=='SUBMIT_ANSWER']\n",
        "\n",
        "evaluations = all_questions.merge(transactions[['transaction_token', 'evaluation']].dropna().replace([\"CORRECT\",\"PARTIAL\",\"WRONG\"],[1,0.5,0]),\n",
        "                                  on='transaction_token',\n",
        "                                  how='left')\n",
        "\n",
        "# Remove users that have a transaction in the event table that is not in the transaction table (~27000 / 400000)\n",
        "evaluations = evaluations[evaluations['evaluation'].notna()]\n",
        "num_questions = evaluations.drop(columns = [\"transaction_token\"]).groupby(\n",
        "    [\"user_id\",\"year\",\"week\"]).size().reset_index(name='num_questions')\n",
        "evaluations_count = evaluations.drop(columns = [\"transaction_token\"]).groupby(\n",
        "    [\"user_id\",\"year\",\"week\"]).sum().reset_index()\n",
        "\n",
        "df_questions = num_questions.merge(evaluations_count, on=['user_id', 'year', 'week'], how='left')\n",
        "df_questions['percentage_correct'] = df_questions['evaluation'] / df_questions['num_questions']\n",
        "df_questions = df_questions.drop(columns='evaluation')\n",
        "df_questions"
      ],
      "id": "d63UGNRN69cI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "2aBLM1Qi69cI",
        "outputId": "5105fe69-2a8e-419a-df4d-9f892a5cdfce"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d6f292e3-e3c3-44f7-b823-60c5f02b627c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>year</th>\n",
              "      <th>week</th>\n",
              "      <th>num_theory</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>387604</td>\n",
              "      <td>2021</td>\n",
              "      <td>33</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>387604</td>\n",
              "      <td>2021</td>\n",
              "      <td>34</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>387604</td>\n",
              "      <td>2021</td>\n",
              "      <td>35</td>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>387604</td>\n",
              "      <td>2021</td>\n",
              "      <td>36</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>387604</td>\n",
              "      <td>2021</td>\n",
              "      <td>37</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7858</th>\n",
              "      <td>404589</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7859</th>\n",
              "      <td>404597</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7860</th>\n",
              "      <td>404598</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7861</th>\n",
              "      <td>404599</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7862</th>\n",
              "      <td>404623</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7863 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6f292e3-e3c3-44f7-b823-60c5f02b627c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d6f292e3-e3c3-44f7-b823-60c5f02b627c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d6f292e3-e3c3-44f7-b823-60c5f02b627c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      user_id  year  week  num_theory\n",
              "0      387604  2021    33          18\n",
              "1      387604  2021    34          50\n",
              "2      387604  2021    35         118\n",
              "3      387604  2021    36          27\n",
              "4      387604  2021    37          78\n",
              "...       ...   ...   ...         ...\n",
              "7858   404589  2022     8           4\n",
              "7859   404597  2022     8           8\n",
              "7860   404598  2022     8          15\n",
              "7861   404599  2022     8          38\n",
              "7862   404623  2022     8           5\n",
              "\n",
              "[7863 rows x 4 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Number of theory pages read per week\n",
        "num_theory = events[[\"user_id\",\"year\",\"week\",\"action\"]].dropna()\n",
        "num_theory = num_theory[num_theory[\"action\"]=='GO_TO_THEORY'].groupby(\n",
        "    [\"user_id\",\"year\",\"week\"]).size().reset_index(name='num_theory')\n",
        "num_theory"
      ],
      "id": "2aBLM1Qi69cI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 958
        },
        "id": "YjRBd2JO69cI",
        "outputId": "e8d148a5-f345-4876-b954-c51ca8bd881f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6464aa8e-04df-4603-be50-7ac321bda11d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>week</th>\n",
              "      <th>num_events</th>\n",
              "      <th>num_questions</th>\n",
              "      <th>percentage_correct</th>\n",
              "      <th>num_theory</th>\n",
              "      <th>last_week_of_activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>387604</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>387604</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>387604</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>387604</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>387604</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>387604</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>387604</td>\n",
              "      <td>6</td>\n",
              "      <td>93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>387604</td>\n",
              "      <td>7</td>\n",
              "      <td>113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>50.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>387604</td>\n",
              "      <td>8</td>\n",
              "      <td>405</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>118.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>387604</td>\n",
              "      <td>9</td>\n",
              "      <td>139</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>27.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>387604</td>\n",
              "      <td>10</td>\n",
              "      <td>178</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>78.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>387604</td>\n",
              "      <td>11</td>\n",
              "      <td>131</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>14.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>387604</td>\n",
              "      <td>12</td>\n",
              "      <td>23</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>387604</td>\n",
              "      <td>13</td>\n",
              "      <td>70</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>387604</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>387604</td>\n",
              "      <td>15</td>\n",
              "      <td>141</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>387604</td>\n",
              "      <td>16</td>\n",
              "      <td>108</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>387604</td>\n",
              "      <td>17</td>\n",
              "      <td>343</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>15.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>387604</td>\n",
              "      <td>18</td>\n",
              "      <td>473</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>36.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>387604</td>\n",
              "      <td>19</td>\n",
              "      <td>28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>387604</td>\n",
              "      <td>20</td>\n",
              "      <td>12</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>387604</td>\n",
              "      <td>21</td>\n",
              "      <td>13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>387604</td>\n",
              "      <td>22</td>\n",
              "      <td>164</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.529412</td>\n",
              "      <td>6.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>387604</td>\n",
              "      <td>23</td>\n",
              "      <td>19</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>387604</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>387604</td>\n",
              "      <td>25</td>\n",
              "      <td>17</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>387604</td>\n",
              "      <td>26</td>\n",
              "      <td>35</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>387604</td>\n",
              "      <td>27</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>387604</td>\n",
              "      <td>28</td>\n",
              "      <td>21</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6464aa8e-04df-4603-be50-7ac321bda11d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6464aa8e-04df-4603-be50-7ac321bda11d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6464aa8e-04df-4603-be50-7ac321bda11d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    user_id  week  num_events  num_questions  percentage_correct  num_theory  \\\n",
              "0    387604     0           1            0.0                 NaN         0.0   \n",
              "1    387604     1           1            0.0                 NaN         0.0   \n",
              "2    387604     2           7            0.0                 NaN         0.0   \n",
              "3    387604     3          25            0.0                 NaN         0.0   \n",
              "4    387604     4          12            0.0                 NaN         0.0   \n",
              "5    387604     5          12            0.0                 NaN         0.0   \n",
              "6    387604     6          93            0.0                 NaN        18.0   \n",
              "7    387604     7         113            0.0                 NaN        50.0   \n",
              "8    387604     8         405            1.0            0.000000       118.0   \n",
              "9    387604     9         139            0.0                 NaN        27.0   \n",
              "10   387604    10         178            0.0                 NaN        78.0   \n",
              "11   387604    11         131            4.0            0.125000        14.0   \n",
              "12   387604    12          23            2.0            0.750000         0.0   \n",
              "13   387604    13          70            1.0            0.500000         0.0   \n",
              "14   387604    14          13            1.0            0.500000         0.0   \n",
              "15   387604    15         141            6.0            0.416667         0.0   \n",
              "16   387604    16         108            2.0            0.750000         0.0   \n",
              "17   387604    17         343           25.0            0.660000        15.0   \n",
              "18   387604    18         473           31.0            0.500000        36.0   \n",
              "19   387604    19          28            0.0                 NaN         0.0   \n",
              "20   387604    20          12            2.0            0.500000         0.0   \n",
              "21   387604    21          13            0.0                 NaN         0.0   \n",
              "22   387604    22         164           17.0            0.529412         6.0   \n",
              "23   387604    23          19            1.0            0.500000         0.0   \n",
              "24   387604    24           6            1.0            0.000000         0.0   \n",
              "25   387604    25          17            2.0            1.000000         0.0   \n",
              "26   387604    26          35            1.0            0.500000         5.0   \n",
              "27   387604    27           3            0.0                 NaN         0.0   \n",
              "28   387604    28          21            0.0                 NaN         1.0   \n",
              "\n",
              "    last_week_of_activity  \n",
              "0                   False  \n",
              "1                   False  \n",
              "2                   False  \n",
              "3                   False  \n",
              "4                   False  \n",
              "5                   False  \n",
              "6                   False  \n",
              "7                   False  \n",
              "8                   False  \n",
              "9                   False  \n",
              "10                  False  \n",
              "11                  False  \n",
              "12                  False  \n",
              "13                  False  \n",
              "14                  False  \n",
              "15                  False  \n",
              "16                  False  \n",
              "17                  False  \n",
              "18                  False  \n",
              "19                  False  \n",
              "20                  False  \n",
              "21                  False  \n",
              "22                  False  \n",
              "23                  False  \n",
              "24                  False  \n",
              "25                  False  \n",
              "26                  False  \n",
              "27                  False  \n",
              "28                   True  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filter out uneeded users and merge all tables\n",
        "df_weekly_merged = df_weekly.copy()\n",
        "df_weekly_merged = df_weekly_merged.merge(df_questions, on=['user_id', 'year', 'week'], how='left').fillna(value={'num_questions':0})\n",
        "df_weekly_merged = df_weekly_merged.merge(num_theory, on=['user_id', 'year', 'week'], how='left').fillna(value={'num_theory':0})\n",
        "\n",
        "# Sort the data per date and renumber the weeks\n",
        "df_weekly_merged = df_weekly_merged.sort_values(by = [\"user_id\",\"year\",\"week\"])\n",
        "df_weekly_merged[\"week\"] = df_weekly_merged.groupby('user_id').cumcount()\n",
        "df_weekly_merged = df_weekly_merged.drop(columns = [\"year\"])\n",
        "\n",
        "# Check which week is the last week of activity of the user\n",
        "s = df_weekly_merged['user_id'].shift(-1)\n",
        "df_weekly_merged['last_week_of_activity'] = df_weekly_merged['user_id'].ne(s)\n",
        "\n",
        "df_weekly_merged\n",
        "\n",
        "# User example\n",
        "df_weekly_merged[df_weekly_merged['user_id']==df_weekly_merged['user_id'].unique()[0]]"
      ],
      "id": "YjRBd2JO69cI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ugGOud5E69cJ",
        "outputId": "987b9451-dfdc-4a22-e4b9-d63872e6c0fe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-462800eb-12fb-4554-8e4b-270c50eeb131\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>week</th>\n",
              "      <th>num_events</th>\n",
              "      <th>num_questions</th>\n",
              "      <th>percentage_correct</th>\n",
              "      <th>num_theory</th>\n",
              "      <th>last_week_of_activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>387604</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>387604</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>387605</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>387605</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>387608</td>\n",
              "      <td>0</td>\n",
              "      <td>93</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16065</th>\n",
              "      <td>404517</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16067</th>\n",
              "      <td>404526</td>\n",
              "      <td>0</td>\n",
              "      <td>682</td>\n",
              "      <td>99.0</td>\n",
              "      <td>0.757576</td>\n",
              "      <td>4.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16068</th>\n",
              "      <td>404526</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16070</th>\n",
              "      <td>404536</td>\n",
              "      <td>0</td>\n",
              "      <td>290</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16071</th>\n",
              "      <td>404536</td>\n",
              "      <td>1</td>\n",
              "      <td>115</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12010 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-462800eb-12fb-4554-8e4b-270c50eeb131')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-462800eb-12fb-4554-8e4b-270c50eeb131 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-462800eb-12fb-4554-8e4b-270c50eeb131');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       user_id  week  num_events  num_questions  percentage_correct  \\\n",
              "0       387604     0           1            0.0                 NaN   \n",
              "1       387604     1           1            0.0                 NaN   \n",
              "2       387605     0          12            3.0            0.833333   \n",
              "3       387605     1          10            1.0            0.500000   \n",
              "4       387608     0          93           15.0            0.933333   \n",
              "...        ...   ...         ...            ...                 ...   \n",
              "16065   404517     1          13            0.0                 NaN   \n",
              "16067   404526     0         682           99.0            0.757576   \n",
              "16068   404526     1          21            1.0            0.500000   \n",
              "16070   404536     0         290           10.0            1.000000   \n",
              "16071   404536     1         115            5.0            1.000000   \n",
              "\n",
              "       num_theory  last_week_of_activity  \n",
              "0             0.0                  False  \n",
              "1             0.0                  False  \n",
              "2             0.0                  False  \n",
              "3             0.0                  False  \n",
              "4             0.0                  False  \n",
              "...           ...                    ...  \n",
              "16065         0.0                   True  \n",
              "16067         4.0                  False  \n",
              "16068         0.0                   True  \n",
              "16070         5.0                  False  \n",
              "16071         0.0                   True  \n",
              "\n",
              "[12010 rows x 7 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Obtain user data from week 0 to n-1\n",
        "def week_up_to_n(df, n):\n",
        "    # Takes up to n weeks of data\n",
        "    df = df.groupby('user_id').head(n).reset_index(drop=True)\n",
        "    \n",
        "    # Remove users that have less than n weeks of data \n",
        "    # TODO: comment on this in report\n",
        "    keep_users = (df.groupby('user_id').size() >= n).reset_index(name='keep')\n",
        "    keep_users = keep_users[keep_users['keep']]\n",
        "    df = df[df['user_id'].isin(keep_users['user_id'])]\n",
        "    \n",
        "    # Has the user dropped out at week n-1 (= no more activity on week n and after)\n",
        "    labels = df[['user_id', 'last_week_of_activity']].groupby('user_id').sum().astype(bool).reset_index().rename(\n",
        "        columns={'last_week_of_activity':'dropout_at_week_n'})\n",
        "    \n",
        "    return df, labels\n",
        "\n",
        "df_weekly_merged_n, labels_n = week_up_to_n(df_weekly_merged, 2)\n",
        "df_weekly_merged_n"
      ],
      "id": "ugGOud5E69cJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "id": "MHp8TV4FvwmD",
        "outputId": "b5cc0095-c877-4fb9-d708-d4a6a8af6ef9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fd893ec23d0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd893e8eb10>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd893e45e90>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd893e074d0>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fd893dbbad0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd893de8cd0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd893d36710>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd893cead10>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fd893cf6bd0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd893cb8350>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd893c9cf50>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd893c60590>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fd893c16b90>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd893bd71d0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd893b8f7d0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd893b45dd0>]],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 16 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "df_week_12 = df_weekly_merged[df_weekly_merged[\"week\"] <= 12]\n",
        "df_week_12[\"last_week_of_activity\"].astype(int).hist(by = df_week_12[\"week\"],figsize = (10,10))"
      ],
      "id": "MHp8TV4FvwmD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "fUJzdHX569cJ",
        "outputId": "a2ce1c92-8f00-434f-cdb7-4ad36d7b8cce"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-450845ba-5c35-4bfd-ab95-ef2026bd8739\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>dropout_at_week_n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>387604</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>387605</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>387608</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>387615</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>387644</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6000</th>\n",
              "      <td>404502</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6001</th>\n",
              "      <td>404510</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6002</th>\n",
              "      <td>404517</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6003</th>\n",
              "      <td>404526</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6004</th>\n",
              "      <td>404536</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6005 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-450845ba-5c35-4bfd-ab95-ef2026bd8739')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-450845ba-5c35-4bfd-ab95-ef2026bd8739 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-450845ba-5c35-4bfd-ab95-ef2026bd8739');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      user_id  dropout_at_week_n\n",
              "0      387604              False\n",
              "1      387605              False\n",
              "2      387608              False\n",
              "3      387615              False\n",
              "4      387644              False\n",
              "...       ...                ...\n",
              "6000   404502               True\n",
              "6001   404510               True\n",
              "6002   404517               True\n",
              "6003   404526               True\n",
              "6004   404536               True\n",
              "\n",
              "[6005 rows x 2 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels_n"
      ],
      "id": "fUJzdHX569cJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "iLoCouyn69cJ",
        "outputId": "6528fa4a-1fba-4145-93fe-22fdf624ca9d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-31ef2de1-d868-4d62-92c5-1b7bf6022ac5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>week</th>\n",
              "      <th>num_events</th>\n",
              "      <th>num_questions</th>\n",
              "      <th>percentage_correct</th>\n",
              "      <th>num_theory</th>\n",
              "      <th>last_week_of_activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>387604</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.792108</td>\n",
              "      <td>-0.594629</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.226180</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>387604</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.792108</td>\n",
              "      <td>-0.594629</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.226180</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>387605</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.714310</td>\n",
              "      <td>-0.457031</td>\n",
              "      <td>1.026192</td>\n",
              "      <td>-0.226180</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>387605</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.728455</td>\n",
              "      <td>-0.548763</td>\n",
              "      <td>-0.810337</td>\n",
              "      <td>-0.226180</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>387608</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.141436</td>\n",
              "      <td>0.093359</td>\n",
              "      <td>1.577150</td>\n",
              "      <td>-0.226180</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16065</th>\n",
              "      <td>404517</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.707238</td>\n",
              "      <td>-0.594629</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.226180</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16067</th>\n",
              "      <td>404526</td>\n",
              "      <td>0</td>\n",
              "      <td>4.024277</td>\n",
              "      <td>3.946087</td>\n",
              "      <td>0.608799</td>\n",
              "      <td>0.133599</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16068</th>\n",
              "      <td>404526</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.650658</td>\n",
              "      <td>-0.548763</td>\n",
              "      <td>-0.810337</td>\n",
              "      <td>-0.226180</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16070</th>\n",
              "      <td>404536</td>\n",
              "      <td>0</td>\n",
              "      <td>1.251850</td>\n",
              "      <td>-0.135971</td>\n",
              "      <td>1.944456</td>\n",
              "      <td>0.223544</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16071</th>\n",
              "      <td>404536</td>\n",
              "      <td>1</td>\n",
              "      <td>0.014159</td>\n",
              "      <td>-0.365300</td>\n",
              "      <td>1.944456</td>\n",
              "      <td>-0.226180</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12010 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31ef2de1-d868-4d62-92c5-1b7bf6022ac5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-31ef2de1-d868-4d62-92c5-1b7bf6022ac5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-31ef2de1-d868-4d62-92c5-1b7bf6022ac5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       user_id  week  num_events  num_questions  percentage_correct  \\\n",
              "0       387604     0   -0.792108      -0.594629                 NaN   \n",
              "1       387604     1   -0.792108      -0.594629                 NaN   \n",
              "2       387605     0   -0.714310      -0.457031            1.026192   \n",
              "3       387605     1   -0.728455      -0.548763           -0.810337   \n",
              "4       387608     0   -0.141436       0.093359            1.577150   \n",
              "...        ...   ...         ...            ...                 ...   \n",
              "16065   404517     1   -0.707238      -0.594629                 NaN   \n",
              "16067   404526     0    4.024277       3.946087            0.608799   \n",
              "16068   404526     1   -0.650658      -0.548763           -0.810337   \n",
              "16070   404536     0    1.251850      -0.135971            1.944456   \n",
              "16071   404536     1    0.014159      -0.365300            1.944456   \n",
              "\n",
              "       num_theory  last_week_of_activity  \n",
              "0       -0.226180                  False  \n",
              "1       -0.226180                  False  \n",
              "2       -0.226180                  False  \n",
              "3       -0.226180                  False  \n",
              "4       -0.226180                  False  \n",
              "...           ...                    ...  \n",
              "16065   -0.226180                   True  \n",
              "16067    0.133599                  False  \n",
              "16068   -0.226180                   True  \n",
              "16070    0.223544                  False  \n",
              "16071   -0.226180                   True  \n",
              "\n",
              "[12010 rows x 7 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# NaN values should be ignored by the Standarizer \n",
        "columns_to_standarize = ['num_events', 'num_questions', 'percentage_correct', 'num_theory']\n",
        "\n",
        "def df_standarize(df):\n",
        "    scaler = StandardScaler()\n",
        "    df_stand = df.copy()\n",
        "    df_stand[columns_to_standarize] = scaler.fit_transform(df[columns_to_standarize]) \n",
        "    return df_stand\n",
        "\n",
        "df_weekly_stand = df_standarize(df_weekly_merged_n)\n",
        "df_weekly_stand"
      ],
      "id": "iLoCouyn69cJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSy7vzvN69cL"
      },
      "outputs": [],
      "source": [
        "# USE THIS PIPELINE TO APPLY TRANSFORMATIONS TO ONLY SOME COLUMNS\n",
        "\n",
        "# preprocessor = ColumnTransformer(\n",
        "#     transformers=[('scaler', StandardScaler(), columns_to_standarize)],\n",
        "#     remainder='passthrough'\n",
        "# )\n",
        "\n",
        "# pipeline = Pipeline([\n",
        "#     ('preprocessor', preprocessor)\n",
        "# ]) # add your model in pipeline\n",
        "\n",
        "# pipeline.fit(THE_DATA)\n"
      ],
      "id": "cSy7vzvN69cL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76d0fcca-686e-47a3-8567-c3f92db187d4"
      },
      "source": [
        "*Your discussion about your processing decisions goes here*"
      ],
      "id": "76d0fcca-686e-47a3-8567-c3f92db187d4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85633adb-d317-4ee3-bf06-e9f82f589c41"
      },
      "source": [
        "## Task 2: Model Building\n",
        "\n",
        "Train a model for your research question. "
      ],
      "id": "85633adb-d317-4ee3-bf06-e9f82f589c41"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fmZcly3nhmE"
      },
      "source": [
        "##Neural Network: Long short-term memory \n",
        "\n",
        "Here is the architecture of the neural network we are using; it is very close to the one implemented for in the class notebook of week 8, as it is a simple neural network mainly composed of a number of LSTMs recurrent unit, and a dense layer with a sigmoid to have a prediction between 0 and 1."
      ],
      "id": "3fmZcly3nhmE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkONW43o69cK"
      },
      "outputs": [],
      "source": [
        "def create_model_lstm_mooc_binary(nb_features, nb_skills, params):\n",
        "  \n",
        "  # Create an LSTM model architecture.\n",
        "  inputs = tf.keras.Input(shape=(None, nb_features), name='inputs')\n",
        "\n",
        "  # LSTM layer\n",
        "  x = tf.keras.layers.LSTM(params['recurrent_units'], \n",
        "                            return_sequences=False, \n",
        "                            dropout=params['dropout_rate'])(inputs)\n",
        "  \n",
        "      \n",
        "  # Dense layer with the sigmoid function \n",
        "  dense = tf.keras.layers.Dense(nb_skills, activation='sigmoid')\n",
        "  outputs = dense(x)\n",
        "  model = tf.keras.models.Model(inputs=inputs, outputs=outputs, name='TimeSeries')\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(loss=tf.keras.losses.binary_crossentropy, \n",
        "                optimizer=params['optimizer'],\n",
        "                metrics=[tf.keras.metrics.AUC(), 'binary_accuracy'])    \n",
        "  return model\n",
        "\n"
      ],
      "id": "GkONW43o69cK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mvs4GEOB2CH"
      },
      "source": [
        "We then train 3 models on various subset of the data; The first only on week 1, the second on week 1 to 4, and the last to week 1 to 8. The goal is to train these models to recognize whether or not a user will drop the course at various stages of them using the learning platform."
      ],
      "id": "-mvs4GEOB2CH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci5GGp4VoMx0"
      },
      "source": [
        "###1st LSTM NN: Training on Week 1:"
      ],
      "id": "ci5GGp4VoMx0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tla367MP69cK",
        "outputId": "410691fa-27a7-46de-91ae-c5b71bd51f63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10113, 7)\n",
            "(10113, 1, 4)\n"
          ]
        }
      ],
      "source": [
        "#Parameters for the dataset of week 1:\n",
        "#Number of weeks\n",
        "n = 1         \n",
        "#Number of features  \n",
        "num_features = 4\n",
        "#Take the weeks up to n\n",
        "df_x, labels = week_up_to_n(df_weekly_merged, n)\n",
        "#Fill missing values in the \"percentage_correct\" column (see report)\n",
        "df_x.fillna(0, inplace = True)\n",
        "#Standardization\n",
        "df_x = df_standarize(df_x)\n",
        "print(df_x.shape)\n",
        "#Preparation of the input in the shape number of users * number of weeks * number of features\n",
        "df_x_binary = df_x.drop(columns=[\"user_id\",\"week\",\"last_week_of_activity\"]).values.reshape(-1, n, num_features)\n",
        "print(df_x_binary.shape)\n",
        "#Preparation of the labels in the shape number of users * boolean of if they dropped the course \n",
        "df_y_binary = labels.drop(columns=[\"user_id\"]).values.reshape(-1, 1)"
      ],
      "id": "Tla367MP69cK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebSXRGVN69cK"
      },
      "outputs": [],
      "source": [
        "# Split into training and test sets.\n",
        "df_x_binary_train_1, df_x_binary_test_1, df_y_binary_train_1, df_y_binary_test_1 = train_test_split(\n",
        "                                                                            df_x_binary, \n",
        "                                                                            df_y_binary,\n",
        "                                                                            test_size=0.2, \n",
        "                                                                            random_state=0, \n",
        "                                                                            stratify=df_y_binary)\n",
        "\n",
        "# Split training into training and validation sets.\n",
        "df_x_binary_train_val_1, df_x_binary_val_1, df_y_binary_train_val_1, df_y_binary_val_1 = train_test_split(\n",
        "                                                                            df_x_binary_train_1, \n",
        "                                                                            df_y_binary_train_1, \n",
        "                                                                            test_size=0.2,\n",
        "                                                                            random_state=0, \n",
        "                                                                            stratify=df_y_binary_train_1)"
      ],
      "id": "ebSXRGVN69cK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMeAKWh469cK"
      },
      "outputs": [],
      "source": [
        "#Parameters of the model\n",
        "params = {}\n",
        "\n",
        "params['batch_size'] = 32\n",
        "params['verbose'] = 1\n",
        "params['best_model_weights'] = 'weights/bestmodel' \n",
        "params['optimizer'] = 'adam'\n",
        "params['recurrent_units'] = 16\n",
        "#The number of epoch is chosen according to how long an epoch takes to train, and how the network behaves;\n",
        "#For a single week of around 10'000 users, 50 epochs are more than enough for the model to overfit\n",
        "params['epochs'] = 50\n",
        "params['dropout_rate'] = 0.1"
      ],
      "id": "yMeAKWh469cK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEKwYImgINzQ"
      },
      "outputs": [],
      "source": [
        "#Grid search on the number of recurrent units in the LSTM model, between 16 and 128\n",
        "params_space = {param: [value] for param, value in params.items()}\n",
        "params_space['recurrent_units'] = [16, 32, 64, 128]\n",
        "params_grid = ParameterGrid(params_space)"
      ],
      "id": "KEKwYImgINzQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5P2e4zD4IOY0",
        "outputId": "90aa678d-3ecc-4390-8dc6-0c31f5a82a07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "203/203 [==============================] - 4s 7ms/step - loss: 0.6848 - auc: 0.5013 - binary_accuracy: 0.5669 - val_loss: 0.6767 - val_auc: 0.5307 - val_binary_accuracy: 0.5952\n",
            "Epoch 2/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6760 - auc: 0.5040 - binary_accuracy: 0.5933 - val_loss: 0.6742 - val_auc: 0.5304 - val_binary_accuracy: 0.5939\n",
            "Epoch 3/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6746 - auc: 0.5136 - binary_accuracy: 0.5938 - val_loss: 0.6738 - val_auc: 0.5424 - val_binary_accuracy: 0.5939\n",
            "Epoch 4/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6740 - auc: 0.5206 - binary_accuracy: 0.5938 - val_loss: 0.6735 - val_auc: 0.5410 - val_binary_accuracy: 0.5939\n",
            "Epoch 5/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6732 - auc: 0.5326 - binary_accuracy: 0.5936 - val_loss: 0.6733 - val_auc: 0.5352 - val_binary_accuracy: 0.5952\n",
            "Epoch 6/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6736 - auc: 0.5259 - binary_accuracy: 0.5936 - val_loss: 0.6731 - val_auc: 0.5392 - val_binary_accuracy: 0.5958\n",
            "Epoch 7/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6728 - auc: 0.5309 - binary_accuracy: 0.5939 - val_loss: 0.6731 - val_auc: 0.5375 - val_binary_accuracy: 0.5958\n",
            "Epoch 8/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6728 - auc: 0.5346 - binary_accuracy: 0.5943 - val_loss: 0.6729 - val_auc: 0.5425 - val_binary_accuracy: 0.5964\n",
            "Epoch 9/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6723 - auc: 0.5394 - binary_accuracy: 0.5946 - val_loss: 0.6727 - val_auc: 0.5402 - val_binary_accuracy: 0.5983\n",
            "Epoch 10/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6720 - auc: 0.5447 - binary_accuracy: 0.5956 - val_loss: 0.6723 - val_auc: 0.5450 - val_binary_accuracy: 0.6007\n",
            "Epoch 11/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6728 - auc: 0.5298 - binary_accuracy: 0.5978 - val_loss: 0.6725 - val_auc: 0.5417 - val_binary_accuracy: 0.6014\n",
            "Epoch 12/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6717 - auc: 0.5429 - binary_accuracy: 0.6000 - val_loss: 0.6722 - val_auc: 0.5417 - val_binary_accuracy: 0.6007\n",
            "Epoch 13/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6716 - auc: 0.5405 - binary_accuracy: 0.5994 - val_loss: 0.6721 - val_auc: 0.5450 - val_binary_accuracy: 0.6026\n",
            "Epoch 14/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6718 - auc: 0.5410 - binary_accuracy: 0.5973 - val_loss: 0.6723 - val_auc: 0.5416 - val_binary_accuracy: 0.6020\n",
            "Epoch 15/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6714 - auc: 0.5418 - binary_accuracy: 0.6020 - val_loss: 0.6724 - val_auc: 0.5398 - val_binary_accuracy: 0.6014\n",
            "Epoch 16/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6723 - auc: 0.5360 - binary_accuracy: 0.5970 - val_loss: 0.6722 - val_auc: 0.5403 - val_binary_accuracy: 0.6020\n",
            "Epoch 17/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6720 - auc: 0.5441 - binary_accuracy: 0.5973 - val_loss: 0.6722 - val_auc: 0.5421 - val_binary_accuracy: 0.6026\n",
            "Epoch 18/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6717 - auc: 0.5421 - binary_accuracy: 0.5977 - val_loss: 0.6723 - val_auc: 0.5412 - val_binary_accuracy: 0.6026\n",
            "Epoch 19/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6715 - auc: 0.5431 - binary_accuracy: 0.5969 - val_loss: 0.6725 - val_auc: 0.5371 - val_binary_accuracy: 0.6032\n",
            "Epoch 20/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6713 - auc: 0.5445 - binary_accuracy: 0.5975 - val_loss: 0.6732 - val_auc: 0.5325 - val_binary_accuracy: 0.6014\n",
            "Epoch 21/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6714 - auc: 0.5440 - binary_accuracy: 0.5990 - val_loss: 0.6723 - val_auc: 0.5430 - val_binary_accuracy: 0.6020\n",
            "Epoch 22/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6705 - auc: 0.5479 - binary_accuracy: 0.5986 - val_loss: 0.6722 - val_auc: 0.5423 - val_binary_accuracy: 0.6020\n",
            "Epoch 23/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6706 - auc: 0.5516 - binary_accuracy: 0.5966 - val_loss: 0.6721 - val_auc: 0.5452 - val_binary_accuracy: 0.6014\n",
            "Epoch 24/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6701 - auc: 0.5506 - binary_accuracy: 0.5975 - val_loss: 0.6725 - val_auc: 0.5398 - val_binary_accuracy: 0.6032\n",
            "Epoch 25/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6704 - auc: 0.5493 - binary_accuracy: 0.5973 - val_loss: 0.6721 - val_auc: 0.5476 - val_binary_accuracy: 0.6007\n",
            "Epoch 26/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6706 - auc: 0.5486 - binary_accuracy: 0.5981 - val_loss: 0.6720 - val_auc: 0.5486 - val_binary_accuracy: 0.6007\n",
            "Epoch 27/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6710 - auc: 0.5469 - binary_accuracy: 0.5963 - val_loss: 0.6723 - val_auc: 0.5448 - val_binary_accuracy: 0.6020\n",
            "Epoch 28/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6716 - auc: 0.5427 - binary_accuracy: 0.5970 - val_loss: 0.6724 - val_auc: 0.5468 - val_binary_accuracy: 0.6020\n",
            "Epoch 29/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6705 - auc: 0.5506 - binary_accuracy: 0.5956 - val_loss: 0.6725 - val_auc: 0.5447 - val_binary_accuracy: 0.6032\n",
            "Epoch 30/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6712 - auc: 0.5468 - binary_accuracy: 0.5953 - val_loss: 0.6727 - val_auc: 0.5435 - val_binary_accuracy: 0.6020\n",
            "Epoch 31/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6713 - auc: 0.5442 - binary_accuracy: 0.5994 - val_loss: 0.6722 - val_auc: 0.5507 - val_binary_accuracy: 0.6014\n",
            "Epoch 32/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6696 - auc: 0.5533 - binary_accuracy: 0.6000 - val_loss: 0.6725 - val_auc: 0.5452 - val_binary_accuracy: 0.6020\n",
            "Epoch 33/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6711 - auc: 0.5464 - binary_accuracy: 0.5981 - val_loss: 0.6720 - val_auc: 0.5512 - val_binary_accuracy: 0.6020\n",
            "Epoch 34/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6693 - auc: 0.5558 - binary_accuracy: 0.6003 - val_loss: 0.6724 - val_auc: 0.5489 - val_binary_accuracy: 0.6014\n",
            "Epoch 35/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6703 - auc: 0.5502 - binary_accuracy: 0.5980 - val_loss: 0.6725 - val_auc: 0.5459 - val_binary_accuracy: 0.6014\n",
            "Epoch 36/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6706 - auc: 0.5517 - binary_accuracy: 0.5952 - val_loss: 0.6728 - val_auc: 0.5423 - val_binary_accuracy: 0.6026\n",
            "Epoch 37/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6710 - auc: 0.5487 - binary_accuracy: 0.5970 - val_loss: 0.6724 - val_auc: 0.5506 - val_binary_accuracy: 0.6007\n",
            "Epoch 38/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6696 - auc: 0.5564 - binary_accuracy: 0.5960 - val_loss: 0.6731 - val_auc: 0.5373 - val_binary_accuracy: 0.6020\n",
            "Epoch 39/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6695 - auc: 0.5549 - binary_accuracy: 0.5977 - val_loss: 0.6728 - val_auc: 0.5453 - val_binary_accuracy: 0.6026\n",
            "Epoch 40/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6699 - auc: 0.5525 - binary_accuracy: 0.5977 - val_loss: 0.6725 - val_auc: 0.5472 - val_binary_accuracy: 0.6007\n",
            "Epoch 41/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6699 - auc: 0.5523 - binary_accuracy: 0.5986 - val_loss: 0.6721 - val_auc: 0.5547 - val_binary_accuracy: 0.6020\n",
            "Epoch 42/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6695 - auc: 0.5604 - binary_accuracy: 0.5972 - val_loss: 0.6721 - val_auc: 0.5540 - val_binary_accuracy: 0.6001\n",
            "Epoch 43/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6707 - auc: 0.5523 - binary_accuracy: 0.5952 - val_loss: 0.6720 - val_auc: 0.5557 - val_binary_accuracy: 0.6020\n",
            "Epoch 44/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6690 - auc: 0.5584 - binary_accuracy: 0.5977 - val_loss: 0.6722 - val_auc: 0.5504 - val_binary_accuracy: 0.6007\n",
            "Epoch 45/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6709 - auc: 0.5507 - binary_accuracy: 0.5933 - val_loss: 0.6729 - val_auc: 0.5434 - val_binary_accuracy: 0.6014\n",
            "Epoch 46/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6698 - auc: 0.5537 - binary_accuracy: 0.5973 - val_loss: 0.6722 - val_auc: 0.5544 - val_binary_accuracy: 0.6001\n",
            "Epoch 47/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6703 - auc: 0.5532 - binary_accuracy: 0.5926 - val_loss: 0.6726 - val_auc: 0.5472 - val_binary_accuracy: 0.6007\n",
            "Epoch 48/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6713 - auc: 0.5453 - binary_accuracy: 0.5946 - val_loss: 0.6725 - val_auc: 0.5502 - val_binary_accuracy: 0.6014\n",
            "Epoch 49/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6694 - auc: 0.5575 - binary_accuracy: 0.5975 - val_loss: 0.6728 - val_auc: 0.5481 - val_binary_accuracy: 0.6014\n",
            "Epoch 50/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6707 - auc: 0.5454 - binary_accuracy: 0.5966 - val_loss: 0.6728 - val_auc: 0.5461 - val_binary_accuracy: 0.6020\n",
            "Epoch 1/50\n",
            "203/203 [==============================] - 4s 8ms/step - loss: 0.6811 - auc_1: 0.5048 - binary_accuracy: 0.5851 - val_loss: 0.6753 - val_auc_1: 0.5406 - val_binary_accuracy: 0.5939\n",
            "Epoch 2/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6748 - auc_1: 0.5134 - binary_accuracy: 0.5938 - val_loss: 0.6745 - val_auc_1: 0.5317 - val_binary_accuracy: 0.5939\n",
            "Epoch 3/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6742 - auc_1: 0.5235 - binary_accuracy: 0.5938 - val_loss: 0.6736 - val_auc_1: 0.5463 - val_binary_accuracy: 0.5939\n",
            "Epoch 4/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6737 - auc_1: 0.5250 - binary_accuracy: 0.5944 - val_loss: 0.6733 - val_auc_1: 0.5399 - val_binary_accuracy: 0.5952\n",
            "Epoch 5/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6729 - auc_1: 0.5358 - binary_accuracy: 0.5946 - val_loss: 0.6733 - val_auc_1: 0.5432 - val_binary_accuracy: 0.5964\n",
            "Epoch 6/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6735 - auc_1: 0.5296 - binary_accuracy: 0.5936 - val_loss: 0.6735 - val_auc_1: 0.5338 - val_binary_accuracy: 0.5964\n",
            "Epoch 7/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6738 - auc_1: 0.5248 - binary_accuracy: 0.5949 - val_loss: 0.6734 - val_auc_1: 0.5348 - val_binary_accuracy: 0.5970\n",
            "Epoch 8/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6733 - auc_1: 0.5338 - binary_accuracy: 0.5939 - val_loss: 0.6733 - val_auc_1: 0.5363 - val_binary_accuracy: 0.5977\n",
            "Epoch 9/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6729 - auc_1: 0.5383 - binary_accuracy: 0.5941 - val_loss: 0.6730 - val_auc_1: 0.5417 - val_binary_accuracy: 0.5989\n",
            "Epoch 10/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6729 - auc_1: 0.5293 - binary_accuracy: 0.5967 - val_loss: 0.6735 - val_auc_1: 0.5301 - val_binary_accuracy: 0.5989\n",
            "Epoch 11/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6723 - auc_1: 0.5394 - binary_accuracy: 0.5952 - val_loss: 0.6729 - val_auc_1: 0.5412 - val_binary_accuracy: 0.6007\n",
            "Epoch 12/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6722 - auc_1: 0.5383 - binary_accuracy: 0.5967 - val_loss: 0.6729 - val_auc_1: 0.5413 - val_binary_accuracy: 0.6014\n",
            "Epoch 13/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6723 - auc_1: 0.5394 - binary_accuracy: 0.5966 - val_loss: 0.6725 - val_auc_1: 0.5450 - val_binary_accuracy: 0.6014\n",
            "Epoch 14/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6720 - auc_1: 0.5377 - binary_accuracy: 0.5984 - val_loss: 0.6727 - val_auc_1: 0.5465 - val_binary_accuracy: 0.6020\n",
            "Epoch 15/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6718 - auc_1: 0.5401 - binary_accuracy: 0.5983 - val_loss: 0.6733 - val_auc_1: 0.5328 - val_binary_accuracy: 0.6014\n",
            "Epoch 16/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6711 - auc_1: 0.5461 - binary_accuracy: 0.6000 - val_loss: 0.6724 - val_auc_1: 0.5468 - val_binary_accuracy: 0.6032\n",
            "Epoch 17/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6716 - auc_1: 0.5424 - binary_accuracy: 0.5998 - val_loss: 0.6727 - val_auc_1: 0.5423 - val_binary_accuracy: 0.6026\n",
            "Epoch 18/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6714 - auc_1: 0.5443 - binary_accuracy: 0.6000 - val_loss: 0.6730 - val_auc_1: 0.5391 - val_binary_accuracy: 0.6026\n",
            "Epoch 19/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6713 - auc_1: 0.5452 - binary_accuracy: 0.5981 - val_loss: 0.6725 - val_auc_1: 0.5458 - val_binary_accuracy: 0.6020\n",
            "Epoch 20/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6711 - auc_1: 0.5441 - binary_accuracy: 0.5986 - val_loss: 0.6727 - val_auc_1: 0.5452 - val_binary_accuracy: 0.6026\n",
            "Epoch 21/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6705 - auc_1: 0.5507 - binary_accuracy: 0.5977 - val_loss: 0.6724 - val_auc_1: 0.5493 - val_binary_accuracy: 0.6014\n",
            "Epoch 22/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6718 - auc_1: 0.5447 - binary_accuracy: 0.5970 - val_loss: 0.6730 - val_auc_1: 0.5441 - val_binary_accuracy: 0.6020\n",
            "Epoch 23/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6712 - auc_1: 0.5431 - binary_accuracy: 0.5956 - val_loss: 0.6725 - val_auc_1: 0.5478 - val_binary_accuracy: 0.6014\n",
            "Epoch 24/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6707 - auc_1: 0.5509 - binary_accuracy: 0.5981 - val_loss: 0.6727 - val_auc_1: 0.5446 - val_binary_accuracy: 0.6032\n",
            "Epoch 25/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6709 - auc_1: 0.5474 - binary_accuracy: 0.5947 - val_loss: 0.6724 - val_auc_1: 0.5471 - val_binary_accuracy: 0.6014\n",
            "Epoch 26/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6709 - auc_1: 0.5465 - binary_accuracy: 0.5966 - val_loss: 0.6725 - val_auc_1: 0.5484 - val_binary_accuracy: 0.6020\n",
            "Epoch 27/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6721 - auc_1: 0.5386 - binary_accuracy: 0.5967 - val_loss: 0.6727 - val_auc_1: 0.5442 - val_binary_accuracy: 0.6020\n",
            "Epoch 28/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6703 - auc_1: 0.5493 - binary_accuracy: 0.5989 - val_loss: 0.6732 - val_auc_1: 0.5362 - val_binary_accuracy: 0.6032\n",
            "Epoch 29/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6720 - auc_1: 0.5400 - binary_accuracy: 0.5938 - val_loss: 0.6729 - val_auc_1: 0.5440 - val_binary_accuracy: 0.6032\n",
            "Epoch 30/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6706 - auc_1: 0.5502 - binary_accuracy: 0.6007 - val_loss: 0.6726 - val_auc_1: 0.5481 - val_binary_accuracy: 0.6026\n",
            "Epoch 31/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6698 - auc_1: 0.5564 - binary_accuracy: 0.5997 - val_loss: 0.6723 - val_auc_1: 0.5520 - val_binary_accuracy: 0.6014\n",
            "Epoch 32/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6698 - auc_1: 0.5529 - binary_accuracy: 0.6007 - val_loss: 0.6726 - val_auc_1: 0.5453 - val_binary_accuracy: 0.6007\n",
            "Epoch 33/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6707 - auc_1: 0.5488 - binary_accuracy: 0.5955 - val_loss: 0.6727 - val_auc_1: 0.5468 - val_binary_accuracy: 0.6026\n",
            "Epoch 34/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6719 - auc_1: 0.5432 - binary_accuracy: 0.5963 - val_loss: 0.6722 - val_auc_1: 0.5542 - val_binary_accuracy: 0.6014\n",
            "Epoch 35/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6708 - auc_1: 0.5457 - binary_accuracy: 0.5990 - val_loss: 0.6730 - val_auc_1: 0.5436 - val_binary_accuracy: 0.6026\n",
            "Epoch 36/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6708 - auc_1: 0.5474 - binary_accuracy: 0.6007 - val_loss: 0.6727 - val_auc_1: 0.5479 - val_binary_accuracy: 0.6020\n",
            "Epoch 37/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6708 - auc_1: 0.5453 - binary_accuracy: 0.5978 - val_loss: 0.6727 - val_auc_1: 0.5461 - val_binary_accuracy: 0.6020\n",
            "Epoch 38/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6697 - auc_1: 0.5531 - binary_accuracy: 0.6026 - val_loss: 0.6720 - val_auc_1: 0.5543 - val_binary_accuracy: 0.6020\n",
            "Epoch 39/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6703 - auc_1: 0.5500 - binary_accuracy: 0.5956 - val_loss: 0.6725 - val_auc_1: 0.5514 - val_binary_accuracy: 0.6014\n",
            "Epoch 40/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6711 - auc_1: 0.5484 - binary_accuracy: 0.5963 - val_loss: 0.6724 - val_auc_1: 0.5512 - val_binary_accuracy: 0.6020\n",
            "Epoch 41/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6715 - auc_1: 0.5426 - binary_accuracy: 0.5977 - val_loss: 0.6728 - val_auc_1: 0.5449 - val_binary_accuracy: 0.6020\n",
            "Epoch 42/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6708 - auc_1: 0.5483 - binary_accuracy: 0.5953 - val_loss: 0.6723 - val_auc_1: 0.5564 - val_binary_accuracy: 0.6014\n",
            "Epoch 43/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6710 - auc_1: 0.5457 - binary_accuracy: 0.5960 - val_loss: 0.6731 - val_auc_1: 0.5422 - val_binary_accuracy: 0.6014\n",
            "Epoch 44/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6702 - auc_1: 0.5538 - binary_accuracy: 0.5978 - val_loss: 0.6729 - val_auc_1: 0.5466 - val_binary_accuracy: 0.6020\n",
            "Epoch 45/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6694 - auc_1: 0.5575 - binary_accuracy: 0.5983 - val_loss: 0.6731 - val_auc_1: 0.5446 - val_binary_accuracy: 0.6020\n",
            "Epoch 46/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6696 - auc_1: 0.5560 - binary_accuracy: 0.5989 - val_loss: 0.6729 - val_auc_1: 0.5434 - val_binary_accuracy: 0.6007\n",
            "Epoch 47/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6717 - auc_1: 0.5411 - binary_accuracy: 0.5967 - val_loss: 0.6725 - val_auc_1: 0.5522 - val_binary_accuracy: 0.6020\n",
            "Epoch 48/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6706 - auc_1: 0.5510 - binary_accuracy: 0.5972 - val_loss: 0.6724 - val_auc_1: 0.5536 - val_binary_accuracy: 0.6001\n",
            "Epoch 49/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6713 - auc_1: 0.5479 - binary_accuracy: 0.5953 - val_loss: 0.6726 - val_auc_1: 0.5533 - val_binary_accuracy: 0.6020\n",
            "Epoch 50/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6705 - auc_1: 0.5503 - binary_accuracy: 0.5963 - val_loss: 0.6723 - val_auc_1: 0.5564 - val_binary_accuracy: 0.6026\n",
            "Epoch 1/50\n",
            "203/203 [==============================] - 4s 7ms/step - loss: 0.6776 - auc_2: 0.5297 - binary_accuracy: 0.5885 - val_loss: 0.6736 - val_auc_2: 0.5415 - val_binary_accuracy: 0.5939\n",
            "Epoch 2/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6744 - auc_2: 0.5163 - binary_accuracy: 0.5941 - val_loss: 0.6743 - val_auc_2: 0.5249 - val_binary_accuracy: 0.5946\n",
            "Epoch 3/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6739 - auc_2: 0.5271 - binary_accuracy: 0.5943 - val_loss: 0.6733 - val_auc_2: 0.5389 - val_binary_accuracy: 0.5964\n",
            "Epoch 4/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6742 - auc_2: 0.5220 - binary_accuracy: 0.5936 - val_loss: 0.6738 - val_auc_2: 0.5333 - val_binary_accuracy: 0.5946\n",
            "Epoch 5/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6729 - auc_2: 0.5340 - binary_accuracy: 0.5947 - val_loss: 0.6731 - val_auc_2: 0.5457 - val_binary_accuracy: 0.5970\n",
            "Epoch 6/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6736 - auc_2: 0.5278 - binary_accuracy: 0.5939 - val_loss: 0.6736 - val_auc_2: 0.5308 - val_binary_accuracy: 0.5964\n",
            "Epoch 7/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6731 - auc_2: 0.5300 - binary_accuracy: 0.5964 - val_loss: 0.6738 - val_auc_2: 0.5293 - val_binary_accuracy: 0.5970\n",
            "Epoch 8/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6731 - auc_2: 0.5310 - binary_accuracy: 0.5953 - val_loss: 0.6739 - val_auc_2: 0.5245 - val_binary_accuracy: 0.5983\n",
            "Epoch 9/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6725 - auc_2: 0.5380 - binary_accuracy: 0.5964 - val_loss: 0.6728 - val_auc_2: 0.5420 - val_binary_accuracy: 0.6014\n",
            "Epoch 10/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6719 - auc_2: 0.5409 - binary_accuracy: 0.5960 - val_loss: 0.6735 - val_auc_2: 0.5322 - val_binary_accuracy: 0.6014\n",
            "Epoch 11/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6725 - auc_2: 0.5380 - binary_accuracy: 0.5961 - val_loss: 0.6739 - val_auc_2: 0.5238 - val_binary_accuracy: 0.5995\n",
            "Epoch 12/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6720 - auc_2: 0.5390 - binary_accuracy: 0.5973 - val_loss: 0.6727 - val_auc_2: 0.5438 - val_binary_accuracy: 0.6020\n",
            "Epoch 13/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6718 - auc_2: 0.5422 - binary_accuracy: 0.5977 - val_loss: 0.6729 - val_auc_2: 0.5407 - val_binary_accuracy: 0.6032\n",
            "Epoch 14/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6711 - auc_2: 0.5469 - binary_accuracy: 0.5980 - val_loss: 0.6731 - val_auc_2: 0.5375 - val_binary_accuracy: 0.6026\n",
            "Epoch 15/50\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6717 - auc_2: 0.5452 - binary_accuracy: 0.5963 - val_loss: 0.6731 - val_auc_2: 0.5391 - val_binary_accuracy: 0.6020\n",
            "Epoch 16/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6720 - auc_2: 0.5388 - binary_accuracy: 0.5987 - val_loss: 0.6730 - val_auc_2: 0.5397 - val_binary_accuracy: 0.6026\n",
            "Epoch 17/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6728 - auc_2: 0.5336 - binary_accuracy: 0.5980 - val_loss: 0.6732 - val_auc_2: 0.5363 - val_binary_accuracy: 0.6014\n",
            "Epoch 18/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6713 - auc_2: 0.5438 - binary_accuracy: 0.5983 - val_loss: 0.6738 - val_auc_2: 0.5282 - val_binary_accuracy: 0.6007\n",
            "Epoch 19/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6721 - auc_2: 0.5417 - binary_accuracy: 0.5966 - val_loss: 0.6725 - val_auc_2: 0.5476 - val_binary_accuracy: 0.6026\n",
            "Epoch 20/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6719 - auc_2: 0.5399 - binary_accuracy: 0.5989 - val_loss: 0.6746 - val_auc_2: 0.5221 - val_binary_accuracy: 0.5995\n",
            "Epoch 21/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6710 - auc_2: 0.5485 - binary_accuracy: 0.5994 - val_loss: 0.6729 - val_auc_2: 0.5422 - val_binary_accuracy: 0.6026\n",
            "Epoch 22/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6710 - auc_2: 0.5479 - binary_accuracy: 0.5981 - val_loss: 0.6739 - val_auc_2: 0.5293 - val_binary_accuracy: 0.6014\n",
            "Epoch 23/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6718 - auc_2: 0.5400 - binary_accuracy: 0.5978 - val_loss: 0.6723 - val_auc_2: 0.5500 - val_binary_accuracy: 0.6014\n",
            "Epoch 24/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6718 - auc_2: 0.5415 - binary_accuracy: 0.5958 - val_loss: 0.6729 - val_auc_2: 0.5518 - val_binary_accuracy: 0.6032\n",
            "Epoch 25/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6709 - auc_2: 0.5430 - binary_accuracy: 0.5980 - val_loss: 0.6727 - val_auc_2: 0.5480 - val_binary_accuracy: 0.6020\n",
            "Epoch 26/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6710 - auc_2: 0.5427 - binary_accuracy: 0.5969 - val_loss: 0.6729 - val_auc_2: 0.5475 - val_binary_accuracy: 0.6026\n",
            "Epoch 27/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6709 - auc_2: 0.5481 - binary_accuracy: 0.5956 - val_loss: 0.6738 - val_auc_2: 0.5330 - val_binary_accuracy: 0.6032\n",
            "Epoch 28/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6717 - auc_2: 0.5443 - binary_accuracy: 0.5967 - val_loss: 0.6727 - val_auc_2: 0.5533 - val_binary_accuracy: 0.6014\n",
            "Epoch 29/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6715 - auc_2: 0.5399 - binary_accuracy: 0.5987 - val_loss: 0.6731 - val_auc_2: 0.5485 - val_binary_accuracy: 0.6007\n",
            "Epoch 30/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6712 - auc_2: 0.5491 - binary_accuracy: 0.5956 - val_loss: 0.6739 - val_auc_2: 0.5406 - val_binary_accuracy: 0.6020\n",
            "Epoch 31/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6710 - auc_2: 0.5504 - binary_accuracy: 0.5935 - val_loss: 0.6730 - val_auc_2: 0.5478 - val_binary_accuracy: 0.6026\n",
            "Epoch 32/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6716 - auc_2: 0.5443 - binary_accuracy: 0.5956 - val_loss: 0.6738 - val_auc_2: 0.5387 - val_binary_accuracy: 0.6026\n",
            "Epoch 33/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6715 - auc_2: 0.5423 - binary_accuracy: 0.5984 - val_loss: 0.6734 - val_auc_2: 0.5423 - val_binary_accuracy: 0.6026\n",
            "Epoch 34/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6707 - auc_2: 0.5508 - binary_accuracy: 0.5973 - val_loss: 0.6734 - val_auc_2: 0.5432 - val_binary_accuracy: 0.6026\n",
            "Epoch 35/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6712 - auc_2: 0.5456 - binary_accuracy: 0.5956 - val_loss: 0.6730 - val_auc_2: 0.5478 - val_binary_accuracy: 0.6026\n",
            "Epoch 36/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6703 - auc_2: 0.5496 - binary_accuracy: 0.5964 - val_loss: 0.6735 - val_auc_2: 0.5429 - val_binary_accuracy: 0.6032\n",
            "Epoch 37/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6703 - auc_2: 0.5523 - binary_accuracy: 0.5961 - val_loss: 0.6734 - val_auc_2: 0.5417 - val_binary_accuracy: 0.6020\n",
            "Epoch 38/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6712 - auc_2: 0.5484 - binary_accuracy: 0.5978 - val_loss: 0.6736 - val_auc_2: 0.5427 - val_binary_accuracy: 0.6014\n",
            "Epoch 39/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6701 - auc_2: 0.5523 - binary_accuracy: 0.5967 - val_loss: 0.6741 - val_auc_2: 0.5378 - val_binary_accuracy: 0.6020\n",
            "Epoch 40/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6706 - auc_2: 0.5491 - binary_accuracy: 0.5975 - val_loss: 0.6733 - val_auc_2: 0.5462 - val_binary_accuracy: 0.6020\n",
            "Epoch 41/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6714 - auc_2: 0.5419 - binary_accuracy: 0.5960 - val_loss: 0.6731 - val_auc_2: 0.5504 - val_binary_accuracy: 0.6026\n",
            "Epoch 42/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6720 - auc_2: 0.5396 - binary_accuracy: 0.5970 - val_loss: 0.6738 - val_auc_2: 0.5409 - val_binary_accuracy: 0.6007\n",
            "Epoch 43/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6717 - auc_2: 0.5415 - binary_accuracy: 0.5970 - val_loss: 0.6734 - val_auc_2: 0.5479 - val_binary_accuracy: 0.6020\n",
            "Epoch 44/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6707 - auc_2: 0.5505 - binary_accuracy: 0.5964 - val_loss: 0.6728 - val_auc_2: 0.5542 - val_binary_accuracy: 0.6014\n",
            "Epoch 45/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6703 - auc_2: 0.5500 - binary_accuracy: 0.5947 - val_loss: 0.6736 - val_auc_2: 0.5452 - val_binary_accuracy: 0.6020\n",
            "Epoch 46/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6708 - auc_2: 0.5533 - binary_accuracy: 0.5915 - val_loss: 0.6739 - val_auc_2: 0.5455 - val_binary_accuracy: 0.6014\n",
            "Epoch 47/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6707 - auc_2: 0.5468 - binary_accuracy: 0.5972 - val_loss: 0.6734 - val_auc_2: 0.5511 - val_binary_accuracy: 0.6014\n",
            "Epoch 48/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6705 - auc_2: 0.5495 - binary_accuracy: 0.5980 - val_loss: 0.6733 - val_auc_2: 0.5512 - val_binary_accuracy: 0.6020\n",
            "Epoch 49/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6699 - auc_2: 0.5534 - binary_accuracy: 0.5990 - val_loss: 0.6731 - val_auc_2: 0.5549 - val_binary_accuracy: 0.5995\n",
            "Epoch 50/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6718 - auc_2: 0.5421 - binary_accuracy: 0.5975 - val_loss: 0.6736 - val_auc_2: 0.5479 - val_binary_accuracy: 0.6020\n",
            "Epoch 1/50\n",
            "203/203 [==============================] - 4s 8ms/step - loss: 0.6798 - auc_3: 0.4945 - binary_accuracy: 0.5907 - val_loss: 0.6748 - val_auc_3: 0.5364 - val_binary_accuracy: 0.5939\n",
            "Epoch 2/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6749 - auc_3: 0.5156 - binary_accuracy: 0.5938 - val_loss: 0.6744 - val_auc_3: 0.5398 - val_binary_accuracy: 0.5939\n",
            "Epoch 3/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6743 - auc_3: 0.5240 - binary_accuracy: 0.5943 - val_loss: 0.6765 - val_auc_3: 0.5111 - val_binary_accuracy: 0.5946\n",
            "Epoch 4/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6741 - auc_3: 0.5252 - binary_accuracy: 0.5932 - val_loss: 0.6754 - val_auc_3: 0.5154 - val_binary_accuracy: 0.5952\n",
            "Epoch 5/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6740 - auc_3: 0.5289 - binary_accuracy: 0.5929 - val_loss: 0.6746 - val_auc_3: 0.5429 - val_binary_accuracy: 0.5958\n",
            "Epoch 6/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6736 - auc_3: 0.5311 - binary_accuracy: 0.5953 - val_loss: 0.6737 - val_auc_3: 0.5421 - val_binary_accuracy: 0.5989\n",
            "Epoch 7/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6733 - auc_3: 0.5303 - binary_accuracy: 0.5939 - val_loss: 0.6739 - val_auc_3: 0.5275 - val_binary_accuracy: 0.5983\n",
            "Epoch 8/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6728 - auc_3: 0.5354 - binary_accuracy: 0.5952 - val_loss: 0.6732 - val_auc_3: 0.5445 - val_binary_accuracy: 0.6007\n",
            "Epoch 9/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6732 - auc_3: 0.5285 - binary_accuracy: 0.5958 - val_loss: 0.6743 - val_auc_3: 0.5196 - val_binary_accuracy: 0.5989\n",
            "Epoch 10/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6725 - auc_3: 0.5373 - binary_accuracy: 0.5972 - val_loss: 0.6735 - val_auc_3: 0.5319 - val_binary_accuracy: 0.6014\n",
            "Epoch 11/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6726 - auc_3: 0.5388 - binary_accuracy: 0.5961 - val_loss: 0.6734 - val_auc_3: 0.5337 - val_binary_accuracy: 0.6014\n",
            "Epoch 12/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6724 - auc_3: 0.5377 - binary_accuracy: 0.5972 - val_loss: 0.6745 - val_auc_3: 0.5231 - val_binary_accuracy: 0.6014\n",
            "Epoch 13/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6724 - auc_3: 0.5376 - binary_accuracy: 0.5980 - val_loss: 0.6727 - val_auc_3: 0.5471 - val_binary_accuracy: 0.6014\n",
            "Epoch 14/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6728 - auc_3: 0.5306 - binary_accuracy: 0.5981 - val_loss: 0.6730 - val_auc_3: 0.5418 - val_binary_accuracy: 0.6032\n",
            "Epoch 15/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6725 - auc_3: 0.5355 - binary_accuracy: 0.5964 - val_loss: 0.6728 - val_auc_3: 0.5424 - val_binary_accuracy: 0.6014\n",
            "Epoch 16/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6719 - auc_3: 0.5391 - binary_accuracy: 0.5986 - val_loss: 0.6730 - val_auc_3: 0.5414 - val_binary_accuracy: 0.6032\n",
            "Epoch 17/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6719 - auc_3: 0.5414 - binary_accuracy: 0.5992 - val_loss: 0.6738 - val_auc_3: 0.5287 - val_binary_accuracy: 0.6026\n",
            "Epoch 18/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6721 - auc_3: 0.5375 - binary_accuracy: 0.5987 - val_loss: 0.6726 - val_auc_3: 0.5453 - val_binary_accuracy: 0.6007\n",
            "Epoch 19/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6721 - auc_3: 0.5397 - binary_accuracy: 0.5978 - val_loss: 0.6732 - val_auc_3: 0.5441 - val_binary_accuracy: 0.6014\n",
            "Epoch 20/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6717 - auc_3: 0.5389 - binary_accuracy: 0.5994 - val_loss: 0.6748 - val_auc_3: 0.5265 - val_binary_accuracy: 0.6014\n",
            "Epoch 21/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6717 - auc_3: 0.5413 - binary_accuracy: 0.6000 - val_loss: 0.6737 - val_auc_3: 0.5336 - val_binary_accuracy: 0.6032\n",
            "Epoch 22/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6717 - auc_3: 0.5423 - binary_accuracy: 0.5981 - val_loss: 0.6747 - val_auc_3: 0.5244 - val_binary_accuracy: 0.6020\n",
            "Epoch 23/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6725 - auc_3: 0.5366 - binary_accuracy: 0.5977 - val_loss: 0.6732 - val_auc_3: 0.5359 - val_binary_accuracy: 0.6026\n",
            "Epoch 24/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6716 - auc_3: 0.5423 - binary_accuracy: 0.5981 - val_loss: 0.6748 - val_auc_3: 0.5231 - val_binary_accuracy: 0.6014\n",
            "Epoch 25/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6707 - auc_3: 0.5472 - binary_accuracy: 0.5998 - val_loss: 0.6734 - val_auc_3: 0.5385 - val_binary_accuracy: 0.6026\n",
            "Epoch 26/50\n",
            "203/203 [==============================] - 1s 7ms/step - loss: 0.6717 - auc_3: 0.5422 - binary_accuracy: 0.5990 - val_loss: 0.6730 - val_auc_3: 0.5441 - val_binary_accuracy: 0.6032\n",
            "Epoch 27/50\n",
            "203/203 [==============================] - 1s 7ms/step - loss: 0.6718 - auc_3: 0.5422 - binary_accuracy: 0.5990 - val_loss: 0.6735 - val_auc_3: 0.5387 - val_binary_accuracy: 0.6032\n",
            "Epoch 28/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6704 - auc_3: 0.5492 - binary_accuracy: 0.5990 - val_loss: 0.6731 - val_auc_3: 0.5466 - val_binary_accuracy: 0.6032\n",
            "Epoch 29/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6705 - auc_3: 0.5506 - binary_accuracy: 0.5984 - val_loss: 0.6736 - val_auc_3: 0.5421 - val_binary_accuracy: 0.6032\n",
            "Epoch 30/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6719 - auc_3: 0.5437 - binary_accuracy: 0.5983 - val_loss: 0.6741 - val_auc_3: 0.5373 - val_binary_accuracy: 0.6014\n",
            "Epoch 31/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6711 - auc_3: 0.5466 - binary_accuracy: 0.5956 - val_loss: 0.6728 - val_auc_3: 0.5539 - val_binary_accuracy: 0.6007\n",
            "Epoch 32/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6716 - auc_3: 0.5425 - binary_accuracy: 0.5939 - val_loss: 0.6734 - val_auc_3: 0.5451 - val_binary_accuracy: 0.6032\n",
            "Epoch 33/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6716 - auc_3: 0.5439 - binary_accuracy: 0.5972 - val_loss: 0.6737 - val_auc_3: 0.5447 - val_binary_accuracy: 0.6026\n",
            "Epoch 34/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6717 - auc_3: 0.5421 - binary_accuracy: 0.5998 - val_loss: 0.6740 - val_auc_3: 0.5390 - val_binary_accuracy: 0.6014\n",
            "Epoch 35/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6713 - auc_3: 0.5468 - binary_accuracy: 0.5972 - val_loss: 0.6737 - val_auc_3: 0.5397 - val_binary_accuracy: 0.6026\n",
            "Epoch 36/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6725 - auc_3: 0.5365 - binary_accuracy: 0.5970 - val_loss: 0.6732 - val_auc_3: 0.5503 - val_binary_accuracy: 0.6026\n",
            "Epoch 37/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6709 - auc_3: 0.5477 - binary_accuracy: 0.5981 - val_loss: 0.6731 - val_auc_3: 0.5507 - val_binary_accuracy: 0.6032\n",
            "Epoch 38/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6705 - auc_3: 0.5485 - binary_accuracy: 0.5994 - val_loss: 0.6731 - val_auc_3: 0.5475 - val_binary_accuracy: 0.6026\n",
            "Epoch 39/50\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6711 - auc_3: 0.5461 - binary_accuracy: 0.5987 - val_loss: 0.6728 - val_auc_3: 0.5493 - val_binary_accuracy: 0.6014\n",
            "Epoch 40/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6714 - auc_3: 0.5483 - binary_accuracy: 0.5947 - val_loss: 0.6729 - val_auc_3: 0.5534 - val_binary_accuracy: 0.6026\n",
            "Epoch 41/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6705 - auc_3: 0.5462 - binary_accuracy: 0.5989 - val_loss: 0.6729 - val_auc_3: 0.5493 - val_binary_accuracy: 0.6020\n",
            "Epoch 42/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6697 - auc_3: 0.5522 - binary_accuracy: 0.6024 - val_loss: 0.6745 - val_auc_3: 0.5319 - val_binary_accuracy: 0.6014\n",
            "Epoch 43/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6705 - auc_3: 0.5505 - binary_accuracy: 0.5972 - val_loss: 0.6730 - val_auc_3: 0.5510 - val_binary_accuracy: 0.6007\n",
            "Epoch 44/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6704 - auc_3: 0.5489 - binary_accuracy: 0.5978 - val_loss: 0.6728 - val_auc_3: 0.5540 - val_binary_accuracy: 0.6014\n",
            "Epoch 45/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6715 - auc_3: 0.5436 - binary_accuracy: 0.5958 - val_loss: 0.6738 - val_auc_3: 0.5428 - val_binary_accuracy: 0.6020\n",
            "Epoch 46/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6698 - auc_3: 0.5540 - binary_accuracy: 0.5994 - val_loss: 0.6730 - val_auc_3: 0.5496 - val_binary_accuracy: 0.6007\n",
            "Epoch 47/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6717 - auc_3: 0.5431 - binary_accuracy: 0.5958 - val_loss: 0.6734 - val_auc_3: 0.5460 - val_binary_accuracy: 0.6026\n",
            "Epoch 48/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6706 - auc_3: 0.5499 - binary_accuracy: 0.5978 - val_loss: 0.6734 - val_auc_3: 0.5453 - val_binary_accuracy: 0.6026\n",
            "Epoch 49/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6714 - auc_3: 0.5461 - binary_accuracy: 0.5933 - val_loss: 0.6740 - val_auc_3: 0.5445 - val_binary_accuracy: 0.6020\n",
            "Epoch 50/50\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.6710 - auc_3: 0.5459 - binary_accuracy: 0.5977 - val_loss: 0.6741 - val_auc_3: 0.5380 - val_binary_accuracy: 0.6020\n",
            "51/51 [==============================] - 1s 2ms/step - loss: 0.6720 - auc_4: 0.5486 - binary_accuracy: 0.6007\n",
            "51/51 [==============================] - 1s 2ms/step - loss: 0.6720 - auc_5: 0.5543 - binary_accuracy: 0.6020\n",
            "51/51 [==============================] - 1s 2ms/step - loss: 0.6723 - auc_6: 0.5500 - binary_accuracy: 0.6014\n",
            "51/51 [==============================] - 1s 2ms/step - loss: 0.6726 - auc_7: 0.5453 - binary_accuracy: 0.6007\n"
          ]
        }
      ],
      "source": [
        "# Conduct the gridsearch over hyperparameters.\n",
        "results_1 = {}\n",
        "\n",
        "for params_i in params_grid:\n",
        "\n",
        "  # Create a LSTM model with the specific parameter setting params_i\n",
        "  time_series_lstm = create_model_lstm_mooc_binary(num_features, 1, params_i)\n",
        "\n",
        "  save_model_name = params_i['best_model_weights'] + \"_\" + str(params_i['recurrent_units']) + \"_\" + str(n)\n",
        "\n",
        "  # Save the best version of the model through the training epochs\n",
        "  ckp_callback = tf.keras.callbacks.ModelCheckpoint(save_model_name, \n",
        "                                                    save_best_only=True, save_weights_only=True)\n",
        "\n",
        "  # Fit the model on the training data with the appropriate parameters  \n",
        "  time_series_lstm.fit(df_x_binary_train_val_1, \n",
        "                        df_y_binary_train_val_1, \n",
        "                        epochs=params_i['epochs'],\n",
        "                        validation_data=(df_x_binary_val_1, df_y_binary_val_1),\n",
        "                        callbacks=[ckp_callback], \n",
        "                        verbose=params_i['verbose'])\n",
        "  \n",
        "#Once each model has been fully trained, evaluate their best version on the validation set to choose the best parameter\n",
        "for params_i in params_grid:\n",
        "  time_series_lstm = create_model_lstm_mooc_binary(num_features, 1, params_i)\n",
        "  save_model_name = params_i['best_model_weights'] + \"_\" + str(params_i['recurrent_units']) + \"_\" + str(n)\n",
        "  time_series_lstm.load_weights(save_model_name)\n",
        "  # Evaluate the model performance\n",
        "  results_1[params_i['recurrent_units']] = time_series_lstm.evaluate(df_x_binary_val_1, \n",
        "                                                                    df_y_binary_val_1,\n",
        "                                                                    verbose=params_i['verbose'], \n",
        "                                                                    return_dict=True)"
      ],
      "id": "5P2e4zD4IOY0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0dQDkloLKt9",
        "outputId": "f36b474b-f725-4fae-8bef-18cc5f93cfaa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sort candidate parameters according to their accuracy\n",
        "results_sorted = sorted(results_1.items(), key=lambda x: x[1]['binary_accuracy'], reverse=True)\n",
        "# Obtain the best parameters\n",
        "best_params_1 = results_sorted[0][0]\n",
        "best_params_1"
      ],
      "id": "w0dQDkloLKt9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeuNAOXtrQyx"
      },
      "source": [
        "###2nd LSTM NN: Training on Weeks 1 to 4:"
      ],
      "id": "DeuNAOXtrQyx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF_eso5rODBN"
      },
      "outputs": [],
      "source": [
        "#Parameters for the dataset of weeks 1 to 4; same procedure as for week 1\n",
        "n = 4\n",
        "df_x, labels = week_up_to_n(df_weekly_merged, n)\n",
        "df_x.fillna(0, inplace = True)\n",
        "df_x = df_standarize(df_x)\n",
        "df_x_binary = df_x.drop(columns=[\"user_id\",\"week\",\"last_week_of_activity\"]).values.reshape(-1, n, num_features)\n",
        "df_y_binary = labels.drop(columns=[\"user_id\"]).values.reshape(-1, 1)"
      ],
      "id": "FF_eso5rODBN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YO6jacjHODBP"
      },
      "outputs": [],
      "source": [
        "# Split into training and test sets.\n",
        "df_x_binary_train_4, df_x_binary_test_4, df_y_binary_train_4, df_y_binary_test_4 = train_test_split(\n",
        "                                                                            df_x_binary, \n",
        "                                                                            df_y_binary,\n",
        "                                                                            test_size=0.2, \n",
        "                                                                            random_state=0, \n",
        "                                                                            stratify=df_y_binary)\n",
        "\n",
        "# Split training into training and validation sets.\n",
        "df_x_binary_train_val_4, df_x_binary_val_4, df_y_binary_train_val_4, df_y_binary_val_4 = train_test_split(\n",
        "                                                                            df_x_binary_train_4, \n",
        "                                                                            df_y_binary_train_4, \n",
        "                                                                            test_size=0.2,\n",
        "                                                                            random_state=0, \n",
        "                                                                            stratify=df_y_binary_train_4)"
      ],
      "id": "YO6jacjHODBP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBEsRzwiODBP"
      },
      "outputs": [],
      "source": [
        "#Parameters of the model\n",
        "params = {}\n",
        "\n",
        "params['batch_size'] = 32\n",
        "params['verbose'] = 1\n",
        "params['best_model_weights'] = 'weights/bestmodel' \n",
        "params['optimizer'] = 'adam'\n",
        "params['recurrent_units'] = 16\n",
        "#Here since we have less users in the dataset (as many dropped out during week 1 to 3), \n",
        "#epochs takes less time and we have to run more of them to have the network overfit\n",
        "params['epochs'] = 200\n",
        "params['dropout_rate'] = 0.1"
      ],
      "id": "HBEsRzwiODBP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlxOv1nfODBQ"
      },
      "outputs": [],
      "source": [
        "#Grid search on the number of recurrent units in the LSTM model, between 16 and 128\n",
        "params_space = {param: [value] for param, value in params.items()}\n",
        "params_space['recurrent_units'] = [16, 32, 64, 128]\n",
        "params_grid = ParameterGrid(params_space)"
      ],
      "id": "BlxOv1nfODBQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dsnZGbDODBQ",
        "outputId": "0135248a-7f0c-406f-e5b2-d1e6bab1d63c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "47/47 [==============================] - 3s 19ms/step - loss: 0.6719 - auc_8: 0.5693 - binary_accuracy: 0.5991 - val_loss: 0.6443 - val_auc_8: 0.6405 - val_binary_accuracy: 0.6542\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6428 - auc_8: 0.5821 - binary_accuracy: 0.6568 - val_loss: 0.6208 - val_auc_8: 0.6385 - val_binary_accuracy: 0.6676\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6303 - auc_8: 0.5700 - binary_accuracy: 0.6662 - val_loss: 0.6135 - val_auc_8: 0.6391 - val_binary_accuracy: 0.6676\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6244 - auc_8: 0.5897 - binary_accuracy: 0.6662 - val_loss: 0.6119 - val_auc_8: 0.6399 - val_binary_accuracy: 0.6676\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6234 - auc_8: 0.5856 - binary_accuracy: 0.6662 - val_loss: 0.6113 - val_auc_8: 0.6423 - val_binary_accuracy: 0.6676\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.6249 - auc_8: 0.5852 - binary_accuracy: 0.6662 - val_loss: 0.6115 - val_auc_8: 0.6410 - val_binary_accuracy: 0.6676\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6228 - auc_8: 0.5890 - binary_accuracy: 0.6662 - val_loss: 0.6105 - val_auc_8: 0.6432 - val_binary_accuracy: 0.6676\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6230 - auc_8: 0.5870 - binary_accuracy: 0.6662 - val_loss: 0.6101 - val_auc_8: 0.6421 - val_binary_accuracy: 0.6676\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6221 - auc_8: 0.5913 - binary_accuracy: 0.6662 - val_loss: 0.6096 - val_auc_8: 0.6450 - val_binary_accuracy: 0.6676\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6215 - auc_8: 0.5900 - binary_accuracy: 0.6662 - val_loss: 0.6086 - val_auc_8: 0.6464 - val_binary_accuracy: 0.6676\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6208 - auc_8: 0.5987 - binary_accuracy: 0.6662 - val_loss: 0.6089 - val_auc_8: 0.6482 - val_binary_accuracy: 0.6676\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6211 - auc_8: 0.5999 - binary_accuracy: 0.6662 - val_loss: 0.6083 - val_auc_8: 0.6464 - val_binary_accuracy: 0.6676\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6194 - auc_8: 0.6027 - binary_accuracy: 0.6662 - val_loss: 0.6081 - val_auc_8: 0.6479 - val_binary_accuracy: 0.6676\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6206 - auc_8: 0.6003 - binary_accuracy: 0.6662 - val_loss: 0.6071 - val_auc_8: 0.6538 - val_binary_accuracy: 0.6676\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6205 - auc_8: 0.5978 - binary_accuracy: 0.6662 - val_loss: 0.6070 - val_auc_8: 0.6481 - val_binary_accuracy: 0.6676\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6199 - auc_8: 0.6001 - binary_accuracy: 0.6655 - val_loss: 0.6067 - val_auc_8: 0.6534 - val_binary_accuracy: 0.6676\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.6188 - auc_8: 0.6064 - binary_accuracy: 0.6662 - val_loss: 0.6068 - val_auc_8: 0.6577 - val_binary_accuracy: 0.6676\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6201 - auc_8: 0.6038 - binary_accuracy: 0.6662 - val_loss: 0.6064 - val_auc_8: 0.6554 - val_binary_accuracy: 0.6676\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6172 - auc_8: 0.6095 - binary_accuracy: 0.6655 - val_loss: 0.6066 - val_auc_8: 0.6515 - val_binary_accuracy: 0.6676\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6181 - auc_8: 0.6118 - binary_accuracy: 0.6662 - val_loss: 0.6063 - val_auc_8: 0.6520 - val_binary_accuracy: 0.6676\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6172 - auc_8: 0.6097 - binary_accuracy: 0.6662 - val_loss: 0.6056 - val_auc_8: 0.6536 - val_binary_accuracy: 0.6676\n",
            "Epoch 22/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6162 - auc_8: 0.6137 - binary_accuracy: 0.6669 - val_loss: 0.6051 - val_auc_8: 0.6542 - val_binary_accuracy: 0.6676\n",
            "Epoch 23/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6178 - auc_8: 0.6097 - binary_accuracy: 0.6649 - val_loss: 0.6049 - val_auc_8: 0.6565 - val_binary_accuracy: 0.6676\n",
            "Epoch 24/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6155 - auc_8: 0.6194 - binary_accuracy: 0.6669 - val_loss: 0.6046 - val_auc_8: 0.6547 - val_binary_accuracy: 0.6702\n",
            "Epoch 25/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6153 - auc_8: 0.6159 - binary_accuracy: 0.6655 - val_loss: 0.6049 - val_auc_8: 0.6529 - val_binary_accuracy: 0.6676\n",
            "Epoch 26/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6176 - auc_8: 0.6098 - binary_accuracy: 0.6682 - val_loss: 0.6060 - val_auc_8: 0.6466 - val_binary_accuracy: 0.6676\n",
            "Epoch 27/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6169 - auc_8: 0.6092 - binary_accuracy: 0.6676 - val_loss: 0.6057 - val_auc_8: 0.6487 - val_binary_accuracy: 0.6676\n",
            "Epoch 28/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6152 - auc_8: 0.6224 - binary_accuracy: 0.6689 - val_loss: 0.6047 - val_auc_8: 0.6493 - val_binary_accuracy: 0.6702\n",
            "Epoch 29/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6124 - auc_8: 0.6214 - binary_accuracy: 0.6689 - val_loss: 0.6042 - val_auc_8: 0.6504 - val_binary_accuracy: 0.6702\n",
            "Epoch 30/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6135 - auc_8: 0.6245 - binary_accuracy: 0.6689 - val_loss: 0.6059 - val_auc_8: 0.6469 - val_binary_accuracy: 0.6729\n",
            "Epoch 31/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.6156 - auc_8: 0.6164 - binary_accuracy: 0.6689 - val_loss: 0.6053 - val_auc_8: 0.6450 - val_binary_accuracy: 0.6702\n",
            "Epoch 32/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6136 - auc_8: 0.6215 - binary_accuracy: 0.6649 - val_loss: 0.6054 - val_auc_8: 0.6433 - val_binary_accuracy: 0.6702\n",
            "Epoch 33/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6128 - auc_8: 0.6247 - binary_accuracy: 0.6716 - val_loss: 0.6056 - val_auc_8: 0.6413 - val_binary_accuracy: 0.6729\n",
            "Epoch 34/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6143 - auc_8: 0.6187 - binary_accuracy: 0.6676 - val_loss: 0.6062 - val_auc_8: 0.6418 - val_binary_accuracy: 0.6729\n",
            "Epoch 35/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6142 - auc_8: 0.6155 - binary_accuracy: 0.6696 - val_loss: 0.6050 - val_auc_8: 0.6461 - val_binary_accuracy: 0.6729\n",
            "Epoch 36/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6148 - auc_8: 0.6224 - binary_accuracy: 0.6655 - val_loss: 0.6048 - val_auc_8: 0.6423 - val_binary_accuracy: 0.6783\n",
            "Epoch 37/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6142 - auc_8: 0.6227 - binary_accuracy: 0.6749 - val_loss: 0.6057 - val_auc_8: 0.6429 - val_binary_accuracy: 0.6729\n",
            "Epoch 38/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6131 - auc_8: 0.6252 - binary_accuracy: 0.6629 - val_loss: 0.6049 - val_auc_8: 0.6436 - val_binary_accuracy: 0.6729\n",
            "Epoch 39/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6119 - auc_8: 0.6260 - binary_accuracy: 0.6689 - val_loss: 0.6045 - val_auc_8: 0.6409 - val_binary_accuracy: 0.6729\n",
            "Epoch 40/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6116 - auc_8: 0.6294 - binary_accuracy: 0.6662 - val_loss: 0.6045 - val_auc_8: 0.6432 - val_binary_accuracy: 0.6756\n",
            "Epoch 41/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6103 - auc_8: 0.6300 - binary_accuracy: 0.6763 - val_loss: 0.6047 - val_auc_8: 0.6417 - val_binary_accuracy: 0.6729\n",
            "Epoch 42/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6122 - auc_8: 0.6254 - binary_accuracy: 0.6716 - val_loss: 0.6053 - val_auc_8: 0.6382 - val_binary_accuracy: 0.6729\n",
            "Epoch 43/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6097 - auc_8: 0.6334 - binary_accuracy: 0.6756 - val_loss: 0.6043 - val_auc_8: 0.6413 - val_binary_accuracy: 0.6729\n",
            "Epoch 44/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6107 - auc_8: 0.6315 - binary_accuracy: 0.6682 - val_loss: 0.6041 - val_auc_8: 0.6434 - val_binary_accuracy: 0.6836\n",
            "Epoch 45/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6118 - auc_8: 0.6297 - binary_accuracy: 0.6763 - val_loss: 0.6043 - val_auc_8: 0.6418 - val_binary_accuracy: 0.6729\n",
            "Epoch 46/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6130 - auc_8: 0.6226 - binary_accuracy: 0.6689 - val_loss: 0.6049 - val_auc_8: 0.6372 - val_binary_accuracy: 0.6729\n",
            "Epoch 47/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6122 - auc_8: 0.6249 - binary_accuracy: 0.6635 - val_loss: 0.6051 - val_auc_8: 0.6351 - val_binary_accuracy: 0.6729\n",
            "Epoch 48/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6101 - auc_8: 0.6301 - binary_accuracy: 0.6743 - val_loss: 0.6049 - val_auc_8: 0.6385 - val_binary_accuracy: 0.6729\n",
            "Epoch 49/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6099 - auc_8: 0.6352 - binary_accuracy: 0.6676 - val_loss: 0.6052 - val_auc_8: 0.6384 - val_binary_accuracy: 0.6756\n",
            "Epoch 50/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6112 - auc_8: 0.6294 - binary_accuracy: 0.6689 - val_loss: 0.6046 - val_auc_8: 0.6401 - val_binary_accuracy: 0.6783\n",
            "Epoch 51/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6099 - auc_8: 0.6346 - binary_accuracy: 0.6669 - val_loss: 0.6051 - val_auc_8: 0.6358 - val_binary_accuracy: 0.6756\n",
            "Epoch 52/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6108 - auc_8: 0.6298 - binary_accuracy: 0.6689 - val_loss: 0.6045 - val_auc_8: 0.6375 - val_binary_accuracy: 0.6729\n",
            "Epoch 53/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6082 - auc_8: 0.6401 - binary_accuracy: 0.6696 - val_loss: 0.6054 - val_auc_8: 0.6369 - val_binary_accuracy: 0.6756\n",
            "Epoch 54/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6069 - auc_8: 0.6426 - binary_accuracy: 0.6790 - val_loss: 0.6041 - val_auc_8: 0.6377 - val_binary_accuracy: 0.6836\n",
            "Epoch 55/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6111 - auc_8: 0.6286 - binary_accuracy: 0.6689 - val_loss: 0.6048 - val_auc_8: 0.6384 - val_binary_accuracy: 0.6756\n",
            "Epoch 56/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6098 - auc_8: 0.6365 - binary_accuracy: 0.6635 - val_loss: 0.6057 - val_auc_8: 0.6372 - val_binary_accuracy: 0.6756\n",
            "Epoch 57/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6102 - auc_8: 0.6308 - binary_accuracy: 0.6790 - val_loss: 0.6045 - val_auc_8: 0.6376 - val_binary_accuracy: 0.6783\n",
            "Epoch 58/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6095 - auc_8: 0.6355 - binary_accuracy: 0.6729 - val_loss: 0.6048 - val_auc_8: 0.6353 - val_binary_accuracy: 0.6756\n",
            "Epoch 59/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6115 - auc_8: 0.6271 - binary_accuracy: 0.6676 - val_loss: 0.6051 - val_auc_8: 0.6331 - val_binary_accuracy: 0.6756\n",
            "Epoch 60/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6095 - auc_8: 0.6327 - binary_accuracy: 0.6736 - val_loss: 0.6034 - val_auc_8: 0.6392 - val_binary_accuracy: 0.6863\n",
            "Epoch 61/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6062 - auc_8: 0.6428 - binary_accuracy: 0.6723 - val_loss: 0.6040 - val_auc_8: 0.6398 - val_binary_accuracy: 0.6836\n",
            "Epoch 62/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6057 - auc_8: 0.6417 - binary_accuracy: 0.6763 - val_loss: 0.6046 - val_auc_8: 0.6355 - val_binary_accuracy: 0.6810\n",
            "Epoch 63/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6074 - auc_8: 0.6375 - binary_accuracy: 0.6783 - val_loss: 0.6049 - val_auc_8: 0.6350 - val_binary_accuracy: 0.6810\n",
            "Epoch 64/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6100 - auc_8: 0.6338 - binary_accuracy: 0.6696 - val_loss: 0.6045 - val_auc_8: 0.6371 - val_binary_accuracy: 0.6810\n",
            "Epoch 65/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6060 - auc_8: 0.6438 - binary_accuracy: 0.6716 - val_loss: 0.6033 - val_auc_8: 0.6393 - val_binary_accuracy: 0.6836\n",
            "Epoch 66/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6081 - auc_8: 0.6365 - binary_accuracy: 0.6776 - val_loss: 0.6044 - val_auc_8: 0.6362 - val_binary_accuracy: 0.6810\n",
            "Epoch 67/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6038 - auc_8: 0.6469 - binary_accuracy: 0.6676 - val_loss: 0.6040 - val_auc_8: 0.6399 - val_binary_accuracy: 0.6863\n",
            "Epoch 68/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6077 - auc_8: 0.6369 - binary_accuracy: 0.6783 - val_loss: 0.6042 - val_auc_8: 0.6375 - val_binary_accuracy: 0.6836\n",
            "Epoch 69/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6038 - auc_8: 0.6451 - binary_accuracy: 0.6729 - val_loss: 0.6038 - val_auc_8: 0.6387 - val_binary_accuracy: 0.6863\n",
            "Epoch 70/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6064 - auc_8: 0.6392 - binary_accuracy: 0.6790 - val_loss: 0.6047 - val_auc_8: 0.6373 - val_binary_accuracy: 0.6917\n",
            "Epoch 71/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6069 - auc_8: 0.6415 - binary_accuracy: 0.6709 - val_loss: 0.6044 - val_auc_8: 0.6382 - val_binary_accuracy: 0.6810\n",
            "Epoch 72/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6073 - auc_8: 0.6388 - binary_accuracy: 0.6696 - val_loss: 0.6037 - val_auc_8: 0.6409 - val_binary_accuracy: 0.6863\n",
            "Epoch 73/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6037 - auc_8: 0.6435 - binary_accuracy: 0.6669 - val_loss: 0.6041 - val_auc_8: 0.6382 - val_binary_accuracy: 0.6836\n",
            "Epoch 74/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6040 - auc_8: 0.6424 - binary_accuracy: 0.6763 - val_loss: 0.6037 - val_auc_8: 0.6389 - val_binary_accuracy: 0.6863\n",
            "Epoch 75/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6058 - auc_8: 0.6411 - binary_accuracy: 0.6763 - val_loss: 0.6038 - val_auc_8: 0.6399 - val_binary_accuracy: 0.6810\n",
            "Epoch 76/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6041 - auc_8: 0.6439 - binary_accuracy: 0.6763 - val_loss: 0.6034 - val_auc_8: 0.6408 - val_binary_accuracy: 0.6890\n",
            "Epoch 77/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6047 - auc_8: 0.6429 - binary_accuracy: 0.6736 - val_loss: 0.6044 - val_auc_8: 0.6371 - val_binary_accuracy: 0.6836\n",
            "Epoch 78/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6055 - auc_8: 0.6446 - binary_accuracy: 0.6723 - val_loss: 0.6042 - val_auc_8: 0.6392 - val_binary_accuracy: 0.6810\n",
            "Epoch 79/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6037 - auc_8: 0.6446 - binary_accuracy: 0.6803 - val_loss: 0.6037 - val_auc_8: 0.6381 - val_binary_accuracy: 0.6917\n",
            "Epoch 80/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6000 - auc_8: 0.6546 - binary_accuracy: 0.6864 - val_loss: 0.6028 - val_auc_8: 0.6440 - val_binary_accuracy: 0.6890\n",
            "Epoch 81/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6042 - auc_8: 0.6465 - binary_accuracy: 0.6797 - val_loss: 0.6030 - val_auc_8: 0.6397 - val_binary_accuracy: 0.6863\n",
            "Epoch 82/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6028 - auc_8: 0.6468 - binary_accuracy: 0.6743 - val_loss: 0.6046 - val_auc_8: 0.6352 - val_binary_accuracy: 0.6783\n",
            "Epoch 83/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5997 - auc_8: 0.6533 - binary_accuracy: 0.6770 - val_loss: 0.6035 - val_auc_8: 0.6368 - val_binary_accuracy: 0.6890\n",
            "Epoch 84/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6018 - auc_8: 0.6491 - binary_accuracy: 0.6682 - val_loss: 0.6039 - val_auc_8: 0.6368 - val_binary_accuracy: 0.6917\n",
            "Epoch 85/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6008 - auc_8: 0.6490 - binary_accuracy: 0.6763 - val_loss: 0.6040 - val_auc_8: 0.6344 - val_binary_accuracy: 0.6890\n",
            "Epoch 86/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6033 - auc_8: 0.6438 - binary_accuracy: 0.6743 - val_loss: 0.6052 - val_auc_8: 0.6316 - val_binary_accuracy: 0.6756\n",
            "Epoch 87/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6029 - auc_8: 0.6454 - binary_accuracy: 0.6729 - val_loss: 0.6043 - val_auc_8: 0.6341 - val_binary_accuracy: 0.6890\n",
            "Epoch 88/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5999 - auc_8: 0.6528 - binary_accuracy: 0.6736 - val_loss: 0.6032 - val_auc_8: 0.6369 - val_binary_accuracy: 0.6863\n",
            "Epoch 89/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5977 - auc_8: 0.6593 - binary_accuracy: 0.6776 - val_loss: 0.6042 - val_auc_8: 0.6361 - val_binary_accuracy: 0.6890\n",
            "Epoch 90/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5997 - auc_8: 0.6576 - binary_accuracy: 0.6716 - val_loss: 0.6035 - val_auc_8: 0.6375 - val_binary_accuracy: 0.6917\n",
            "Epoch 91/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5991 - auc_8: 0.6534 - binary_accuracy: 0.6870 - val_loss: 0.6050 - val_auc_8: 0.6346 - val_binary_accuracy: 0.6917\n",
            "Epoch 92/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6022 - auc_8: 0.6511 - binary_accuracy: 0.6709 - val_loss: 0.6041 - val_auc_8: 0.6361 - val_binary_accuracy: 0.6890\n",
            "Epoch 93/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6012 - auc_8: 0.6446 - binary_accuracy: 0.6776 - val_loss: 0.6041 - val_auc_8: 0.6366 - val_binary_accuracy: 0.6917\n",
            "Epoch 94/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5993 - auc_8: 0.6581 - binary_accuracy: 0.6783 - val_loss: 0.6039 - val_auc_8: 0.6377 - val_binary_accuracy: 0.6917\n",
            "Epoch 95/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5970 - auc_8: 0.6546 - binary_accuracy: 0.6797 - val_loss: 0.6032 - val_auc_8: 0.6381 - val_binary_accuracy: 0.6863\n",
            "Epoch 96/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6043 - auc_8: 0.6456 - binary_accuracy: 0.6749 - val_loss: 0.6034 - val_auc_8: 0.6369 - val_binary_accuracy: 0.6890\n",
            "Epoch 97/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5989 - auc_8: 0.6553 - binary_accuracy: 0.6749 - val_loss: 0.6045 - val_auc_8: 0.6351 - val_binary_accuracy: 0.6890\n",
            "Epoch 98/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5994 - auc_8: 0.6529 - binary_accuracy: 0.6823 - val_loss: 0.6035 - val_auc_8: 0.6389 - val_binary_accuracy: 0.6890\n",
            "Epoch 99/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5999 - auc_8: 0.6518 - binary_accuracy: 0.6729 - val_loss: 0.6043 - val_auc_8: 0.6374 - val_binary_accuracy: 0.6863\n",
            "Epoch 100/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5943 - auc_8: 0.6644 - binary_accuracy: 0.6729 - val_loss: 0.6028 - val_auc_8: 0.6440 - val_binary_accuracy: 0.6863\n",
            "Epoch 101/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5980 - auc_8: 0.6561 - binary_accuracy: 0.6864 - val_loss: 0.6032 - val_auc_8: 0.6403 - val_binary_accuracy: 0.6890\n",
            "Epoch 102/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5942 - auc_8: 0.6667 - binary_accuracy: 0.6823 - val_loss: 0.6041 - val_auc_8: 0.6390 - val_binary_accuracy: 0.6863\n",
            "Epoch 103/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5972 - auc_8: 0.6556 - binary_accuracy: 0.6783 - val_loss: 0.6039 - val_auc_8: 0.6398 - val_binary_accuracy: 0.6917\n",
            "Epoch 104/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5994 - auc_8: 0.6512 - binary_accuracy: 0.6770 - val_loss: 0.6013 - val_auc_8: 0.6460 - val_binary_accuracy: 0.6836\n",
            "Epoch 105/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5998 - auc_8: 0.6438 - binary_accuracy: 0.6817 - val_loss: 0.6020 - val_auc_8: 0.6447 - val_binary_accuracy: 0.6836\n",
            "Epoch 106/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5965 - auc_8: 0.6599 - binary_accuracy: 0.6736 - val_loss: 0.6024 - val_auc_8: 0.6459 - val_binary_accuracy: 0.6917\n",
            "Epoch 107/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5960 - auc_8: 0.6612 - binary_accuracy: 0.6770 - val_loss: 0.6021 - val_auc_8: 0.6470 - val_binary_accuracy: 0.6917\n",
            "Epoch 108/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5965 - auc_8: 0.6578 - binary_accuracy: 0.6716 - val_loss: 0.6009 - val_auc_8: 0.6488 - val_binary_accuracy: 0.6917\n",
            "Epoch 109/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5930 - auc_8: 0.6640 - binary_accuracy: 0.6817 - val_loss: 0.6025 - val_auc_8: 0.6468 - val_binary_accuracy: 0.6917\n",
            "Epoch 110/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6021 - auc_8: 0.6408 - binary_accuracy: 0.6810 - val_loss: 0.6030 - val_auc_8: 0.6449 - val_binary_accuracy: 0.6944\n",
            "Epoch 111/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5931 - auc_8: 0.6686 - binary_accuracy: 0.6756 - val_loss: 0.6032 - val_auc_8: 0.6450 - val_binary_accuracy: 0.6944\n",
            "Epoch 112/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5960 - auc_8: 0.6634 - binary_accuracy: 0.6763 - val_loss: 0.6048 - val_auc_8: 0.6412 - val_binary_accuracy: 0.6917\n",
            "Epoch 113/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5953 - auc_8: 0.6618 - binary_accuracy: 0.6790 - val_loss: 0.6031 - val_auc_8: 0.6446 - val_binary_accuracy: 0.6944\n",
            "Epoch 114/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5927 - auc_8: 0.6669 - binary_accuracy: 0.6817 - val_loss: 0.6024 - val_auc_8: 0.6469 - val_binary_accuracy: 0.6944\n",
            "Epoch 115/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5974 - auc_8: 0.6576 - binary_accuracy: 0.6716 - val_loss: 0.6009 - val_auc_8: 0.6483 - val_binary_accuracy: 0.6917\n",
            "Epoch 116/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5968 - auc_8: 0.6635 - binary_accuracy: 0.6723 - val_loss: 0.6014 - val_auc_8: 0.6466 - val_binary_accuracy: 0.6917\n",
            "Epoch 117/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5953 - auc_8: 0.6626 - binary_accuracy: 0.6790 - val_loss: 0.6022 - val_auc_8: 0.6475 - val_binary_accuracy: 0.6944\n",
            "Epoch 118/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5929 - auc_8: 0.6647 - binary_accuracy: 0.6776 - val_loss: 0.6021 - val_auc_8: 0.6496 - val_binary_accuracy: 0.6944\n",
            "Epoch 119/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5945 - auc_8: 0.6651 - binary_accuracy: 0.6723 - val_loss: 0.6035 - val_auc_8: 0.6465 - val_binary_accuracy: 0.6917\n",
            "Epoch 120/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5933 - auc_8: 0.6640 - binary_accuracy: 0.6803 - val_loss: 0.6016 - val_auc_8: 0.6510 - val_binary_accuracy: 0.6890\n",
            "Epoch 121/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5925 - auc_8: 0.6677 - binary_accuracy: 0.6736 - val_loss: 0.6017 - val_auc_8: 0.6506 - val_binary_accuracy: 0.6944\n",
            "Epoch 122/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5925 - auc_8: 0.6698 - binary_accuracy: 0.6763 - val_loss: 0.6029 - val_auc_8: 0.6487 - val_binary_accuracy: 0.6944\n",
            "Epoch 123/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5909 - auc_8: 0.6712 - binary_accuracy: 0.6763 - val_loss: 0.6025 - val_auc_8: 0.6509 - val_binary_accuracy: 0.6944\n",
            "Epoch 124/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5955 - auc_8: 0.6607 - binary_accuracy: 0.6783 - val_loss: 0.6018 - val_auc_8: 0.6496 - val_binary_accuracy: 0.6971\n",
            "Epoch 125/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5922 - auc_8: 0.6686 - binary_accuracy: 0.6763 - val_loss: 0.6025 - val_auc_8: 0.6501 - val_binary_accuracy: 0.6971\n",
            "Epoch 126/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5931 - auc_8: 0.6650 - binary_accuracy: 0.6790 - val_loss: 0.6018 - val_auc_8: 0.6508 - val_binary_accuracy: 0.6944\n",
            "Epoch 127/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5925 - auc_8: 0.6687 - binary_accuracy: 0.6803 - val_loss: 0.6035 - val_auc_8: 0.6492 - val_binary_accuracy: 0.6971\n",
            "Epoch 128/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5929 - auc_8: 0.6604 - binary_accuracy: 0.6770 - val_loss: 0.6020 - val_auc_8: 0.6525 - val_binary_accuracy: 0.6997\n",
            "Epoch 129/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5905 - auc_8: 0.6699 - binary_accuracy: 0.6810 - val_loss: 0.6021 - val_auc_8: 0.6530 - val_binary_accuracy: 0.6890\n",
            "Epoch 130/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5920 - auc_8: 0.6679 - binary_accuracy: 0.6696 - val_loss: 0.6026 - val_auc_8: 0.6506 - val_binary_accuracy: 0.6997\n",
            "Epoch 131/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5938 - auc_8: 0.6629 - binary_accuracy: 0.6756 - val_loss: 0.6035 - val_auc_8: 0.6479 - val_binary_accuracy: 0.6944\n",
            "Epoch 132/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5973 - auc_8: 0.6542 - binary_accuracy: 0.6756 - val_loss: 0.6027 - val_auc_8: 0.6501 - val_binary_accuracy: 0.6997\n",
            "Epoch 133/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5902 - auc_8: 0.6691 - binary_accuracy: 0.6823 - val_loss: 0.6032 - val_auc_8: 0.6494 - val_binary_accuracy: 0.6944\n",
            "Epoch 134/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5879 - auc_8: 0.6772 - binary_accuracy: 0.6850 - val_loss: 0.6013 - val_auc_8: 0.6537 - val_binary_accuracy: 0.6917\n",
            "Epoch 135/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5868 - auc_8: 0.6734 - binary_accuracy: 0.6797 - val_loss: 0.6037 - val_auc_8: 0.6489 - val_binary_accuracy: 0.6944\n",
            "Epoch 136/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5892 - auc_8: 0.6746 - binary_accuracy: 0.6817 - val_loss: 0.6045 - val_auc_8: 0.6467 - val_binary_accuracy: 0.6944\n",
            "Epoch 137/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5946 - auc_8: 0.6649 - binary_accuracy: 0.6770 - val_loss: 0.6033 - val_auc_8: 0.6533 - val_binary_accuracy: 0.6917\n",
            "Epoch 138/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5899 - auc_8: 0.6770 - binary_accuracy: 0.6864 - val_loss: 0.6032 - val_auc_8: 0.6493 - val_binary_accuracy: 0.6944\n",
            "Epoch 139/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5894 - auc_8: 0.6752 - binary_accuracy: 0.6810 - val_loss: 0.6024 - val_auc_8: 0.6532 - val_binary_accuracy: 0.6971\n",
            "Epoch 140/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5897 - auc_8: 0.6667 - binary_accuracy: 0.6770 - val_loss: 0.6033 - val_auc_8: 0.6502 - val_binary_accuracy: 0.6890\n",
            "Epoch 141/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5898 - auc_8: 0.6730 - binary_accuracy: 0.6830 - val_loss: 0.6010 - val_auc_8: 0.6563 - val_binary_accuracy: 0.6917\n",
            "Epoch 142/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5881 - auc_8: 0.6784 - binary_accuracy: 0.6830 - val_loss: 0.6015 - val_auc_8: 0.6558 - val_binary_accuracy: 0.6917\n",
            "Epoch 143/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5849 - auc_8: 0.6833 - binary_accuracy: 0.6837 - val_loss: 0.6037 - val_auc_8: 0.6532 - val_binary_accuracy: 0.6971\n",
            "Epoch 144/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5852 - auc_8: 0.6826 - binary_accuracy: 0.6810 - val_loss: 0.6012 - val_auc_8: 0.6576 - val_binary_accuracy: 0.6917\n",
            "Epoch 145/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5848 - auc_8: 0.6785 - binary_accuracy: 0.6850 - val_loss: 0.6010 - val_auc_8: 0.6594 - val_binary_accuracy: 0.6971\n",
            "Epoch 146/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5821 - auc_8: 0.6862 - binary_accuracy: 0.6904 - val_loss: 0.6024 - val_auc_8: 0.6554 - val_binary_accuracy: 0.6944\n",
            "Epoch 147/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5855 - auc_8: 0.6810 - binary_accuracy: 0.6797 - val_loss: 0.6008 - val_auc_8: 0.6596 - val_binary_accuracy: 0.6917\n",
            "Epoch 148/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5862 - auc_8: 0.6769 - binary_accuracy: 0.6776 - val_loss: 0.6018 - val_auc_8: 0.6589 - val_binary_accuracy: 0.6944\n",
            "Epoch 149/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5880 - auc_8: 0.6776 - binary_accuracy: 0.6803 - val_loss: 0.6012 - val_auc_8: 0.6575 - val_binary_accuracy: 0.6944\n",
            "Epoch 150/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5838 - auc_8: 0.6820 - binary_accuracy: 0.6917 - val_loss: 0.6024 - val_auc_8: 0.6575 - val_binary_accuracy: 0.6971\n",
            "Epoch 151/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5883 - auc_8: 0.6800 - binary_accuracy: 0.6783 - val_loss: 0.5999 - val_auc_8: 0.6606 - val_binary_accuracy: 0.6890\n",
            "Epoch 152/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5895 - auc_8: 0.6644 - binary_accuracy: 0.6783 - val_loss: 0.6018 - val_auc_8: 0.6579 - val_binary_accuracy: 0.6971\n",
            "Epoch 153/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5830 - auc_8: 0.6847 - binary_accuracy: 0.6810 - val_loss: 0.6013 - val_auc_8: 0.6593 - val_binary_accuracy: 0.6890\n",
            "Epoch 154/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5827 - auc_8: 0.6864 - binary_accuracy: 0.6924 - val_loss: 0.6034 - val_auc_8: 0.6559 - val_binary_accuracy: 0.6944\n",
            "Epoch 155/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5814 - auc_8: 0.6899 - binary_accuracy: 0.6877 - val_loss: 0.6025 - val_auc_8: 0.6584 - val_binary_accuracy: 0.6944\n",
            "Epoch 156/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5843 - auc_8: 0.6861 - binary_accuracy: 0.6844 - val_loss: 0.6027 - val_auc_8: 0.6554 - val_binary_accuracy: 0.6917\n",
            "Epoch 157/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5862 - auc_8: 0.6747 - binary_accuracy: 0.6830 - val_loss: 0.6025 - val_auc_8: 0.6557 - val_binary_accuracy: 0.6971\n",
            "Epoch 158/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5806 - auc_8: 0.6923 - binary_accuracy: 0.6823 - val_loss: 0.6015 - val_auc_8: 0.6585 - val_binary_accuracy: 0.6944\n",
            "Epoch 159/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5821 - auc_8: 0.6844 - binary_accuracy: 0.6844 - val_loss: 0.6042 - val_auc_8: 0.6548 - val_binary_accuracy: 0.6971\n",
            "Epoch 160/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5790 - auc_8: 0.6924 - binary_accuracy: 0.6884 - val_loss: 0.6054 - val_auc_8: 0.6535 - val_binary_accuracy: 0.6890\n",
            "Epoch 161/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5838 - auc_8: 0.6820 - binary_accuracy: 0.6830 - val_loss: 0.6048 - val_auc_8: 0.6553 - val_binary_accuracy: 0.6971\n",
            "Epoch 162/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5788 - auc_8: 0.6964 - binary_accuracy: 0.6911 - val_loss: 0.6044 - val_auc_8: 0.6555 - val_binary_accuracy: 0.6944\n",
            "Epoch 163/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5803 - auc_8: 0.6836 - binary_accuracy: 0.6904 - val_loss: 0.6051 - val_auc_8: 0.6549 - val_binary_accuracy: 0.6863\n",
            "Epoch 164/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5856 - auc_8: 0.6769 - binary_accuracy: 0.6797 - val_loss: 0.6055 - val_auc_8: 0.6549 - val_binary_accuracy: 0.6890\n",
            "Epoch 165/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5758 - auc_8: 0.6979 - binary_accuracy: 0.6911 - val_loss: 0.6046 - val_auc_8: 0.6553 - val_binary_accuracy: 0.6944\n",
            "Epoch 166/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5802 - auc_8: 0.6917 - binary_accuracy: 0.6891 - val_loss: 0.6064 - val_auc_8: 0.6521 - val_binary_accuracy: 0.6863\n",
            "Epoch 167/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5848 - auc_8: 0.6849 - binary_accuracy: 0.6817 - val_loss: 0.6045 - val_auc_8: 0.6556 - val_binary_accuracy: 0.6944\n",
            "Epoch 168/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5775 - auc_8: 0.6931 - binary_accuracy: 0.6803 - val_loss: 0.6051 - val_auc_8: 0.6564 - val_binary_accuracy: 0.6917\n",
            "Epoch 169/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5771 - auc_8: 0.7007 - binary_accuracy: 0.6891 - val_loss: 0.6061 - val_auc_8: 0.6547 - val_binary_accuracy: 0.6836\n",
            "Epoch 170/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5813 - auc_8: 0.6871 - binary_accuracy: 0.6837 - val_loss: 0.6054 - val_auc_8: 0.6549 - val_binary_accuracy: 0.6890\n",
            "Epoch 171/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5795 - auc_8: 0.6941 - binary_accuracy: 0.6944 - val_loss: 0.6069 - val_auc_8: 0.6527 - val_binary_accuracy: 0.6917\n",
            "Epoch 172/200\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 0.5769 - auc_8: 0.6984 - binary_accuracy: 0.6904 - val_loss: 0.6051 - val_auc_8: 0.6574 - val_binary_accuracy: 0.6863\n",
            "Epoch 173/200\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 0.5806 - auc_8: 0.6933 - binary_accuracy: 0.6877 - val_loss: 0.6071 - val_auc_8: 0.6529 - val_binary_accuracy: 0.6890\n",
            "Epoch 174/200\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 0.5757 - auc_8: 0.7048 - binary_accuracy: 0.6857 - val_loss: 0.6063 - val_auc_8: 0.6561 - val_binary_accuracy: 0.6917\n",
            "Epoch 175/200\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 0.5756 - auc_8: 0.6983 - binary_accuracy: 0.6938 - val_loss: 0.6072 - val_auc_8: 0.6559 - val_binary_accuracy: 0.6917\n",
            "Epoch 176/200\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 0.5813 - auc_8: 0.6822 - binary_accuracy: 0.6810 - val_loss: 0.6072 - val_auc_8: 0.6530 - val_binary_accuracy: 0.6917\n",
            "Epoch 177/200\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 0.5754 - auc_8: 0.7003 - binary_accuracy: 0.6870 - val_loss: 0.6083 - val_auc_8: 0.6514 - val_binary_accuracy: 0.6917\n",
            "Epoch 178/200\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 0.5761 - auc_8: 0.7004 - binary_accuracy: 0.6884 - val_loss: 0.6079 - val_auc_8: 0.6528 - val_binary_accuracy: 0.6917\n",
            "Epoch 179/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5720 - auc_8: 0.7047 - binary_accuracy: 0.6877 - val_loss: 0.6094 - val_auc_8: 0.6528 - val_binary_accuracy: 0.6944\n",
            "Epoch 180/200\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 0.5725 - auc_8: 0.7040 - binary_accuracy: 0.6958 - val_loss: 0.6085 - val_auc_8: 0.6530 - val_binary_accuracy: 0.6836\n",
            "Epoch 181/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5725 - auc_8: 0.7071 - binary_accuracy: 0.6864 - val_loss: 0.6112 - val_auc_8: 0.6463 - val_binary_accuracy: 0.6890\n",
            "Epoch 182/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5714 - auc_8: 0.7039 - binary_accuracy: 0.6917 - val_loss: 0.6107 - val_auc_8: 0.6484 - val_binary_accuracy: 0.6917\n",
            "Epoch 183/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5720 - auc_8: 0.7058 - binary_accuracy: 0.6897 - val_loss: 0.6116 - val_auc_8: 0.6484 - val_binary_accuracy: 0.6836\n",
            "Epoch 184/200\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 0.5753 - auc_8: 0.6951 - binary_accuracy: 0.6917 - val_loss: 0.6104 - val_auc_8: 0.6491 - val_binary_accuracy: 0.6890\n",
            "Epoch 185/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5771 - auc_8: 0.6904 - binary_accuracy: 0.6884 - val_loss: 0.6104 - val_auc_8: 0.6484 - val_binary_accuracy: 0.6863\n",
            "Epoch 186/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5771 - auc_8: 0.6937 - binary_accuracy: 0.6877 - val_loss: 0.6090 - val_auc_8: 0.6522 - val_binary_accuracy: 0.6863\n",
            "Epoch 187/200\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 0.5782 - auc_8: 0.6944 - binary_accuracy: 0.6837 - val_loss: 0.6107 - val_auc_8: 0.6492 - val_binary_accuracy: 0.6863\n",
            "Epoch 188/200\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 0.5705 - auc_8: 0.7057 - binary_accuracy: 0.6971 - val_loss: 0.6112 - val_auc_8: 0.6520 - val_binary_accuracy: 0.6917\n",
            "Epoch 189/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5777 - auc_8: 0.7010 - binary_accuracy: 0.6938 - val_loss: 0.6119 - val_auc_8: 0.6496 - val_binary_accuracy: 0.6836\n",
            "Epoch 190/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5753 - auc_8: 0.7010 - binary_accuracy: 0.6964 - val_loss: 0.6069 - val_auc_8: 0.6546 - val_binary_accuracy: 0.6836\n",
            "Epoch 191/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5735 - auc_8: 0.7047 - binary_accuracy: 0.6870 - val_loss: 0.6104 - val_auc_8: 0.6502 - val_binary_accuracy: 0.6890\n",
            "Epoch 192/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5718 - auc_8: 0.7028 - binary_accuracy: 0.6783 - val_loss: 0.6104 - val_auc_8: 0.6482 - val_binary_accuracy: 0.6836\n",
            "Epoch 193/200\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 0.5698 - auc_8: 0.7089 - binary_accuracy: 0.6964 - val_loss: 0.6101 - val_auc_8: 0.6518 - val_binary_accuracy: 0.6836\n",
            "Epoch 194/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5731 - auc_8: 0.7028 - binary_accuracy: 0.6917 - val_loss: 0.6106 - val_auc_8: 0.6513 - val_binary_accuracy: 0.6863\n",
            "Epoch 195/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5690 - auc_8: 0.7117 - binary_accuracy: 0.6931 - val_loss: 0.6119 - val_auc_8: 0.6497 - val_binary_accuracy: 0.6810\n",
            "Epoch 196/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5696 - auc_8: 0.7095 - binary_accuracy: 0.6904 - val_loss: 0.6104 - val_auc_8: 0.6505 - val_binary_accuracy: 0.6810\n",
            "Epoch 197/200\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 0.5681 - auc_8: 0.7095 - binary_accuracy: 0.6971 - val_loss: 0.6112 - val_auc_8: 0.6507 - val_binary_accuracy: 0.6863\n",
            "Epoch 198/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5757 - auc_8: 0.6911 - binary_accuracy: 0.6904 - val_loss: 0.6131 - val_auc_8: 0.6484 - val_binary_accuracy: 0.6863\n",
            "Epoch 199/200\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 0.5725 - auc_8: 0.7067 - binary_accuracy: 0.7045 - val_loss: 0.6110 - val_auc_8: 0.6503 - val_binary_accuracy: 0.6836\n",
            "Epoch 200/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5672 - auc_8: 0.7169 - binary_accuracy: 0.7005 - val_loss: 0.6122 - val_auc_8: 0.6486 - val_binary_accuracy: 0.6836\n",
            "Epoch 1/200\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
            "47/47 [==============================] - 4s 20ms/step - loss: 0.6791 - auc_9: 0.5085 - binary_accuracy: 0.5756 - val_loss: 0.6530 - val_auc_9: 0.5452 - val_binary_accuracy: 0.6595\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6414 - auc_9: 0.5484 - binary_accuracy: 0.6662 - val_loss: 0.6208 - val_auc_9: 0.6106 - val_binary_accuracy: 0.6676\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6272 - auc_9: 0.5838 - binary_accuracy: 0.6662 - val_loss: 0.6153 - val_auc_9: 0.6230 - val_binary_accuracy: 0.6676\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6238 - auc_9: 0.5906 - binary_accuracy: 0.6662 - val_loss: 0.6129 - val_auc_9: 0.6321 - val_binary_accuracy: 0.6676\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6215 - auc_9: 0.5945 - binary_accuracy: 0.6662 - val_loss: 0.6104 - val_auc_9: 0.6348 - val_binary_accuracy: 0.6676\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6208 - auc_9: 0.6006 - binary_accuracy: 0.6662 - val_loss: 0.6098 - val_auc_9: 0.6367 - val_binary_accuracy: 0.6676\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6216 - auc_9: 0.6016 - binary_accuracy: 0.6662 - val_loss: 0.6091 - val_auc_9: 0.6463 - val_binary_accuracy: 0.6676\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6200 - auc_9: 0.6034 - binary_accuracy: 0.6662 - val_loss: 0.6083 - val_auc_9: 0.6431 - val_binary_accuracy: 0.6676\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6195 - auc_9: 0.6106 - binary_accuracy: 0.6662 - val_loss: 0.6084 - val_auc_9: 0.6467 - val_binary_accuracy: 0.6676\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6197 - auc_9: 0.6056 - binary_accuracy: 0.6662 - val_loss: 0.6084 - val_auc_9: 0.6428 - val_binary_accuracy: 0.6676\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6210 - auc_9: 0.6052 - binary_accuracy: 0.6662 - val_loss: 0.6071 - val_auc_9: 0.6490 - val_binary_accuracy: 0.6676\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6190 - auc_9: 0.6095 - binary_accuracy: 0.6655 - val_loss: 0.6079 - val_auc_9: 0.6484 - val_binary_accuracy: 0.6676\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6179 - auc_9: 0.6092 - binary_accuracy: 0.6662 - val_loss: 0.6076 - val_auc_9: 0.6478 - val_binary_accuracy: 0.6676\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6194 - auc_9: 0.6059 - binary_accuracy: 0.6662 - val_loss: 0.6089 - val_auc_9: 0.6438 - val_binary_accuracy: 0.6676\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6180 - auc_9: 0.6107 - binary_accuracy: 0.6676 - val_loss: 0.6079 - val_auc_9: 0.6441 - val_binary_accuracy: 0.6676\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6167 - auc_9: 0.6126 - binary_accuracy: 0.6662 - val_loss: 0.6079 - val_auc_9: 0.6438 - val_binary_accuracy: 0.6676\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6194 - auc_9: 0.6063 - binary_accuracy: 0.6635 - val_loss: 0.6080 - val_auc_9: 0.6416 - val_binary_accuracy: 0.6676\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6183 - auc_9: 0.6087 - binary_accuracy: 0.6608 - val_loss: 0.6075 - val_auc_9: 0.6435 - val_binary_accuracy: 0.6702\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6172 - auc_9: 0.6130 - binary_accuracy: 0.6642 - val_loss: 0.6090 - val_auc_9: 0.6353 - val_binary_accuracy: 0.6676\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6152 - auc_9: 0.6182 - binary_accuracy: 0.6602 - val_loss: 0.6072 - val_auc_9: 0.6392 - val_binary_accuracy: 0.6810\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6132 - auc_9: 0.6283 - binary_accuracy: 0.6655 - val_loss: 0.6085 - val_auc_9: 0.6339 - val_binary_accuracy: 0.6702\n",
            "Epoch 22/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6154 - auc_9: 0.6202 - binary_accuracy: 0.6662 - val_loss: 0.6106 - val_auc_9: 0.6289 - val_binary_accuracy: 0.6676\n",
            "Epoch 23/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6151 - auc_9: 0.6077 - binary_accuracy: 0.6649 - val_loss: 0.6095 - val_auc_9: 0.6280 - val_binary_accuracy: 0.6676\n",
            "Epoch 24/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6133 - auc_9: 0.6208 - binary_accuracy: 0.6682 - val_loss: 0.6096 - val_auc_9: 0.6287 - val_binary_accuracy: 0.6729\n",
            "Epoch 25/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6153 - auc_9: 0.6159 - binary_accuracy: 0.6682 - val_loss: 0.6105 - val_auc_9: 0.6231 - val_binary_accuracy: 0.6702\n",
            "Epoch 26/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6123 - auc_9: 0.6250 - binary_accuracy: 0.6723 - val_loss: 0.6091 - val_auc_9: 0.6297 - val_binary_accuracy: 0.6810\n",
            "Epoch 27/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6119 - auc_9: 0.6209 - binary_accuracy: 0.6716 - val_loss: 0.6106 - val_auc_9: 0.6215 - val_binary_accuracy: 0.6702\n",
            "Epoch 28/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6127 - auc_9: 0.6179 - binary_accuracy: 0.6729 - val_loss: 0.6103 - val_auc_9: 0.6242 - val_binary_accuracy: 0.6649\n",
            "Epoch 29/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6126 - auc_9: 0.6224 - binary_accuracy: 0.6709 - val_loss: 0.6112 - val_auc_9: 0.6204 - val_binary_accuracy: 0.6702\n",
            "Epoch 30/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6145 - auc_9: 0.6156 - binary_accuracy: 0.6649 - val_loss: 0.6093 - val_auc_9: 0.6250 - val_binary_accuracy: 0.6810\n",
            "Epoch 31/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6107 - auc_9: 0.6315 - binary_accuracy: 0.6689 - val_loss: 0.6100 - val_auc_9: 0.6263 - val_binary_accuracy: 0.6649\n",
            "Epoch 32/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6136 - auc_9: 0.6223 - binary_accuracy: 0.6615 - val_loss: 0.6108 - val_auc_9: 0.6226 - val_binary_accuracy: 0.6676\n",
            "Epoch 33/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6134 - auc_9: 0.6176 - binary_accuracy: 0.6696 - val_loss: 0.6102 - val_auc_9: 0.6218 - val_binary_accuracy: 0.6676\n",
            "Epoch 34/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6118 - auc_9: 0.6254 - binary_accuracy: 0.6635 - val_loss: 0.6097 - val_auc_9: 0.6237 - val_binary_accuracy: 0.6756\n",
            "Epoch 35/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6126 - auc_9: 0.6204 - binary_accuracy: 0.6662 - val_loss: 0.6108 - val_auc_9: 0.6201 - val_binary_accuracy: 0.6783\n",
            "Epoch 36/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6085 - auc_9: 0.6340 - binary_accuracy: 0.6729 - val_loss: 0.6101 - val_auc_9: 0.6244 - val_binary_accuracy: 0.6783\n",
            "Epoch 37/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6108 - auc_9: 0.6264 - binary_accuracy: 0.6743 - val_loss: 0.6106 - val_auc_9: 0.6256 - val_binary_accuracy: 0.6649\n",
            "Epoch 38/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6106 - auc_9: 0.6363 - binary_accuracy: 0.6696 - val_loss: 0.6105 - val_auc_9: 0.6280 - val_binary_accuracy: 0.6836\n",
            "Epoch 39/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6109 - auc_9: 0.6325 - binary_accuracy: 0.6702 - val_loss: 0.6091 - val_auc_9: 0.6303 - val_binary_accuracy: 0.6810\n",
            "Epoch 40/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6097 - auc_9: 0.6286 - binary_accuracy: 0.6716 - val_loss: 0.6109 - val_auc_9: 0.6207 - val_binary_accuracy: 0.6676\n",
            "Epoch 41/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6074 - auc_9: 0.6370 - binary_accuracy: 0.6709 - val_loss: 0.6087 - val_auc_9: 0.6313 - val_binary_accuracy: 0.6783\n",
            "Epoch 42/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6077 - auc_9: 0.6382 - binary_accuracy: 0.6723 - val_loss: 0.6100 - val_auc_9: 0.6262 - val_binary_accuracy: 0.6810\n",
            "Epoch 43/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6096 - auc_9: 0.6263 - binary_accuracy: 0.6729 - val_loss: 0.6091 - val_auc_9: 0.6299 - val_binary_accuracy: 0.6836\n",
            "Epoch 44/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6101 - auc_9: 0.6280 - binary_accuracy: 0.6676 - val_loss: 0.6077 - val_auc_9: 0.6357 - val_binary_accuracy: 0.6756\n",
            "Epoch 45/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6064 - auc_9: 0.6385 - binary_accuracy: 0.6810 - val_loss: 0.6094 - val_auc_9: 0.6278 - val_binary_accuracy: 0.6810\n",
            "Epoch 46/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6063 - auc_9: 0.6398 - binary_accuracy: 0.6696 - val_loss: 0.6101 - val_auc_9: 0.6251 - val_binary_accuracy: 0.6810\n",
            "Epoch 47/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6059 - auc_9: 0.6370 - binary_accuracy: 0.6676 - val_loss: 0.6099 - val_auc_9: 0.6285 - val_binary_accuracy: 0.6836\n",
            "Epoch 48/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6070 - auc_9: 0.6342 - binary_accuracy: 0.6736 - val_loss: 0.6098 - val_auc_9: 0.6270 - val_binary_accuracy: 0.6863\n",
            "Epoch 49/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6100 - auc_9: 0.6250 - binary_accuracy: 0.6729 - val_loss: 0.6095 - val_auc_9: 0.6333 - val_binary_accuracy: 0.6783\n",
            "Epoch 50/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6080 - auc_9: 0.6339 - binary_accuracy: 0.6655 - val_loss: 0.6107 - val_auc_9: 0.6266 - val_binary_accuracy: 0.6836\n",
            "Epoch 51/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6059 - auc_9: 0.6392 - binary_accuracy: 0.6770 - val_loss: 0.6114 - val_auc_9: 0.6261 - val_binary_accuracy: 0.6863\n",
            "Epoch 52/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6060 - auc_9: 0.6362 - binary_accuracy: 0.6756 - val_loss: 0.6105 - val_auc_9: 0.6270 - val_binary_accuracy: 0.6810\n",
            "Epoch 53/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6053 - auc_9: 0.6382 - binary_accuracy: 0.6749 - val_loss: 0.6113 - val_auc_9: 0.6261 - val_binary_accuracy: 0.6729\n",
            "Epoch 54/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6030 - auc_9: 0.6439 - binary_accuracy: 0.6716 - val_loss: 0.6097 - val_auc_9: 0.6306 - val_binary_accuracy: 0.6836\n",
            "Epoch 55/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6044 - auc_9: 0.6429 - binary_accuracy: 0.6743 - val_loss: 0.6106 - val_auc_9: 0.6350 - val_binary_accuracy: 0.6836\n",
            "Epoch 56/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6039 - auc_9: 0.6455 - binary_accuracy: 0.6676 - val_loss: 0.6124 - val_auc_9: 0.6279 - val_binary_accuracy: 0.6676\n",
            "Epoch 57/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6008 - auc_9: 0.6483 - binary_accuracy: 0.6783 - val_loss: 0.6126 - val_auc_9: 0.6285 - val_binary_accuracy: 0.6729\n",
            "Epoch 58/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6023 - auc_9: 0.6467 - binary_accuracy: 0.6790 - val_loss: 0.6097 - val_auc_9: 0.6370 - val_binary_accuracy: 0.6756\n",
            "Epoch 59/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5977 - auc_9: 0.6524 - binary_accuracy: 0.6817 - val_loss: 0.6117 - val_auc_9: 0.6321 - val_binary_accuracy: 0.6836\n",
            "Epoch 60/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6017 - auc_9: 0.6521 - binary_accuracy: 0.6696 - val_loss: 0.6124 - val_auc_9: 0.6311 - val_binary_accuracy: 0.6783\n",
            "Epoch 61/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6025 - auc_9: 0.6472 - binary_accuracy: 0.6702 - val_loss: 0.6129 - val_auc_9: 0.6253 - val_binary_accuracy: 0.6836\n",
            "Epoch 62/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6014 - auc_9: 0.6521 - binary_accuracy: 0.6729 - val_loss: 0.6137 - val_auc_9: 0.6282 - val_binary_accuracy: 0.6729\n",
            "Epoch 63/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6020 - auc_9: 0.6480 - binary_accuracy: 0.6749 - val_loss: 0.6124 - val_auc_9: 0.6329 - val_binary_accuracy: 0.6810\n",
            "Epoch 64/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5995 - auc_9: 0.6486 - binary_accuracy: 0.6749 - val_loss: 0.6149 - val_auc_9: 0.6234 - val_binary_accuracy: 0.6729\n",
            "Epoch 65/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5949 - auc_9: 0.6651 - binary_accuracy: 0.6743 - val_loss: 0.6132 - val_auc_9: 0.6293 - val_binary_accuracy: 0.6729\n",
            "Epoch 66/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5951 - auc_9: 0.6615 - binary_accuracy: 0.6817 - val_loss: 0.6130 - val_auc_9: 0.6314 - val_binary_accuracy: 0.6810\n",
            "Epoch 67/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5978 - auc_9: 0.6574 - binary_accuracy: 0.6763 - val_loss: 0.6142 - val_auc_9: 0.6300 - val_binary_accuracy: 0.6890\n",
            "Epoch 68/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5955 - auc_9: 0.6596 - binary_accuracy: 0.6837 - val_loss: 0.6129 - val_auc_9: 0.6362 - val_binary_accuracy: 0.6702\n",
            "Epoch 69/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5978 - auc_9: 0.6538 - binary_accuracy: 0.6756 - val_loss: 0.6147 - val_auc_9: 0.6286 - val_binary_accuracy: 0.6783\n",
            "Epoch 70/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5979 - auc_9: 0.6541 - binary_accuracy: 0.6736 - val_loss: 0.6187 - val_auc_9: 0.6178 - val_binary_accuracy: 0.6702\n",
            "Epoch 71/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5975 - auc_9: 0.6613 - binary_accuracy: 0.6716 - val_loss: 0.6153 - val_auc_9: 0.6277 - val_binary_accuracy: 0.6783\n",
            "Epoch 72/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5898 - auc_9: 0.6763 - binary_accuracy: 0.6817 - val_loss: 0.6140 - val_auc_9: 0.6366 - val_binary_accuracy: 0.6836\n",
            "Epoch 73/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5938 - auc_9: 0.6680 - binary_accuracy: 0.6729 - val_loss: 0.6146 - val_auc_9: 0.6339 - val_binary_accuracy: 0.6836\n",
            "Epoch 74/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5952 - auc_9: 0.6586 - binary_accuracy: 0.6810 - val_loss: 0.6167 - val_auc_9: 0.6280 - val_binary_accuracy: 0.6836\n",
            "Epoch 75/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5966 - auc_9: 0.6595 - binary_accuracy: 0.6857 - val_loss: 0.6169 - val_auc_9: 0.6250 - val_binary_accuracy: 0.6783\n",
            "Epoch 76/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5961 - auc_9: 0.6634 - binary_accuracy: 0.6743 - val_loss: 0.6155 - val_auc_9: 0.6333 - val_binary_accuracy: 0.6810\n",
            "Epoch 77/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5978 - auc_9: 0.6538 - binary_accuracy: 0.6749 - val_loss: 0.6156 - val_auc_9: 0.6339 - val_binary_accuracy: 0.6863\n",
            "Epoch 78/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5914 - auc_9: 0.6637 - binary_accuracy: 0.6797 - val_loss: 0.6142 - val_auc_9: 0.6322 - val_binary_accuracy: 0.6756\n",
            "Epoch 79/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5976 - auc_9: 0.6548 - binary_accuracy: 0.6749 - val_loss: 0.6162 - val_auc_9: 0.6339 - val_binary_accuracy: 0.6810\n",
            "Epoch 80/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5901 - auc_9: 0.6714 - binary_accuracy: 0.6797 - val_loss: 0.6159 - val_auc_9: 0.6338 - val_binary_accuracy: 0.6863\n",
            "Epoch 81/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5963 - auc_9: 0.6563 - binary_accuracy: 0.6830 - val_loss: 0.6186 - val_auc_9: 0.6270 - val_binary_accuracy: 0.6810\n",
            "Epoch 82/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5938 - auc_9: 0.6684 - binary_accuracy: 0.6797 - val_loss: 0.6179 - val_auc_9: 0.6280 - val_binary_accuracy: 0.6863\n",
            "Epoch 83/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5946 - auc_9: 0.6675 - binary_accuracy: 0.6736 - val_loss: 0.6178 - val_auc_9: 0.6297 - val_binary_accuracy: 0.6810\n",
            "Epoch 84/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5881 - auc_9: 0.6772 - binary_accuracy: 0.6837 - val_loss: 0.6179 - val_auc_9: 0.6304 - val_binary_accuracy: 0.6756\n",
            "Epoch 85/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5873 - auc_9: 0.6785 - binary_accuracy: 0.6844 - val_loss: 0.6191 - val_auc_9: 0.6353 - val_binary_accuracy: 0.6836\n",
            "Epoch 86/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5919 - auc_9: 0.6681 - binary_accuracy: 0.6723 - val_loss: 0.6196 - val_auc_9: 0.6280 - val_binary_accuracy: 0.6729\n",
            "Epoch 87/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5888 - auc_9: 0.6697 - binary_accuracy: 0.6844 - val_loss: 0.6175 - val_auc_9: 0.6343 - val_binary_accuracy: 0.6863\n",
            "Epoch 88/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5925 - auc_9: 0.6620 - binary_accuracy: 0.6783 - val_loss: 0.6183 - val_auc_9: 0.6307 - val_binary_accuracy: 0.6729\n",
            "Epoch 89/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5895 - auc_9: 0.6743 - binary_accuracy: 0.6797 - val_loss: 0.6182 - val_auc_9: 0.6319 - val_binary_accuracy: 0.6836\n",
            "Epoch 90/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5870 - auc_9: 0.6776 - binary_accuracy: 0.6823 - val_loss: 0.6191 - val_auc_9: 0.6344 - val_binary_accuracy: 0.6729\n",
            "Epoch 91/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5825 - auc_9: 0.6833 - binary_accuracy: 0.6877 - val_loss: 0.6189 - val_auc_9: 0.6347 - val_binary_accuracy: 0.6756\n",
            "Epoch 92/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5857 - auc_9: 0.6770 - binary_accuracy: 0.6817 - val_loss: 0.6180 - val_auc_9: 0.6369 - val_binary_accuracy: 0.6729\n",
            "Epoch 93/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5895 - auc_9: 0.6713 - binary_accuracy: 0.6817 - val_loss: 0.6230 - val_auc_9: 0.6237 - val_binary_accuracy: 0.6810\n",
            "Epoch 94/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5890 - auc_9: 0.6691 - binary_accuracy: 0.6810 - val_loss: 0.6214 - val_auc_9: 0.6280 - val_binary_accuracy: 0.6810\n",
            "Epoch 95/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5849 - auc_9: 0.6852 - binary_accuracy: 0.6864 - val_loss: 0.6190 - val_auc_9: 0.6356 - val_binary_accuracy: 0.6810\n",
            "Epoch 96/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5895 - auc_9: 0.6708 - binary_accuracy: 0.6830 - val_loss: 0.6210 - val_auc_9: 0.6187 - val_binary_accuracy: 0.6702\n",
            "Epoch 97/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5894 - auc_9: 0.6704 - binary_accuracy: 0.6837 - val_loss: 0.6199 - val_auc_9: 0.6287 - val_binary_accuracy: 0.6729\n",
            "Epoch 98/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5828 - auc_9: 0.6798 - binary_accuracy: 0.6877 - val_loss: 0.6213 - val_auc_9: 0.6273 - val_binary_accuracy: 0.6756\n",
            "Epoch 99/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5906 - auc_9: 0.6697 - binary_accuracy: 0.6776 - val_loss: 0.6231 - val_auc_9: 0.6204 - val_binary_accuracy: 0.6756\n",
            "Epoch 100/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5826 - auc_9: 0.6888 - binary_accuracy: 0.6938 - val_loss: 0.6202 - val_auc_9: 0.6341 - val_binary_accuracy: 0.6836\n",
            "Epoch 101/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5824 - auc_9: 0.6852 - binary_accuracy: 0.6870 - val_loss: 0.6225 - val_auc_9: 0.6290 - val_binary_accuracy: 0.6810\n",
            "Epoch 102/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5833 - auc_9: 0.6851 - binary_accuracy: 0.6917 - val_loss: 0.6236 - val_auc_9: 0.6246 - val_binary_accuracy: 0.6783\n",
            "Epoch 103/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5844 - auc_9: 0.6804 - binary_accuracy: 0.6844 - val_loss: 0.6235 - val_auc_9: 0.6267 - val_binary_accuracy: 0.6836\n",
            "Epoch 104/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5800 - auc_9: 0.6875 - binary_accuracy: 0.6951 - val_loss: 0.6220 - val_auc_9: 0.6278 - val_binary_accuracy: 0.6810\n",
            "Epoch 105/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5781 - auc_9: 0.6918 - binary_accuracy: 0.6951 - val_loss: 0.6230 - val_auc_9: 0.6287 - val_binary_accuracy: 0.6810\n",
            "Epoch 106/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5808 - auc_9: 0.6875 - binary_accuracy: 0.6884 - val_loss: 0.6245 - val_auc_9: 0.6250 - val_binary_accuracy: 0.6810\n",
            "Epoch 107/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5794 - auc_9: 0.6900 - binary_accuracy: 0.6904 - val_loss: 0.6218 - val_auc_9: 0.6359 - val_binary_accuracy: 0.6863\n",
            "Epoch 108/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5796 - auc_9: 0.6875 - binary_accuracy: 0.6938 - val_loss: 0.6225 - val_auc_9: 0.6338 - val_binary_accuracy: 0.6783\n",
            "Epoch 109/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5743 - auc_9: 0.6977 - binary_accuracy: 0.6904 - val_loss: 0.6252 - val_auc_9: 0.6287 - val_binary_accuracy: 0.6810\n",
            "Epoch 110/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5748 - auc_9: 0.6956 - binary_accuracy: 0.6830 - val_loss: 0.6251 - val_auc_9: 0.6343 - val_binary_accuracy: 0.6595\n",
            "Epoch 111/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5811 - auc_9: 0.6838 - binary_accuracy: 0.6891 - val_loss: 0.6241 - val_auc_9: 0.6338 - val_binary_accuracy: 0.6756\n",
            "Epoch 112/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5760 - auc_9: 0.6945 - binary_accuracy: 0.6870 - val_loss: 0.6249 - val_auc_9: 0.6289 - val_binary_accuracy: 0.6756\n",
            "Epoch 113/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5744 - auc_9: 0.6971 - binary_accuracy: 0.6877 - val_loss: 0.6258 - val_auc_9: 0.6282 - val_binary_accuracy: 0.6729\n",
            "Epoch 114/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5744 - auc_9: 0.6934 - binary_accuracy: 0.6924 - val_loss: 0.6251 - val_auc_9: 0.6288 - val_binary_accuracy: 0.6702\n",
            "Epoch 115/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5749 - auc_9: 0.6889 - binary_accuracy: 0.6897 - val_loss: 0.6279 - val_auc_9: 0.6264 - val_binary_accuracy: 0.6702\n",
            "Epoch 116/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5789 - auc_9: 0.6875 - binary_accuracy: 0.6857 - val_loss: 0.6266 - val_auc_9: 0.6325 - val_binary_accuracy: 0.6756\n",
            "Epoch 117/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5726 - auc_9: 0.6980 - binary_accuracy: 0.6978 - val_loss: 0.6253 - val_auc_9: 0.6384 - val_binary_accuracy: 0.6836\n",
            "Epoch 118/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5780 - auc_9: 0.6863 - binary_accuracy: 0.6938 - val_loss: 0.6237 - val_auc_9: 0.6349 - val_binary_accuracy: 0.6756\n",
            "Epoch 119/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5739 - auc_9: 0.7012 - binary_accuracy: 0.6911 - val_loss: 0.6279 - val_auc_9: 0.6282 - val_binary_accuracy: 0.6676\n",
            "Epoch 120/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5697 - auc_9: 0.7046 - binary_accuracy: 0.6931 - val_loss: 0.6274 - val_auc_9: 0.6409 - val_binary_accuracy: 0.6649\n",
            "Epoch 121/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5739 - auc_9: 0.6959 - binary_accuracy: 0.6891 - val_loss: 0.6255 - val_auc_9: 0.6315 - val_binary_accuracy: 0.6729\n",
            "Epoch 122/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5702 - auc_9: 0.7045 - binary_accuracy: 0.6864 - val_loss: 0.6268 - val_auc_9: 0.6298 - val_binary_accuracy: 0.6676\n",
            "Epoch 123/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5665 - auc_9: 0.7133 - binary_accuracy: 0.7005 - val_loss: 0.6271 - val_auc_9: 0.6352 - val_binary_accuracy: 0.6729\n",
            "Epoch 124/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5672 - auc_9: 0.7090 - binary_accuracy: 0.6944 - val_loss: 0.6270 - val_auc_9: 0.6373 - val_binary_accuracy: 0.6729\n",
            "Epoch 125/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5659 - auc_9: 0.7159 - binary_accuracy: 0.6978 - val_loss: 0.6290 - val_auc_9: 0.6326 - val_binary_accuracy: 0.6729\n",
            "Epoch 126/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5671 - auc_9: 0.7098 - binary_accuracy: 0.6951 - val_loss: 0.6253 - val_auc_9: 0.6373 - val_binary_accuracy: 0.6783\n",
            "Epoch 127/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5732 - auc_9: 0.6961 - binary_accuracy: 0.7025 - val_loss: 0.6236 - val_auc_9: 0.6438 - val_binary_accuracy: 0.6649\n",
            "Epoch 128/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5725 - auc_9: 0.6919 - binary_accuracy: 0.7018 - val_loss: 0.6274 - val_auc_9: 0.6314 - val_binary_accuracy: 0.6756\n",
            "Epoch 129/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5666 - auc_9: 0.7047 - binary_accuracy: 0.7018 - val_loss: 0.6292 - val_auc_9: 0.6313 - val_binary_accuracy: 0.6676\n",
            "Epoch 130/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5668 - auc_9: 0.7078 - binary_accuracy: 0.6978 - val_loss: 0.6300 - val_auc_9: 0.6315 - val_binary_accuracy: 0.6756\n",
            "Epoch 131/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5641 - auc_9: 0.7115 - binary_accuracy: 0.6897 - val_loss: 0.6307 - val_auc_9: 0.6224 - val_binary_accuracy: 0.6783\n",
            "Epoch 132/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5669 - auc_9: 0.7070 - binary_accuracy: 0.6951 - val_loss: 0.6290 - val_auc_9: 0.6295 - val_binary_accuracy: 0.6649\n",
            "Epoch 133/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5620 - auc_9: 0.7163 - binary_accuracy: 0.7011 - val_loss: 0.6329 - val_auc_9: 0.6260 - val_binary_accuracy: 0.6702\n",
            "Epoch 134/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5764 - auc_9: 0.6931 - binary_accuracy: 0.6857 - val_loss: 0.6312 - val_auc_9: 0.6307 - val_binary_accuracy: 0.6702\n",
            "Epoch 135/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5637 - auc_9: 0.7150 - binary_accuracy: 0.6904 - val_loss: 0.6294 - val_auc_9: 0.6298 - val_binary_accuracy: 0.6702\n",
            "Epoch 136/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5649 - auc_9: 0.7120 - binary_accuracy: 0.7038 - val_loss: 0.6259 - val_auc_9: 0.6402 - val_binary_accuracy: 0.6729\n",
            "Epoch 137/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5640 - auc_9: 0.7124 - binary_accuracy: 0.6971 - val_loss: 0.6312 - val_auc_9: 0.6367 - val_binary_accuracy: 0.6756\n",
            "Epoch 138/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5692 - auc_9: 0.7016 - binary_accuracy: 0.6964 - val_loss: 0.6314 - val_auc_9: 0.6319 - val_binary_accuracy: 0.6729\n",
            "Epoch 139/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5638 - auc_9: 0.7154 - binary_accuracy: 0.7025 - val_loss: 0.6305 - val_auc_9: 0.6313 - val_binary_accuracy: 0.6756\n",
            "Epoch 140/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5623 - auc_9: 0.7113 - binary_accuracy: 0.6931 - val_loss: 0.6311 - val_auc_9: 0.6338 - val_binary_accuracy: 0.6729\n",
            "Epoch 141/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5550 - auc_9: 0.7263 - binary_accuracy: 0.7079 - val_loss: 0.6373 - val_auc_9: 0.6219 - val_binary_accuracy: 0.6702\n",
            "Epoch 142/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5593 - auc_9: 0.7232 - binary_accuracy: 0.7018 - val_loss: 0.6353 - val_auc_9: 0.6306 - val_binary_accuracy: 0.6756\n",
            "Epoch 143/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5634 - auc_9: 0.7141 - binary_accuracy: 0.6857 - val_loss: 0.6335 - val_auc_9: 0.6295 - val_binary_accuracy: 0.6756\n",
            "Epoch 144/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5618 - auc_9: 0.7127 - binary_accuracy: 0.6931 - val_loss: 0.6303 - val_auc_9: 0.6341 - val_binary_accuracy: 0.6649\n",
            "Epoch 145/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5549 - auc_9: 0.7281 - binary_accuracy: 0.7025 - val_loss: 0.6317 - val_auc_9: 0.6348 - val_binary_accuracy: 0.6729\n",
            "Epoch 146/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5558 - auc_9: 0.7256 - binary_accuracy: 0.6958 - val_loss: 0.6307 - val_auc_9: 0.6400 - val_binary_accuracy: 0.6756\n",
            "Epoch 147/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5610 - auc_9: 0.7153 - binary_accuracy: 0.6985 - val_loss: 0.6333 - val_auc_9: 0.6342 - val_binary_accuracy: 0.6783\n",
            "Epoch 148/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5594 - auc_9: 0.7153 - binary_accuracy: 0.7045 - val_loss: 0.6319 - val_auc_9: 0.6371 - val_binary_accuracy: 0.6756\n",
            "Epoch 149/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5560 - auc_9: 0.7232 - binary_accuracy: 0.6991 - val_loss: 0.6302 - val_auc_9: 0.6425 - val_binary_accuracy: 0.6568\n",
            "Epoch 150/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5557 - auc_9: 0.7219 - binary_accuracy: 0.7092 - val_loss: 0.6323 - val_auc_9: 0.6366 - val_binary_accuracy: 0.6756\n",
            "Epoch 151/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5538 - auc_9: 0.7270 - binary_accuracy: 0.7085 - val_loss: 0.6347 - val_auc_9: 0.6350 - val_binary_accuracy: 0.6810\n",
            "Epoch 152/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5549 - auc_9: 0.7194 - binary_accuracy: 0.7025 - val_loss: 0.6332 - val_auc_9: 0.6394 - val_binary_accuracy: 0.6783\n",
            "Epoch 153/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5563 - auc_9: 0.7266 - binary_accuracy: 0.7011 - val_loss: 0.6341 - val_auc_9: 0.6335 - val_binary_accuracy: 0.6595\n",
            "Epoch 154/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5557 - auc_9: 0.7268 - binary_accuracy: 0.7079 - val_loss: 0.6356 - val_auc_9: 0.6360 - val_binary_accuracy: 0.6595\n",
            "Epoch 155/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5541 - auc_9: 0.7267 - binary_accuracy: 0.7032 - val_loss: 0.6327 - val_auc_9: 0.6396 - val_binary_accuracy: 0.6756\n",
            "Epoch 156/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5464 - auc_9: 0.7327 - binary_accuracy: 0.7038 - val_loss: 0.6299 - val_auc_9: 0.6488 - val_binary_accuracy: 0.6622\n",
            "Epoch 157/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5508 - auc_9: 0.7305 - binary_accuracy: 0.6971 - val_loss: 0.6290 - val_auc_9: 0.6468 - val_binary_accuracy: 0.6676\n",
            "Epoch 158/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5468 - auc_9: 0.7382 - binary_accuracy: 0.7112 - val_loss: 0.6319 - val_auc_9: 0.6450 - val_binary_accuracy: 0.6810\n",
            "Epoch 159/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5523 - auc_9: 0.7266 - binary_accuracy: 0.7018 - val_loss: 0.6299 - val_auc_9: 0.6516 - val_binary_accuracy: 0.6783\n",
            "Epoch 160/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5549 - auc_9: 0.7329 - binary_accuracy: 0.7058 - val_loss: 0.6353 - val_auc_9: 0.6401 - val_binary_accuracy: 0.6676\n",
            "Epoch 161/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5480 - auc_9: 0.7361 - binary_accuracy: 0.7119 - val_loss: 0.6321 - val_auc_9: 0.6459 - val_binary_accuracy: 0.6836\n",
            "Epoch 162/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5454 - auc_9: 0.7358 - binary_accuracy: 0.7045 - val_loss: 0.6314 - val_auc_9: 0.6455 - val_binary_accuracy: 0.6810\n",
            "Epoch 163/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5514 - auc_9: 0.7256 - binary_accuracy: 0.7018 - val_loss: 0.6342 - val_auc_9: 0.6478 - val_binary_accuracy: 0.6729\n",
            "Epoch 164/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5475 - auc_9: 0.7356 - binary_accuracy: 0.7072 - val_loss: 0.6362 - val_auc_9: 0.6433 - val_binary_accuracy: 0.6702\n",
            "Epoch 165/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5418 - auc_9: 0.7425 - binary_accuracy: 0.7038 - val_loss: 0.6355 - val_auc_9: 0.6504 - val_binary_accuracy: 0.6783\n",
            "Epoch 166/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5413 - auc_9: 0.7404 - binary_accuracy: 0.7099 - val_loss: 0.6292 - val_auc_9: 0.6579 - val_binary_accuracy: 0.6890\n",
            "Epoch 167/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5409 - auc_9: 0.7475 - binary_accuracy: 0.7132 - val_loss: 0.6326 - val_auc_9: 0.6543 - val_binary_accuracy: 0.6783\n",
            "Epoch 168/200\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 0.5474 - auc_9: 0.7331 - binary_accuracy: 0.7072 - val_loss: 0.6350 - val_auc_9: 0.6483 - val_binary_accuracy: 0.6810\n",
            "Epoch 169/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5402 - auc_9: 0.7461 - binary_accuracy: 0.7119 - val_loss: 0.6363 - val_auc_9: 0.6444 - val_binary_accuracy: 0.6810\n",
            "Epoch 170/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5477 - auc_9: 0.7328 - binary_accuracy: 0.7112 - val_loss: 0.6390 - val_auc_9: 0.6384 - val_binary_accuracy: 0.6595\n",
            "Epoch 171/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5357 - auc_9: 0.7502 - binary_accuracy: 0.7213 - val_loss: 0.6373 - val_auc_9: 0.6463 - val_binary_accuracy: 0.6756\n",
            "Epoch 172/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.5425 - auc_9: 0.7407 - binary_accuracy: 0.7079 - val_loss: 0.6382 - val_auc_9: 0.6406 - val_binary_accuracy: 0.6783\n",
            "Epoch 173/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5385 - auc_9: 0.7493 - binary_accuracy: 0.7166 - val_loss: 0.6372 - val_auc_9: 0.6482 - val_binary_accuracy: 0.6622\n",
            "Epoch 174/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5235 - auc_9: 0.7663 - binary_accuracy: 0.7293 - val_loss: 0.6393 - val_auc_9: 0.6423 - val_binary_accuracy: 0.6702\n",
            "Epoch 175/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5355 - auc_9: 0.7505 - binary_accuracy: 0.7105 - val_loss: 0.6423 - val_auc_9: 0.6458 - val_binary_accuracy: 0.6729\n",
            "Epoch 176/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5352 - auc_9: 0.7551 - binary_accuracy: 0.7132 - val_loss: 0.6428 - val_auc_9: 0.6397 - val_binary_accuracy: 0.6756\n",
            "Epoch 177/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5329 - auc_9: 0.7571 - binary_accuracy: 0.7173 - val_loss: 0.6432 - val_auc_9: 0.6413 - val_binary_accuracy: 0.6542\n",
            "Epoch 178/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5339 - auc_9: 0.7591 - binary_accuracy: 0.7112 - val_loss: 0.6396 - val_auc_9: 0.6495 - val_binary_accuracy: 0.6676\n",
            "Epoch 179/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5304 - auc_9: 0.7510 - binary_accuracy: 0.7199 - val_loss: 0.6394 - val_auc_9: 0.6492 - val_binary_accuracy: 0.6649\n",
            "Epoch 180/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5252 - auc_9: 0.7629 - binary_accuracy: 0.7240 - val_loss: 0.6407 - val_auc_9: 0.6469 - val_binary_accuracy: 0.6756\n",
            "Epoch 181/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5416 - auc_9: 0.7416 - binary_accuracy: 0.7226 - val_loss: 0.6422 - val_auc_9: 0.6424 - val_binary_accuracy: 0.6729\n",
            "Epoch 182/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5296 - auc_9: 0.7578 - binary_accuracy: 0.7226 - val_loss: 0.6403 - val_auc_9: 0.6439 - val_binary_accuracy: 0.6756\n",
            "Epoch 183/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5326 - auc_9: 0.7590 - binary_accuracy: 0.7199 - val_loss: 0.6408 - val_auc_9: 0.6472 - val_binary_accuracy: 0.6729\n",
            "Epoch 184/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5283 - auc_9: 0.7610 - binary_accuracy: 0.7320 - val_loss: 0.6431 - val_auc_9: 0.6363 - val_binary_accuracy: 0.6783\n",
            "Epoch 185/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5323 - auc_9: 0.7537 - binary_accuracy: 0.7213 - val_loss: 0.6441 - val_auc_9: 0.6440 - val_binary_accuracy: 0.6702\n",
            "Epoch 186/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5236 - auc_9: 0.7674 - binary_accuracy: 0.7226 - val_loss: 0.6387 - val_auc_9: 0.6521 - val_binary_accuracy: 0.6729\n",
            "Epoch 187/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5340 - auc_9: 0.7523 - binary_accuracy: 0.7146 - val_loss: 0.6422 - val_auc_9: 0.6446 - val_binary_accuracy: 0.6622\n",
            "Epoch 188/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5306 - auc_9: 0.7555 - binary_accuracy: 0.7112 - val_loss: 0.6381 - val_auc_9: 0.6563 - val_binary_accuracy: 0.6756\n",
            "Epoch 189/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5228 - auc_9: 0.7642 - binary_accuracy: 0.7220 - val_loss: 0.6406 - val_auc_9: 0.6477 - val_binary_accuracy: 0.6783\n",
            "Epoch 190/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5271 - auc_9: 0.7613 - binary_accuracy: 0.7139 - val_loss: 0.6405 - val_auc_9: 0.6493 - val_binary_accuracy: 0.6783\n",
            "Epoch 191/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5259 - auc_9: 0.7642 - binary_accuracy: 0.7240 - val_loss: 0.6413 - val_auc_9: 0.6464 - val_binary_accuracy: 0.6783\n",
            "Epoch 192/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5218 - auc_9: 0.7698 - binary_accuracy: 0.7267 - val_loss: 0.6368 - val_auc_9: 0.6578 - val_binary_accuracy: 0.6702\n",
            "Epoch 193/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5254 - auc_9: 0.7632 - binary_accuracy: 0.7220 - val_loss: 0.6362 - val_auc_9: 0.6599 - val_binary_accuracy: 0.6783\n",
            "Epoch 194/200\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 0.5148 - auc_9: 0.7781 - binary_accuracy: 0.7300 - val_loss: 0.6346 - val_auc_9: 0.6614 - val_binary_accuracy: 0.6810\n",
            "Epoch 195/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5205 - auc_9: 0.7672 - binary_accuracy: 0.7293 - val_loss: 0.6393 - val_auc_9: 0.6499 - val_binary_accuracy: 0.6756\n",
            "Epoch 196/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5203 - auc_9: 0.7709 - binary_accuracy: 0.7260 - val_loss: 0.6393 - val_auc_9: 0.6540 - val_binary_accuracy: 0.6756\n",
            "Epoch 197/200\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 0.5141 - auc_9: 0.7801 - binary_accuracy: 0.7300 - val_loss: 0.6430 - val_auc_9: 0.6491 - val_binary_accuracy: 0.6783\n",
            "Epoch 198/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5182 - auc_9: 0.7737 - binary_accuracy: 0.7401 - val_loss: 0.6377 - val_auc_9: 0.6590 - val_binary_accuracy: 0.6702\n",
            "Epoch 199/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5225 - auc_9: 0.7661 - binary_accuracy: 0.7139 - val_loss: 0.6432 - val_auc_9: 0.6493 - val_binary_accuracy: 0.6676\n",
            "Epoch 200/200\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 0.5155 - auc_9: 0.7787 - binary_accuracy: 0.7340 - val_loss: 0.6347 - val_auc_9: 0.6643 - val_binary_accuracy: 0.6756\n",
            "Epoch 1/200\n",
            "47/47 [==============================] - 3s 21ms/step - loss: 0.6630 - auc_10: 0.5267 - binary_accuracy: 0.6347 - val_loss: 0.6257 - val_auc_10: 0.6254 - val_binary_accuracy: 0.6676\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6274 - auc_10: 0.5809 - binary_accuracy: 0.6662 - val_loss: 0.6111 - val_auc_10: 0.6434 - val_binary_accuracy: 0.6676\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6226 - auc_10: 0.5910 - binary_accuracy: 0.6662 - val_loss: 0.6085 - val_auc_10: 0.6586 - val_binary_accuracy: 0.6676\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6238 - auc_10: 0.5970 - binary_accuracy: 0.6662 - val_loss: 0.6086 - val_auc_10: 0.6532 - val_binary_accuracy: 0.6676\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6200 - auc_10: 0.6043 - binary_accuracy: 0.6662 - val_loss: 0.6085 - val_auc_10: 0.6541 - val_binary_accuracy: 0.6676\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6223 - auc_10: 0.5945 - binary_accuracy: 0.6629 - val_loss: 0.6072 - val_auc_10: 0.6594 - val_binary_accuracy: 0.6676\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6181 - auc_10: 0.6072 - binary_accuracy: 0.6669 - val_loss: 0.6059 - val_auc_10: 0.6578 - val_binary_accuracy: 0.6676\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6200 - auc_10: 0.5981 - binary_accuracy: 0.6662 - val_loss: 0.6075 - val_auc_10: 0.6466 - val_binary_accuracy: 0.6676\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6173 - auc_10: 0.6109 - binary_accuracy: 0.6669 - val_loss: 0.6045 - val_auc_10: 0.6561 - val_binary_accuracy: 0.6676\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6169 - auc_10: 0.6104 - binary_accuracy: 0.6669 - val_loss: 0.6080 - val_auc_10: 0.6424 - val_binary_accuracy: 0.6676\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6188 - auc_10: 0.6045 - binary_accuracy: 0.6669 - val_loss: 0.6057 - val_auc_10: 0.6452 - val_binary_accuracy: 0.6729\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6173 - auc_10: 0.6023 - binary_accuracy: 0.6629 - val_loss: 0.6063 - val_auc_10: 0.6447 - val_binary_accuracy: 0.6729\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6154 - auc_10: 0.6124 - binary_accuracy: 0.6716 - val_loss: 0.6052 - val_auc_10: 0.6511 - val_binary_accuracy: 0.6676\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6162 - auc_10: 0.6141 - binary_accuracy: 0.6682 - val_loss: 0.6050 - val_auc_10: 0.6485 - val_binary_accuracy: 0.6729\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6146 - auc_10: 0.6136 - binary_accuracy: 0.6642 - val_loss: 0.6063 - val_auc_10: 0.6423 - val_binary_accuracy: 0.6676\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6149 - auc_10: 0.6161 - binary_accuracy: 0.6662 - val_loss: 0.6055 - val_auc_10: 0.6515 - val_binary_accuracy: 0.6676\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6154 - auc_10: 0.6111 - binary_accuracy: 0.6669 - val_loss: 0.6066 - val_auc_10: 0.6361 - val_binary_accuracy: 0.6756\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6133 - auc_10: 0.6215 - binary_accuracy: 0.6662 - val_loss: 0.6079 - val_auc_10: 0.6377 - val_binary_accuracy: 0.6702\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6122 - auc_10: 0.6220 - binary_accuracy: 0.6669 - val_loss: 0.6070 - val_auc_10: 0.6409 - val_binary_accuracy: 0.6729\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6139 - auc_10: 0.6115 - binary_accuracy: 0.6702 - val_loss: 0.6070 - val_auc_10: 0.6357 - val_binary_accuracy: 0.6756\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6141 - auc_10: 0.6132 - binary_accuracy: 0.6669 - val_loss: 0.6074 - val_auc_10: 0.6391 - val_binary_accuracy: 0.6783\n",
            "Epoch 22/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6122 - auc_10: 0.6184 - binary_accuracy: 0.6709 - val_loss: 0.6093 - val_auc_10: 0.6299 - val_binary_accuracy: 0.6676\n",
            "Epoch 23/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6128 - auc_10: 0.6217 - binary_accuracy: 0.6622 - val_loss: 0.6117 - val_auc_10: 0.6231 - val_binary_accuracy: 0.6702\n",
            "Epoch 24/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6106 - auc_10: 0.6211 - binary_accuracy: 0.6696 - val_loss: 0.6101 - val_auc_10: 0.6305 - val_binary_accuracy: 0.6729\n",
            "Epoch 25/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6065 - auc_10: 0.6331 - binary_accuracy: 0.6776 - val_loss: 0.6091 - val_auc_10: 0.6354 - val_binary_accuracy: 0.6756\n",
            "Epoch 26/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.6096 - auc_10: 0.6273 - binary_accuracy: 0.6669 - val_loss: 0.6116 - val_auc_10: 0.6206 - val_binary_accuracy: 0.6702\n",
            "Epoch 27/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6107 - auc_10: 0.6243 - binary_accuracy: 0.6662 - val_loss: 0.6111 - val_auc_10: 0.6251 - val_binary_accuracy: 0.6702\n",
            "Epoch 28/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6100 - auc_10: 0.6228 - binary_accuracy: 0.6696 - val_loss: 0.6122 - val_auc_10: 0.6291 - val_binary_accuracy: 0.6756\n",
            "Epoch 29/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6102 - auc_10: 0.6257 - binary_accuracy: 0.6669 - val_loss: 0.6127 - val_auc_10: 0.6182 - val_binary_accuracy: 0.6676\n",
            "Epoch 30/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6096 - auc_10: 0.6295 - binary_accuracy: 0.6629 - val_loss: 0.6128 - val_auc_10: 0.6186 - val_binary_accuracy: 0.6729\n",
            "Epoch 31/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6078 - auc_10: 0.6313 - binary_accuracy: 0.6716 - val_loss: 0.6167 - val_auc_10: 0.6136 - val_binary_accuracy: 0.6702\n",
            "Epoch 32/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6065 - auc_10: 0.6338 - binary_accuracy: 0.6749 - val_loss: 0.6125 - val_auc_10: 0.6290 - val_binary_accuracy: 0.6783\n",
            "Epoch 33/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6062 - auc_10: 0.6362 - binary_accuracy: 0.6723 - val_loss: 0.6141 - val_auc_10: 0.6245 - val_binary_accuracy: 0.6810\n",
            "Epoch 34/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6028 - auc_10: 0.6461 - binary_accuracy: 0.6662 - val_loss: 0.6148 - val_auc_10: 0.6254 - val_binary_accuracy: 0.6783\n",
            "Epoch 35/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6033 - auc_10: 0.6406 - binary_accuracy: 0.6729 - val_loss: 0.6159 - val_auc_10: 0.6246 - val_binary_accuracy: 0.6729\n",
            "Epoch 36/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6054 - auc_10: 0.6372 - binary_accuracy: 0.6729 - val_loss: 0.6175 - val_auc_10: 0.6209 - val_binary_accuracy: 0.6729\n",
            "Epoch 37/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6034 - auc_10: 0.6429 - binary_accuracy: 0.6770 - val_loss: 0.6179 - val_auc_10: 0.6215 - val_binary_accuracy: 0.6702\n",
            "Epoch 38/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.6027 - auc_10: 0.6430 - binary_accuracy: 0.6749 - val_loss: 0.6188 - val_auc_10: 0.6194 - val_binary_accuracy: 0.6676\n",
            "Epoch 39/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6040 - auc_10: 0.6350 - binary_accuracy: 0.6736 - val_loss: 0.6188 - val_auc_10: 0.6190 - val_binary_accuracy: 0.6676\n",
            "Epoch 40/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6007 - auc_10: 0.6478 - binary_accuracy: 0.6729 - val_loss: 0.6198 - val_auc_10: 0.6100 - val_binary_accuracy: 0.6702\n",
            "Epoch 41/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5994 - auc_10: 0.6442 - binary_accuracy: 0.6756 - val_loss: 0.6204 - val_auc_10: 0.6186 - val_binary_accuracy: 0.6756\n",
            "Epoch 42/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.6019 - auc_10: 0.6368 - binary_accuracy: 0.6743 - val_loss: 0.6214 - val_auc_10: 0.6169 - val_binary_accuracy: 0.6702\n",
            "Epoch 43/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5961 - auc_10: 0.6603 - binary_accuracy: 0.6716 - val_loss: 0.6243 - val_auc_10: 0.6046 - val_binary_accuracy: 0.6676\n",
            "Epoch 44/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5975 - auc_10: 0.6545 - binary_accuracy: 0.6749 - val_loss: 0.6227 - val_auc_10: 0.6036 - val_binary_accuracy: 0.6729\n",
            "Epoch 45/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5992 - auc_10: 0.6465 - binary_accuracy: 0.6669 - val_loss: 0.6248 - val_auc_10: 0.6161 - val_binary_accuracy: 0.6702\n",
            "Epoch 46/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.6016 - auc_10: 0.6469 - binary_accuracy: 0.6689 - val_loss: 0.6217 - val_auc_10: 0.6240 - val_binary_accuracy: 0.6810\n",
            "Epoch 47/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5978 - auc_10: 0.6604 - binary_accuracy: 0.6709 - val_loss: 0.6213 - val_auc_10: 0.6133 - val_binary_accuracy: 0.6649\n",
            "Epoch 48/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5975 - auc_10: 0.6597 - binary_accuracy: 0.6702 - val_loss: 0.6277 - val_auc_10: 0.6022 - val_binary_accuracy: 0.6649\n",
            "Epoch 49/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5961 - auc_10: 0.6535 - binary_accuracy: 0.6756 - val_loss: 0.6270 - val_auc_10: 0.5977 - val_binary_accuracy: 0.6702\n",
            "Epoch 50/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5930 - auc_10: 0.6657 - binary_accuracy: 0.6689 - val_loss: 0.6270 - val_auc_10: 0.6057 - val_binary_accuracy: 0.6676\n",
            "Epoch 51/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5971 - auc_10: 0.6536 - binary_accuracy: 0.6763 - val_loss: 0.6263 - val_auc_10: 0.6006 - val_binary_accuracy: 0.6756\n",
            "Epoch 52/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5985 - auc_10: 0.6526 - binary_accuracy: 0.6689 - val_loss: 0.6296 - val_auc_10: 0.6032 - val_binary_accuracy: 0.6568\n",
            "Epoch 53/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5927 - auc_10: 0.6637 - binary_accuracy: 0.6776 - val_loss: 0.6281 - val_auc_10: 0.5946 - val_binary_accuracy: 0.6783\n",
            "Epoch 54/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5961 - auc_10: 0.6518 - binary_accuracy: 0.6783 - val_loss: 0.6313 - val_auc_10: 0.5967 - val_binary_accuracy: 0.6649\n",
            "Epoch 55/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5913 - auc_10: 0.6669 - binary_accuracy: 0.6763 - val_loss: 0.6301 - val_auc_10: 0.6094 - val_binary_accuracy: 0.6783\n",
            "Epoch 56/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5895 - auc_10: 0.6687 - binary_accuracy: 0.6817 - val_loss: 0.6274 - val_auc_10: 0.6057 - val_binary_accuracy: 0.6729\n",
            "Epoch 57/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5920 - auc_10: 0.6658 - binary_accuracy: 0.6749 - val_loss: 0.6276 - val_auc_10: 0.6139 - val_binary_accuracy: 0.6729\n",
            "Epoch 58/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5908 - auc_10: 0.6688 - binary_accuracy: 0.6743 - val_loss: 0.6319 - val_auc_10: 0.6050 - val_binary_accuracy: 0.6595\n",
            "Epoch 59/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5921 - auc_10: 0.6602 - binary_accuracy: 0.6729 - val_loss: 0.6278 - val_auc_10: 0.6071 - val_binary_accuracy: 0.6595\n",
            "Epoch 60/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5899 - auc_10: 0.6692 - binary_accuracy: 0.6716 - val_loss: 0.6296 - val_auc_10: 0.6116 - val_binary_accuracy: 0.6810\n",
            "Epoch 61/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5952 - auc_10: 0.6587 - binary_accuracy: 0.6682 - val_loss: 0.6335 - val_auc_10: 0.5978 - val_binary_accuracy: 0.6729\n",
            "Epoch 62/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5881 - auc_10: 0.6797 - binary_accuracy: 0.6749 - val_loss: 0.6310 - val_auc_10: 0.6004 - val_binary_accuracy: 0.6729\n",
            "Epoch 63/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5874 - auc_10: 0.6712 - binary_accuracy: 0.6790 - val_loss: 0.6313 - val_auc_10: 0.6038 - val_binary_accuracy: 0.6756\n",
            "Epoch 64/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5901 - auc_10: 0.6654 - binary_accuracy: 0.6763 - val_loss: 0.6354 - val_auc_10: 0.6008 - val_binary_accuracy: 0.6595\n",
            "Epoch 65/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5890 - auc_10: 0.6705 - binary_accuracy: 0.6783 - val_loss: 0.6329 - val_auc_10: 0.6090 - val_binary_accuracy: 0.6649\n",
            "Epoch 66/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5867 - auc_10: 0.6729 - binary_accuracy: 0.6723 - val_loss: 0.6297 - val_auc_10: 0.6044 - val_binary_accuracy: 0.6756\n",
            "Epoch 67/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5853 - auc_10: 0.6761 - binary_accuracy: 0.6817 - val_loss: 0.6295 - val_auc_10: 0.6184 - val_binary_accuracy: 0.6810\n",
            "Epoch 68/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5873 - auc_10: 0.6753 - binary_accuracy: 0.6723 - val_loss: 0.6317 - val_auc_10: 0.6116 - val_binary_accuracy: 0.6783\n",
            "Epoch 69/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5807 - auc_10: 0.6816 - binary_accuracy: 0.6823 - val_loss: 0.6331 - val_auc_10: 0.6140 - val_binary_accuracy: 0.6863\n",
            "Epoch 70/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5882 - auc_10: 0.6708 - binary_accuracy: 0.6790 - val_loss: 0.6321 - val_auc_10: 0.6158 - val_binary_accuracy: 0.6729\n",
            "Epoch 71/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5891 - auc_10: 0.6707 - binary_accuracy: 0.6797 - val_loss: 0.6360 - val_auc_10: 0.6113 - val_binary_accuracy: 0.6783\n",
            "Epoch 72/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5851 - auc_10: 0.6693 - binary_accuracy: 0.6837 - val_loss: 0.6347 - val_auc_10: 0.6012 - val_binary_accuracy: 0.6676\n",
            "Epoch 73/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5837 - auc_10: 0.6794 - binary_accuracy: 0.6770 - val_loss: 0.6315 - val_auc_10: 0.6184 - val_binary_accuracy: 0.6836\n",
            "Epoch 74/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5867 - auc_10: 0.6715 - binary_accuracy: 0.6797 - val_loss: 0.6330 - val_auc_10: 0.6183 - val_binary_accuracy: 0.6729\n",
            "Epoch 75/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5859 - auc_10: 0.6789 - binary_accuracy: 0.6770 - val_loss: 0.6319 - val_auc_10: 0.6181 - val_binary_accuracy: 0.6756\n",
            "Epoch 76/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5867 - auc_10: 0.6710 - binary_accuracy: 0.6776 - val_loss: 0.6310 - val_auc_10: 0.6207 - val_binary_accuracy: 0.6863\n",
            "Epoch 77/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5774 - auc_10: 0.6883 - binary_accuracy: 0.6776 - val_loss: 0.6311 - val_auc_10: 0.6207 - val_binary_accuracy: 0.6810\n",
            "Epoch 78/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5735 - auc_10: 0.6948 - binary_accuracy: 0.6837 - val_loss: 0.6344 - val_auc_10: 0.6235 - val_binary_accuracy: 0.6810\n",
            "Epoch 79/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5748 - auc_10: 0.6901 - binary_accuracy: 0.6877 - val_loss: 0.6361 - val_auc_10: 0.6141 - val_binary_accuracy: 0.6729\n",
            "Epoch 80/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5824 - auc_10: 0.6792 - binary_accuracy: 0.6783 - val_loss: 0.6398 - val_auc_10: 0.6141 - val_binary_accuracy: 0.6702\n",
            "Epoch 81/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5786 - auc_10: 0.6823 - binary_accuracy: 0.6850 - val_loss: 0.6373 - val_auc_10: 0.6171 - val_binary_accuracy: 0.6622\n",
            "Epoch 82/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5787 - auc_10: 0.6862 - binary_accuracy: 0.6870 - val_loss: 0.6352 - val_auc_10: 0.6169 - val_binary_accuracy: 0.6836\n",
            "Epoch 83/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5756 - auc_10: 0.6943 - binary_accuracy: 0.6850 - val_loss: 0.6414 - val_auc_10: 0.6121 - val_binary_accuracy: 0.6729\n",
            "Epoch 84/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5733 - auc_10: 0.6969 - binary_accuracy: 0.6823 - val_loss: 0.6398 - val_auc_10: 0.6166 - val_binary_accuracy: 0.6756\n",
            "Epoch 85/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5730 - auc_10: 0.6946 - binary_accuracy: 0.6830 - val_loss: 0.6374 - val_auc_10: 0.6127 - val_binary_accuracy: 0.6783\n",
            "Epoch 86/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5738 - auc_10: 0.6978 - binary_accuracy: 0.6904 - val_loss: 0.6363 - val_auc_10: 0.6179 - val_binary_accuracy: 0.6729\n",
            "Epoch 87/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5701 - auc_10: 0.7010 - binary_accuracy: 0.6870 - val_loss: 0.6376 - val_auc_10: 0.6231 - val_binary_accuracy: 0.6676\n",
            "Epoch 88/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5704 - auc_10: 0.6941 - binary_accuracy: 0.6864 - val_loss: 0.6399 - val_auc_10: 0.6095 - val_binary_accuracy: 0.6515\n",
            "Epoch 89/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5727 - auc_10: 0.6986 - binary_accuracy: 0.6891 - val_loss: 0.6418 - val_auc_10: 0.6174 - val_binary_accuracy: 0.6622\n",
            "Epoch 90/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5710 - auc_10: 0.6925 - binary_accuracy: 0.6978 - val_loss: 0.6385 - val_auc_10: 0.6187 - val_binary_accuracy: 0.6676\n",
            "Epoch 91/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5661 - auc_10: 0.7050 - binary_accuracy: 0.6964 - val_loss: 0.6455 - val_auc_10: 0.6193 - val_binary_accuracy: 0.6595\n",
            "Epoch 92/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5695 - auc_10: 0.6988 - binary_accuracy: 0.6891 - val_loss: 0.6445 - val_auc_10: 0.6089 - val_binary_accuracy: 0.6461\n",
            "Epoch 93/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5655 - auc_10: 0.7092 - binary_accuracy: 0.6958 - val_loss: 0.6405 - val_auc_10: 0.6208 - val_binary_accuracy: 0.6622\n",
            "Epoch 94/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5691 - auc_10: 0.7065 - binary_accuracy: 0.6978 - val_loss: 0.6397 - val_auc_10: 0.6203 - val_binary_accuracy: 0.6595\n",
            "Epoch 95/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5733 - auc_10: 0.6921 - binary_accuracy: 0.6823 - val_loss: 0.6488 - val_auc_10: 0.6083 - val_binary_accuracy: 0.6649\n",
            "Epoch 96/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5677 - auc_10: 0.7059 - binary_accuracy: 0.6897 - val_loss: 0.6488 - val_auc_10: 0.6097 - val_binary_accuracy: 0.6515\n",
            "Epoch 97/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5692 - auc_10: 0.6980 - binary_accuracy: 0.6904 - val_loss: 0.6438 - val_auc_10: 0.6152 - val_binary_accuracy: 0.6676\n",
            "Epoch 98/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5588 - auc_10: 0.7067 - binary_accuracy: 0.6911 - val_loss: 0.6466 - val_auc_10: 0.6320 - val_binary_accuracy: 0.6622\n",
            "Epoch 99/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5622 - auc_10: 0.7069 - binary_accuracy: 0.7038 - val_loss: 0.6446 - val_auc_10: 0.6209 - val_binary_accuracy: 0.6595\n",
            "Epoch 100/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5616 - auc_10: 0.7118 - binary_accuracy: 0.6864 - val_loss: 0.6448 - val_auc_10: 0.6235 - val_binary_accuracy: 0.6676\n",
            "Epoch 101/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5620 - auc_10: 0.7100 - binary_accuracy: 0.6911 - val_loss: 0.6422 - val_auc_10: 0.6212 - val_binary_accuracy: 0.6622\n",
            "Epoch 102/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5628 - auc_10: 0.7100 - binary_accuracy: 0.6951 - val_loss: 0.6469 - val_auc_10: 0.6104 - val_binary_accuracy: 0.6649\n",
            "Epoch 103/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5609 - auc_10: 0.7102 - binary_accuracy: 0.7052 - val_loss: 0.6462 - val_auc_10: 0.6196 - val_binary_accuracy: 0.6676\n",
            "Epoch 104/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5577 - auc_10: 0.7254 - binary_accuracy: 0.6951 - val_loss: 0.6501 - val_auc_10: 0.6150 - val_binary_accuracy: 0.6676\n",
            "Epoch 105/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5536 - auc_10: 0.7235 - binary_accuracy: 0.7045 - val_loss: 0.6568 - val_auc_10: 0.6275 - val_binary_accuracy: 0.6622\n",
            "Epoch 106/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5614 - auc_10: 0.7114 - binary_accuracy: 0.7011 - val_loss: 0.6499 - val_auc_10: 0.6245 - val_binary_accuracy: 0.6702\n",
            "Epoch 107/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5584 - auc_10: 0.7209 - binary_accuracy: 0.7005 - val_loss: 0.6551 - val_auc_10: 0.6174 - val_binary_accuracy: 0.6595\n",
            "Epoch 108/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5519 - auc_10: 0.7224 - binary_accuracy: 0.6951 - val_loss: 0.6528 - val_auc_10: 0.6155 - val_binary_accuracy: 0.6676\n",
            "Epoch 109/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5542 - auc_10: 0.7227 - binary_accuracy: 0.7018 - val_loss: 0.6560 - val_auc_10: 0.6113 - val_binary_accuracy: 0.6488\n",
            "Epoch 110/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5471 - auc_10: 0.7293 - binary_accuracy: 0.7011 - val_loss: 0.6568 - val_auc_10: 0.6088 - val_binary_accuracy: 0.6676\n",
            "Epoch 111/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5500 - auc_10: 0.7298 - binary_accuracy: 0.7058 - val_loss: 0.6495 - val_auc_10: 0.6188 - val_binary_accuracy: 0.6649\n",
            "Epoch 112/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5486 - auc_10: 0.7324 - binary_accuracy: 0.7085 - val_loss: 0.6615 - val_auc_10: 0.6126 - val_binary_accuracy: 0.6515\n",
            "Epoch 113/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5494 - auc_10: 0.7316 - binary_accuracy: 0.7052 - val_loss: 0.6529 - val_auc_10: 0.6231 - val_binary_accuracy: 0.6676\n",
            "Epoch 114/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5439 - auc_10: 0.7400 - binary_accuracy: 0.7139 - val_loss: 0.6583 - val_auc_10: 0.6226 - val_binary_accuracy: 0.6568\n",
            "Epoch 115/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5428 - auc_10: 0.7354 - binary_accuracy: 0.7011 - val_loss: 0.6553 - val_auc_10: 0.6228 - val_binary_accuracy: 0.6595\n",
            "Epoch 116/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5443 - auc_10: 0.7396 - binary_accuracy: 0.7058 - val_loss: 0.6622 - val_auc_10: 0.6160 - val_binary_accuracy: 0.6649\n",
            "Epoch 117/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5426 - auc_10: 0.7402 - binary_accuracy: 0.7112 - val_loss: 0.6590 - val_auc_10: 0.6198 - val_binary_accuracy: 0.6568\n",
            "Epoch 118/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5397 - auc_10: 0.7426 - binary_accuracy: 0.7092 - val_loss: 0.6655 - val_auc_10: 0.6193 - val_binary_accuracy: 0.6488\n",
            "Epoch 119/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5325 - auc_10: 0.7551 - binary_accuracy: 0.7159 - val_loss: 0.6722 - val_auc_10: 0.6085 - val_binary_accuracy: 0.6649\n",
            "Epoch 120/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5435 - auc_10: 0.7364 - binary_accuracy: 0.7119 - val_loss: 0.6644 - val_auc_10: 0.6080 - val_binary_accuracy: 0.6595\n",
            "Epoch 121/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5325 - auc_10: 0.7602 - binary_accuracy: 0.7092 - val_loss: 0.6701 - val_auc_10: 0.6201 - val_binary_accuracy: 0.6702\n",
            "Epoch 122/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5380 - auc_10: 0.7480 - binary_accuracy: 0.7206 - val_loss: 0.6759 - val_auc_10: 0.6077 - val_binary_accuracy: 0.6408\n",
            "Epoch 123/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5341 - auc_10: 0.7511 - binary_accuracy: 0.7226 - val_loss: 0.6742 - val_auc_10: 0.6088 - val_binary_accuracy: 0.6488\n",
            "Epoch 124/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5341 - auc_10: 0.7515 - binary_accuracy: 0.7146 - val_loss: 0.6796 - val_auc_10: 0.6041 - val_binary_accuracy: 0.6434\n",
            "Epoch 125/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5382 - auc_10: 0.7485 - binary_accuracy: 0.7132 - val_loss: 0.6742 - val_auc_10: 0.6119 - val_binary_accuracy: 0.6434\n",
            "Epoch 126/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5390 - auc_10: 0.7492 - binary_accuracy: 0.7159 - val_loss: 0.6715 - val_auc_10: 0.6097 - val_binary_accuracy: 0.6649\n",
            "Epoch 127/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5240 - auc_10: 0.7668 - binary_accuracy: 0.7260 - val_loss: 0.6769 - val_auc_10: 0.6074 - val_binary_accuracy: 0.6595\n",
            "Epoch 128/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5236 - auc_10: 0.7663 - binary_accuracy: 0.7280 - val_loss: 0.6703 - val_auc_10: 0.6147 - val_binary_accuracy: 0.6622\n",
            "Epoch 129/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5357 - auc_10: 0.7482 - binary_accuracy: 0.7186 - val_loss: 0.6828 - val_auc_10: 0.6023 - val_binary_accuracy: 0.6595\n",
            "Epoch 130/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5360 - auc_10: 0.7468 - binary_accuracy: 0.7159 - val_loss: 0.6772 - val_auc_10: 0.6188 - val_binary_accuracy: 0.6515\n",
            "Epoch 131/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5295 - auc_10: 0.7534 - binary_accuracy: 0.7126 - val_loss: 0.6693 - val_auc_10: 0.6108 - val_binary_accuracy: 0.6595\n",
            "Epoch 132/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5234 - auc_10: 0.7611 - binary_accuracy: 0.7179 - val_loss: 0.6801 - val_auc_10: 0.6045 - val_binary_accuracy: 0.6676\n",
            "Epoch 133/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5284 - auc_10: 0.7594 - binary_accuracy: 0.7226 - val_loss: 0.6799 - val_auc_10: 0.6075 - val_binary_accuracy: 0.6595\n",
            "Epoch 134/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5240 - auc_10: 0.7601 - binary_accuracy: 0.7267 - val_loss: 0.6858 - val_auc_10: 0.5971 - val_binary_accuracy: 0.6542\n",
            "Epoch 135/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5347 - auc_10: 0.7472 - binary_accuracy: 0.7280 - val_loss: 0.6835 - val_auc_10: 0.6082 - val_binary_accuracy: 0.6622\n",
            "Epoch 136/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5219 - auc_10: 0.7609 - binary_accuracy: 0.7240 - val_loss: 0.6870 - val_auc_10: 0.6088 - val_binary_accuracy: 0.6649\n",
            "Epoch 137/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5231 - auc_10: 0.7641 - binary_accuracy: 0.7233 - val_loss: 0.6878 - val_auc_10: 0.6097 - val_binary_accuracy: 0.6488\n",
            "Epoch 138/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5179 - auc_10: 0.7638 - binary_accuracy: 0.7220 - val_loss: 0.6926 - val_auc_10: 0.6045 - val_binary_accuracy: 0.6595\n",
            "Epoch 139/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5168 - auc_10: 0.7745 - binary_accuracy: 0.7367 - val_loss: 0.6848 - val_auc_10: 0.6091 - val_binary_accuracy: 0.6676\n",
            "Epoch 140/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5319 - auc_10: 0.7513 - binary_accuracy: 0.7139 - val_loss: 0.6884 - val_auc_10: 0.6069 - val_binary_accuracy: 0.6676\n",
            "Epoch 141/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5204 - auc_10: 0.7649 - binary_accuracy: 0.7246 - val_loss: 0.7023 - val_auc_10: 0.5939 - val_binary_accuracy: 0.6488\n",
            "Epoch 142/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5167 - auc_10: 0.7696 - binary_accuracy: 0.7146 - val_loss: 0.6919 - val_auc_10: 0.6153 - val_binary_accuracy: 0.6568\n",
            "Epoch 143/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5149 - auc_10: 0.7700 - binary_accuracy: 0.7273 - val_loss: 0.6874 - val_auc_10: 0.6163 - val_binary_accuracy: 0.6676\n",
            "Epoch 144/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.5114 - auc_10: 0.7778 - binary_accuracy: 0.7267 - val_loss: 0.6949 - val_auc_10: 0.5994 - val_binary_accuracy: 0.6622\n",
            "Epoch 145/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5077 - auc_10: 0.7885 - binary_accuracy: 0.7347 - val_loss: 0.6966 - val_auc_10: 0.6053 - val_binary_accuracy: 0.6622\n",
            "Epoch 146/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5063 - auc_10: 0.7836 - binary_accuracy: 0.7461 - val_loss: 0.6952 - val_auc_10: 0.6087 - val_binary_accuracy: 0.6649\n",
            "Epoch 147/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5028 - auc_10: 0.7871 - binary_accuracy: 0.7354 - val_loss: 0.6998 - val_auc_10: 0.6073 - val_binary_accuracy: 0.6461\n",
            "Epoch 148/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5109 - auc_10: 0.7846 - binary_accuracy: 0.7381 - val_loss: 0.6954 - val_auc_10: 0.6118 - val_binary_accuracy: 0.6676\n",
            "Epoch 149/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5159 - auc_10: 0.7736 - binary_accuracy: 0.7220 - val_loss: 0.6928 - val_auc_10: 0.6107 - val_binary_accuracy: 0.6676\n",
            "Epoch 150/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5180 - auc_10: 0.7727 - binary_accuracy: 0.7340 - val_loss: 0.7012 - val_auc_10: 0.6080 - val_binary_accuracy: 0.6434\n",
            "Epoch 151/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5088 - auc_10: 0.7859 - binary_accuracy: 0.7475 - val_loss: 0.7050 - val_auc_10: 0.6069 - val_binary_accuracy: 0.6595\n",
            "Epoch 152/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.4996 - auc_10: 0.7878 - binary_accuracy: 0.7401 - val_loss: 0.6999 - val_auc_10: 0.6076 - val_binary_accuracy: 0.6622\n",
            "Epoch 153/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.4987 - auc_10: 0.7958 - binary_accuracy: 0.7414 - val_loss: 0.7064 - val_auc_10: 0.6014 - val_binary_accuracy: 0.6622\n",
            "Epoch 154/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.4955 - auc_10: 0.7965 - binary_accuracy: 0.7461 - val_loss: 0.7034 - val_auc_10: 0.6119 - val_binary_accuracy: 0.6568\n",
            "Epoch 155/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.4995 - auc_10: 0.7871 - binary_accuracy: 0.7408 - val_loss: 0.7028 - val_auc_10: 0.6132 - val_binary_accuracy: 0.6408\n",
            "Epoch 156/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.5010 - auc_10: 0.7901 - binary_accuracy: 0.7388 - val_loss: 0.7090 - val_auc_10: 0.6079 - val_binary_accuracy: 0.6702\n",
            "Epoch 157/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.4937 - auc_10: 0.7989 - binary_accuracy: 0.7435 - val_loss: 0.7049 - val_auc_10: 0.6124 - val_binary_accuracy: 0.6354\n",
            "Epoch 158/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.5060 - auc_10: 0.7858 - binary_accuracy: 0.7421 - val_loss: 0.7076 - val_auc_10: 0.6112 - val_binary_accuracy: 0.6488\n",
            "Epoch 159/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.4998 - auc_10: 0.7885 - binary_accuracy: 0.7394 - val_loss: 0.7239 - val_auc_10: 0.6063 - val_binary_accuracy: 0.6354\n",
            "Epoch 160/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.4941 - auc_10: 0.8000 - binary_accuracy: 0.7482 - val_loss: 0.7194 - val_auc_10: 0.6027 - val_binary_accuracy: 0.6461\n",
            "Epoch 161/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.4904 - auc_10: 0.8039 - binary_accuracy: 0.7475 - val_loss: 0.7143 - val_auc_10: 0.6067 - val_binary_accuracy: 0.6515\n",
            "Epoch 162/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.4964 - auc_10: 0.7968 - binary_accuracy: 0.7428 - val_loss: 0.7193 - val_auc_10: 0.6039 - val_binary_accuracy: 0.6381\n",
            "Epoch 163/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.4876 - auc_10: 0.8024 - binary_accuracy: 0.7468 - val_loss: 0.7132 - val_auc_10: 0.6088 - val_binary_accuracy: 0.6568\n",
            "Epoch 164/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.4909 - auc_10: 0.8046 - binary_accuracy: 0.7562 - val_loss: 0.7248 - val_auc_10: 0.6031 - val_binary_accuracy: 0.6568\n",
            "Epoch 165/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.4779 - auc_10: 0.8171 - binary_accuracy: 0.7643 - val_loss: 0.7307 - val_auc_10: 0.5911 - val_binary_accuracy: 0.6461\n",
            "Epoch 166/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.4739 - auc_10: 0.8236 - binary_accuracy: 0.7663 - val_loss: 0.7330 - val_auc_10: 0.5880 - val_binary_accuracy: 0.6408\n",
            "Epoch 167/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.4834 - auc_10: 0.8088 - binary_accuracy: 0.7542 - val_loss: 0.7238 - val_auc_10: 0.6010 - val_binary_accuracy: 0.6381\n",
            "Epoch 168/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.4802 - auc_10: 0.8115 - binary_accuracy: 0.7482 - val_loss: 0.7376 - val_auc_10: 0.5868 - val_binary_accuracy: 0.6676\n",
            "Epoch 169/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.4727 - auc_10: 0.8206 - binary_accuracy: 0.7616 - val_loss: 0.7269 - val_auc_10: 0.6013 - val_binary_accuracy: 0.6515\n",
            "Epoch 170/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.4736 - auc_10: 0.8253 - binary_accuracy: 0.7582 - val_loss: 0.7322 - val_auc_10: 0.5979 - val_binary_accuracy: 0.6568\n",
            "Epoch 171/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.4827 - auc_10: 0.8047 - binary_accuracy: 0.7488 - val_loss: 0.7371 - val_auc_10: 0.6012 - val_binary_accuracy: 0.6542\n",
            "Epoch 172/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.4805 - auc_10: 0.8090 - binary_accuracy: 0.7482 - val_loss: 0.7358 - val_auc_10: 0.6061 - val_binary_accuracy: 0.6542\n",
            "Epoch 173/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.4775 - auc_10: 0.8189 - binary_accuracy: 0.7703 - val_loss: 0.7322 - val_auc_10: 0.6072 - val_binary_accuracy: 0.6622\n",
            "Epoch 174/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.4828 - auc_10: 0.8035 - binary_accuracy: 0.7549 - val_loss: 0.7355 - val_auc_10: 0.6055 - val_binary_accuracy: 0.6354\n",
            "Epoch 175/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.4718 - auc_10: 0.8205 - binary_accuracy: 0.7629 - val_loss: 0.7416 - val_auc_10: 0.5965 - val_binary_accuracy: 0.6676\n",
            "Epoch 176/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.4699 - auc_10: 0.8208 - binary_accuracy: 0.7649 - val_loss: 0.7379 - val_auc_10: 0.6124 - val_binary_accuracy: 0.6515\n",
            "Epoch 177/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.4836 - auc_10: 0.8056 - binary_accuracy: 0.7602 - val_loss: 0.7426 - val_auc_10: 0.5943 - val_binary_accuracy: 0.6461\n",
            "Epoch 178/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.4608 - auc_10: 0.8358 - binary_accuracy: 0.7576 - val_loss: 0.7418 - val_auc_10: 0.6087 - val_binary_accuracy: 0.6568\n",
            "Epoch 179/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.4709 - auc_10: 0.8255 - binary_accuracy: 0.7676 - val_loss: 0.7348 - val_auc_10: 0.6073 - val_binary_accuracy: 0.6542\n",
            "Epoch 180/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.4642 - auc_10: 0.8296 - binary_accuracy: 0.7670 - val_loss: 0.7510 - val_auc_10: 0.5905 - val_binary_accuracy: 0.6434\n",
            "Epoch 181/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.4586 - auc_10: 0.8342 - binary_accuracy: 0.7690 - val_loss: 0.7497 - val_auc_10: 0.6048 - val_binary_accuracy: 0.6649\n",
            "Epoch 182/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.4597 - auc_10: 0.8297 - binary_accuracy: 0.7750 - val_loss: 0.7449 - val_auc_10: 0.6136 - val_binary_accuracy: 0.6488\n",
            "Epoch 183/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.4532 - auc_10: 0.8376 - binary_accuracy: 0.7555 - val_loss: 0.7559 - val_auc_10: 0.6062 - val_binary_accuracy: 0.6354\n",
            "Epoch 184/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.4578 - auc_10: 0.8360 - binary_accuracy: 0.7730 - val_loss: 0.7630 - val_auc_10: 0.5879 - val_binary_accuracy: 0.6408\n",
            "Epoch 185/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.4618 - auc_10: 0.8249 - binary_accuracy: 0.7508 - val_loss: 0.7463 - val_auc_10: 0.6079 - val_binary_accuracy: 0.6381\n",
            "Epoch 186/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.4629 - auc_10: 0.8278 - binary_accuracy: 0.7703 - val_loss: 0.7636 - val_auc_10: 0.5882 - val_binary_accuracy: 0.6488\n",
            "Epoch 187/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.4577 - auc_10: 0.8361 - binary_accuracy: 0.7717 - val_loss: 0.7550 - val_auc_10: 0.5998 - val_binary_accuracy: 0.6488\n",
            "Epoch 188/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.4707 - auc_10: 0.8217 - binary_accuracy: 0.7569 - val_loss: 0.7611 - val_auc_10: 0.5982 - val_binary_accuracy: 0.6461\n",
            "Epoch 189/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.4698 - auc_10: 0.8199 - binary_accuracy: 0.7515 - val_loss: 0.7566 - val_auc_10: 0.5973 - val_binary_accuracy: 0.6461\n",
            "Epoch 190/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.4656 - auc_10: 0.8276 - binary_accuracy: 0.7596 - val_loss: 0.7648 - val_auc_10: 0.5961 - val_binary_accuracy: 0.6515\n",
            "Epoch 191/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.4486 - auc_10: 0.8471 - binary_accuracy: 0.7757 - val_loss: 0.7613 - val_auc_10: 0.6075 - val_binary_accuracy: 0.6273\n",
            "Epoch 192/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.4542 - auc_10: 0.8366 - binary_accuracy: 0.7737 - val_loss: 0.7578 - val_auc_10: 0.6098 - val_binary_accuracy: 0.6434\n",
            "Epoch 193/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.4485 - auc_10: 0.8425 - binary_accuracy: 0.7717 - val_loss: 0.7753 - val_auc_10: 0.5995 - val_binary_accuracy: 0.6166\n",
            "Epoch 194/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.4536 - auc_10: 0.8361 - binary_accuracy: 0.7643 - val_loss: 0.7677 - val_auc_10: 0.5949 - val_binary_accuracy: 0.6408\n",
            "Epoch 195/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.4527 - auc_10: 0.8389 - binary_accuracy: 0.7717 - val_loss: 0.7670 - val_auc_10: 0.5960 - val_binary_accuracy: 0.6300\n",
            "Epoch 196/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.4298 - auc_10: 0.8609 - binary_accuracy: 0.7898 - val_loss: 0.7707 - val_auc_10: 0.6044 - val_binary_accuracy: 0.6434\n",
            "Epoch 197/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.4356 - auc_10: 0.8538 - binary_accuracy: 0.7871 - val_loss: 0.7714 - val_auc_10: 0.6013 - val_binary_accuracy: 0.6327\n",
            "Epoch 198/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.4464 - auc_10: 0.8442 - binary_accuracy: 0.7898 - val_loss: 0.7730 - val_auc_10: 0.5976 - val_binary_accuracy: 0.6381\n",
            "Epoch 199/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.4427 - auc_10: 0.8485 - binary_accuracy: 0.7757 - val_loss: 0.7756 - val_auc_10: 0.6010 - val_binary_accuracy: 0.6327\n",
            "Epoch 200/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 0.4447 - auc_10: 0.8458 - binary_accuracy: 0.7690 - val_loss: 0.7778 - val_auc_10: 0.5919 - val_binary_accuracy: 0.6273\n",
            "Epoch 1/200\n",
            "47/47 [==============================] - 3s 24ms/step - loss: 0.6488 - auc_11: 0.5599 - binary_accuracy: 0.6514 - val_loss: 0.6134 - val_auc_11: 0.6500 - val_binary_accuracy: 0.6676\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.6251 - auc_11: 0.5747 - binary_accuracy: 0.6662 - val_loss: 0.6068 - val_auc_11: 0.6511 - val_binary_accuracy: 0.6676\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.6240 - auc_11: 0.5878 - binary_accuracy: 0.6662 - val_loss: 0.6114 - val_auc_11: 0.6658 - val_binary_accuracy: 0.6676\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.6245 - auc_11: 0.5915 - binary_accuracy: 0.6669 - val_loss: 0.6036 - val_auc_11: 0.6658 - val_binary_accuracy: 0.6676\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.6228 - auc_11: 0.5916 - binary_accuracy: 0.6689 - val_loss: 0.6055 - val_auc_11: 0.6658 - val_binary_accuracy: 0.6676\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.6229 - auc_11: 0.5987 - binary_accuracy: 0.6662 - val_loss: 0.6078 - val_auc_11: 0.6448 - val_binary_accuracy: 0.6676\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.6190 - auc_11: 0.6032 - binary_accuracy: 0.6669 - val_loss: 0.6067 - val_auc_11: 0.6548 - val_binary_accuracy: 0.6676\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.6198 - auc_11: 0.6043 - binary_accuracy: 0.6716 - val_loss: 0.6050 - val_auc_11: 0.6585 - val_binary_accuracy: 0.6702\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.6196 - auc_11: 0.5996 - binary_accuracy: 0.6702 - val_loss: 0.6027 - val_auc_11: 0.6579 - val_binary_accuracy: 0.6702\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.6187 - auc_11: 0.6038 - binary_accuracy: 0.6723 - val_loss: 0.6054 - val_auc_11: 0.6481 - val_binary_accuracy: 0.6676\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.6145 - auc_11: 0.6163 - binary_accuracy: 0.6696 - val_loss: 0.6035 - val_auc_11: 0.6559 - val_binary_accuracy: 0.6676\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.6157 - auc_11: 0.6126 - binary_accuracy: 0.6635 - val_loss: 0.6033 - val_auc_11: 0.6539 - val_binary_accuracy: 0.6756\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.6120 - auc_11: 0.6197 - binary_accuracy: 0.6669 - val_loss: 0.6041 - val_auc_11: 0.6453 - val_binary_accuracy: 0.6756\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.6157 - auc_11: 0.6129 - binary_accuracy: 0.6662 - val_loss: 0.6066 - val_auc_11: 0.6346 - val_binary_accuracy: 0.6729\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.6138 - auc_11: 0.6202 - binary_accuracy: 0.6588 - val_loss: 0.6118 - val_auc_11: 0.6249 - val_binary_accuracy: 0.6676\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.6114 - auc_11: 0.6271 - binary_accuracy: 0.6635 - val_loss: 0.6090 - val_auc_11: 0.6297 - val_binary_accuracy: 0.6756\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.6136 - auc_11: 0.6145 - binary_accuracy: 0.6608 - val_loss: 0.6108 - val_auc_11: 0.6281 - val_binary_accuracy: 0.6702\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.6100 - auc_11: 0.6253 - binary_accuracy: 0.6642 - val_loss: 0.6093 - val_auc_11: 0.6304 - val_binary_accuracy: 0.6729\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.6095 - auc_11: 0.6316 - binary_accuracy: 0.6642 - val_loss: 0.6092 - val_auc_11: 0.6400 - val_binary_accuracy: 0.6756\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.6094 - auc_11: 0.6317 - binary_accuracy: 0.6682 - val_loss: 0.6143 - val_auc_11: 0.6252 - val_binary_accuracy: 0.6676\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.6098 - auc_11: 0.6231 - binary_accuracy: 0.6729 - val_loss: 0.6124 - val_auc_11: 0.6354 - val_binary_accuracy: 0.6783\n",
            "Epoch 22/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.6069 - auc_11: 0.6379 - binary_accuracy: 0.6709 - val_loss: 0.6152 - val_auc_11: 0.6193 - val_binary_accuracy: 0.6676\n",
            "Epoch 23/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.6112 - auc_11: 0.6301 - binary_accuracy: 0.6575 - val_loss: 0.6157 - val_auc_11: 0.6203 - val_binary_accuracy: 0.6676\n",
            "Epoch 24/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.6069 - auc_11: 0.6262 - binary_accuracy: 0.6716 - val_loss: 0.6192 - val_auc_11: 0.6162 - val_binary_accuracy: 0.6702\n",
            "Epoch 25/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.6086 - auc_11: 0.6312 - binary_accuracy: 0.6629 - val_loss: 0.6203 - val_auc_11: 0.6196 - val_binary_accuracy: 0.6676\n",
            "Epoch 26/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.6041 - auc_11: 0.6437 - binary_accuracy: 0.6682 - val_loss: 0.6196 - val_auc_11: 0.6193 - val_binary_accuracy: 0.6676\n",
            "Epoch 27/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.6041 - auc_11: 0.6435 - binary_accuracy: 0.6655 - val_loss: 0.6220 - val_auc_11: 0.6018 - val_binary_accuracy: 0.6702\n",
            "Epoch 28/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5991 - auc_11: 0.6476 - binary_accuracy: 0.6763 - val_loss: 0.6212 - val_auc_11: 0.6289 - val_binary_accuracy: 0.6756\n",
            "Epoch 29/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.6042 - auc_11: 0.6356 - binary_accuracy: 0.6682 - val_loss: 0.6284 - val_auc_11: 0.5986 - val_binary_accuracy: 0.6649\n",
            "Epoch 30/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5981 - auc_11: 0.6594 - binary_accuracy: 0.6736 - val_loss: 0.6266 - val_auc_11: 0.6176 - val_binary_accuracy: 0.6649\n",
            "Epoch 31/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.6018 - auc_11: 0.6459 - binary_accuracy: 0.6689 - val_loss: 0.6294 - val_auc_11: 0.6114 - val_binary_accuracy: 0.6702\n",
            "Epoch 32/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.6004 - auc_11: 0.6526 - binary_accuracy: 0.6608 - val_loss: 0.6264 - val_auc_11: 0.6264 - val_binary_accuracy: 0.6729\n",
            "Epoch 33/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.6000 - auc_11: 0.6457 - binary_accuracy: 0.6736 - val_loss: 0.6299 - val_auc_11: 0.6134 - val_binary_accuracy: 0.6783\n",
            "Epoch 34/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.6009 - auc_11: 0.6455 - binary_accuracy: 0.6649 - val_loss: 0.6245 - val_auc_11: 0.6266 - val_binary_accuracy: 0.6756\n",
            "Epoch 35/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5986 - auc_11: 0.6510 - binary_accuracy: 0.6776 - val_loss: 0.6296 - val_auc_11: 0.6066 - val_binary_accuracy: 0.6756\n",
            "Epoch 36/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5992 - auc_11: 0.6520 - binary_accuracy: 0.6716 - val_loss: 0.6294 - val_auc_11: 0.6100 - val_binary_accuracy: 0.6729\n",
            "Epoch 37/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.6017 - auc_11: 0.6476 - binary_accuracy: 0.6696 - val_loss: 0.6338 - val_auc_11: 0.6126 - val_binary_accuracy: 0.6676\n",
            "Epoch 38/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5931 - auc_11: 0.6675 - binary_accuracy: 0.6763 - val_loss: 0.6301 - val_auc_11: 0.6107 - val_binary_accuracy: 0.6756\n",
            "Epoch 39/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5967 - auc_11: 0.6570 - binary_accuracy: 0.6689 - val_loss: 0.6355 - val_auc_11: 0.6034 - val_binary_accuracy: 0.6649\n",
            "Epoch 40/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5975 - auc_11: 0.6516 - binary_accuracy: 0.6729 - val_loss: 0.6347 - val_auc_11: 0.6157 - val_binary_accuracy: 0.6756\n",
            "Epoch 41/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5953 - auc_11: 0.6600 - binary_accuracy: 0.6756 - val_loss: 0.6353 - val_auc_11: 0.6099 - val_binary_accuracy: 0.6729\n",
            "Epoch 42/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5901 - auc_11: 0.6679 - binary_accuracy: 0.6709 - val_loss: 0.6366 - val_auc_11: 0.6180 - val_binary_accuracy: 0.6702\n",
            "Epoch 43/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5921 - auc_11: 0.6625 - binary_accuracy: 0.6709 - val_loss: 0.6312 - val_auc_11: 0.6193 - val_binary_accuracy: 0.6756\n",
            "Epoch 44/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5909 - auc_11: 0.6637 - binary_accuracy: 0.6749 - val_loss: 0.6403 - val_auc_11: 0.6123 - val_binary_accuracy: 0.6702\n",
            "Epoch 45/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5907 - auc_11: 0.6694 - binary_accuracy: 0.6702 - val_loss: 0.6390 - val_auc_11: 0.6106 - val_binary_accuracy: 0.6676\n",
            "Epoch 46/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5881 - auc_11: 0.6717 - binary_accuracy: 0.6749 - val_loss: 0.6327 - val_auc_11: 0.6117 - val_binary_accuracy: 0.6649\n",
            "Epoch 47/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5904 - auc_11: 0.6707 - binary_accuracy: 0.6716 - val_loss: 0.6431 - val_auc_11: 0.6034 - val_binary_accuracy: 0.6542\n",
            "Epoch 48/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5887 - auc_11: 0.6705 - binary_accuracy: 0.6810 - val_loss: 0.6345 - val_auc_11: 0.6294 - val_binary_accuracy: 0.6676\n",
            "Epoch 49/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5859 - auc_11: 0.6766 - binary_accuracy: 0.6810 - val_loss: 0.6421 - val_auc_11: 0.6184 - val_binary_accuracy: 0.6595\n",
            "Epoch 50/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5906 - auc_11: 0.6645 - binary_accuracy: 0.6749 - val_loss: 0.6372 - val_auc_11: 0.6289 - val_binary_accuracy: 0.6783\n",
            "Epoch 51/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5893 - auc_11: 0.6693 - binary_accuracy: 0.6776 - val_loss: 0.6419 - val_auc_11: 0.6176 - val_binary_accuracy: 0.6649\n",
            "Epoch 52/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5851 - auc_11: 0.6779 - binary_accuracy: 0.6810 - val_loss: 0.6430 - val_auc_11: 0.6143 - val_binary_accuracy: 0.6622\n",
            "Epoch 53/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5873 - auc_11: 0.6728 - binary_accuracy: 0.6790 - val_loss: 0.6408 - val_auc_11: 0.6223 - val_binary_accuracy: 0.6649\n",
            "Epoch 54/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5846 - auc_11: 0.6741 - binary_accuracy: 0.6736 - val_loss: 0.6413 - val_auc_11: 0.6106 - val_binary_accuracy: 0.6649\n",
            "Epoch 55/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5816 - auc_11: 0.6838 - binary_accuracy: 0.6817 - val_loss: 0.6421 - val_auc_11: 0.6162 - val_binary_accuracy: 0.6676\n",
            "Epoch 56/200\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 0.5820 - auc_11: 0.6813 - binary_accuracy: 0.6844 - val_loss: 0.6473 - val_auc_11: 0.6142 - val_binary_accuracy: 0.6676\n",
            "Epoch 57/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5857 - auc_11: 0.6721 - binary_accuracy: 0.6756 - val_loss: 0.6459 - val_auc_11: 0.6113 - val_binary_accuracy: 0.6595\n",
            "Epoch 58/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5805 - auc_11: 0.6764 - binary_accuracy: 0.6770 - val_loss: 0.6470 - val_auc_11: 0.6199 - val_binary_accuracy: 0.6568\n",
            "Epoch 59/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5821 - auc_11: 0.6802 - binary_accuracy: 0.6723 - val_loss: 0.6439 - val_auc_11: 0.6173 - val_binary_accuracy: 0.6649\n",
            "Epoch 60/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5728 - auc_11: 0.6996 - binary_accuracy: 0.6951 - val_loss: 0.6463 - val_auc_11: 0.6250 - val_binary_accuracy: 0.6676\n",
            "Epoch 61/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5840 - auc_11: 0.6765 - binary_accuracy: 0.6924 - val_loss: 0.6478 - val_auc_11: 0.6103 - val_binary_accuracy: 0.6622\n",
            "Epoch 62/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5810 - auc_11: 0.6830 - binary_accuracy: 0.6891 - val_loss: 0.6491 - val_auc_11: 0.6100 - val_binary_accuracy: 0.6649\n",
            "Epoch 63/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5694 - auc_11: 0.6989 - binary_accuracy: 0.6803 - val_loss: 0.6530 - val_auc_11: 0.6113 - val_binary_accuracy: 0.6595\n",
            "Epoch 64/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5805 - auc_11: 0.6813 - binary_accuracy: 0.6817 - val_loss: 0.6469 - val_auc_11: 0.6221 - val_binary_accuracy: 0.6649\n",
            "Epoch 65/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5696 - auc_11: 0.6959 - binary_accuracy: 0.6911 - val_loss: 0.6490 - val_auc_11: 0.6159 - val_binary_accuracy: 0.6568\n",
            "Epoch 66/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5661 - auc_11: 0.7076 - binary_accuracy: 0.6797 - val_loss: 0.6457 - val_auc_11: 0.6271 - val_binary_accuracy: 0.6729\n",
            "Epoch 67/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5707 - auc_11: 0.7028 - binary_accuracy: 0.6924 - val_loss: 0.6530 - val_auc_11: 0.6177 - val_binary_accuracy: 0.6729\n",
            "Epoch 68/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5752 - auc_11: 0.6872 - binary_accuracy: 0.6844 - val_loss: 0.6541 - val_auc_11: 0.6141 - val_binary_accuracy: 0.6676\n",
            "Epoch 69/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5676 - auc_11: 0.7039 - binary_accuracy: 0.6944 - val_loss: 0.6607 - val_auc_11: 0.6120 - val_binary_accuracy: 0.6595\n",
            "Epoch 70/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5698 - auc_11: 0.6955 - binary_accuracy: 0.6924 - val_loss: 0.6519 - val_auc_11: 0.6180 - val_binary_accuracy: 0.6729\n",
            "Epoch 71/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5685 - auc_11: 0.7044 - binary_accuracy: 0.6857 - val_loss: 0.6569 - val_auc_11: 0.6101 - val_binary_accuracy: 0.6568\n",
            "Epoch 72/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5686 - auc_11: 0.7011 - binary_accuracy: 0.6877 - val_loss: 0.6609 - val_auc_11: 0.6094 - val_binary_accuracy: 0.6649\n",
            "Epoch 73/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5628 - auc_11: 0.7090 - binary_accuracy: 0.7052 - val_loss: 0.6637 - val_auc_11: 0.5963 - val_binary_accuracy: 0.6515\n",
            "Epoch 74/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5615 - auc_11: 0.7137 - binary_accuracy: 0.6911 - val_loss: 0.6579 - val_auc_11: 0.6116 - val_binary_accuracy: 0.6461\n",
            "Epoch 75/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5596 - auc_11: 0.7137 - binary_accuracy: 0.6971 - val_loss: 0.6668 - val_auc_11: 0.6044 - val_binary_accuracy: 0.6595\n",
            "Epoch 76/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5652 - auc_11: 0.6995 - binary_accuracy: 0.6931 - val_loss: 0.6592 - val_auc_11: 0.6061 - val_binary_accuracy: 0.6542\n",
            "Epoch 77/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5510 - auc_11: 0.7226 - binary_accuracy: 0.6985 - val_loss: 0.6606 - val_auc_11: 0.6204 - val_binary_accuracy: 0.6568\n",
            "Epoch 78/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5611 - auc_11: 0.7124 - binary_accuracy: 0.7045 - val_loss: 0.6752 - val_auc_11: 0.6032 - val_binary_accuracy: 0.6488\n",
            "Epoch 79/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5537 - auc_11: 0.7179 - binary_accuracy: 0.6958 - val_loss: 0.6608 - val_auc_11: 0.6100 - val_binary_accuracy: 0.6568\n",
            "Epoch 80/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5481 - auc_11: 0.7322 - binary_accuracy: 0.7065 - val_loss: 0.6662 - val_auc_11: 0.6110 - val_binary_accuracy: 0.6622\n",
            "Epoch 81/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5496 - auc_11: 0.7311 - binary_accuracy: 0.6978 - val_loss: 0.6674 - val_auc_11: 0.6134 - val_binary_accuracy: 0.6595\n",
            "Epoch 82/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5529 - auc_11: 0.7215 - binary_accuracy: 0.6884 - val_loss: 0.6750 - val_auc_11: 0.6029 - val_binary_accuracy: 0.6488\n",
            "Epoch 83/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5526 - auc_11: 0.7265 - binary_accuracy: 0.6978 - val_loss: 0.6728 - val_auc_11: 0.6072 - val_binary_accuracy: 0.6542\n",
            "Epoch 84/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5413 - auc_11: 0.7402 - binary_accuracy: 0.7139 - val_loss: 0.6762 - val_auc_11: 0.6071 - val_binary_accuracy: 0.6568\n",
            "Epoch 85/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5554 - auc_11: 0.7196 - binary_accuracy: 0.6998 - val_loss: 0.6698 - val_auc_11: 0.6048 - val_binary_accuracy: 0.6595\n",
            "Epoch 86/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5416 - auc_11: 0.7351 - binary_accuracy: 0.7132 - val_loss: 0.6724 - val_auc_11: 0.6134 - val_binary_accuracy: 0.6622\n",
            "Epoch 87/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5446 - auc_11: 0.7361 - binary_accuracy: 0.7025 - val_loss: 0.6728 - val_auc_11: 0.6120 - val_binary_accuracy: 0.6434\n",
            "Epoch 88/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5389 - auc_11: 0.7419 - binary_accuracy: 0.7079 - val_loss: 0.6752 - val_auc_11: 0.6085 - val_binary_accuracy: 0.6595\n",
            "Epoch 89/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5498 - auc_11: 0.7330 - binary_accuracy: 0.6938 - val_loss: 0.6786 - val_auc_11: 0.6121 - val_binary_accuracy: 0.6595\n",
            "Epoch 90/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5412 - auc_11: 0.7340 - binary_accuracy: 0.7099 - val_loss: 0.6758 - val_auc_11: 0.6171 - val_binary_accuracy: 0.6515\n",
            "Epoch 91/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5416 - auc_11: 0.7413 - binary_accuracy: 0.7092 - val_loss: 0.6769 - val_auc_11: 0.6178 - val_binary_accuracy: 0.6461\n",
            "Epoch 92/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5405 - auc_11: 0.7386 - binary_accuracy: 0.7005 - val_loss: 0.6759 - val_auc_11: 0.6155 - val_binary_accuracy: 0.6595\n",
            "Epoch 93/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5325 - auc_11: 0.7543 - binary_accuracy: 0.7233 - val_loss: 0.6813 - val_auc_11: 0.6129 - val_binary_accuracy: 0.6488\n",
            "Epoch 94/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5365 - auc_11: 0.7451 - binary_accuracy: 0.7099 - val_loss: 0.6879 - val_auc_11: 0.6085 - val_binary_accuracy: 0.6461\n",
            "Epoch 95/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5326 - auc_11: 0.7449 - binary_accuracy: 0.7179 - val_loss: 0.6922 - val_auc_11: 0.6026 - val_binary_accuracy: 0.6461\n",
            "Epoch 96/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5304 - auc_11: 0.7591 - binary_accuracy: 0.7052 - val_loss: 0.6868 - val_auc_11: 0.6099 - val_binary_accuracy: 0.6595\n",
            "Epoch 97/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5267 - auc_11: 0.7652 - binary_accuracy: 0.7199 - val_loss: 0.6932 - val_auc_11: 0.6036 - val_binary_accuracy: 0.6568\n",
            "Epoch 98/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5260 - auc_11: 0.7595 - binary_accuracy: 0.7280 - val_loss: 0.6909 - val_auc_11: 0.6115 - val_binary_accuracy: 0.6676\n",
            "Epoch 99/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5349 - auc_11: 0.7476 - binary_accuracy: 0.7105 - val_loss: 0.6929 - val_auc_11: 0.6121 - val_binary_accuracy: 0.6300\n",
            "Epoch 100/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5213 - auc_11: 0.7681 - binary_accuracy: 0.7347 - val_loss: 0.6939 - val_auc_11: 0.5999 - val_binary_accuracy: 0.6488\n",
            "Epoch 101/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5226 - auc_11: 0.7638 - binary_accuracy: 0.7260 - val_loss: 0.7046 - val_auc_11: 0.6012 - val_binary_accuracy: 0.6408\n",
            "Epoch 102/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5233 - auc_11: 0.7602 - binary_accuracy: 0.7166 - val_loss: 0.6955 - val_auc_11: 0.6113 - val_binary_accuracy: 0.6408\n",
            "Epoch 103/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5241 - auc_11: 0.7662 - binary_accuracy: 0.7213 - val_loss: 0.7067 - val_auc_11: 0.6051 - val_binary_accuracy: 0.6461\n",
            "Epoch 104/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5173 - auc_11: 0.7695 - binary_accuracy: 0.7253 - val_loss: 0.6915 - val_auc_11: 0.6133 - val_binary_accuracy: 0.6461\n",
            "Epoch 105/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5149 - auc_11: 0.7755 - binary_accuracy: 0.7408 - val_loss: 0.6988 - val_auc_11: 0.6133 - val_binary_accuracy: 0.6542\n",
            "Epoch 106/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5218 - auc_11: 0.7683 - binary_accuracy: 0.7334 - val_loss: 0.6911 - val_auc_11: 0.6141 - val_binary_accuracy: 0.6354\n",
            "Epoch 107/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4997 - auc_11: 0.7899 - binary_accuracy: 0.7414 - val_loss: 0.7061 - val_auc_11: 0.6095 - val_binary_accuracy: 0.6488\n",
            "Epoch 108/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5137 - auc_11: 0.7723 - binary_accuracy: 0.7233 - val_loss: 0.7015 - val_auc_11: 0.6118 - val_binary_accuracy: 0.6515\n",
            "Epoch 109/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5111 - auc_11: 0.7773 - binary_accuracy: 0.7367 - val_loss: 0.7033 - val_auc_11: 0.6093 - val_binary_accuracy: 0.6595\n",
            "Epoch 110/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5100 - auc_11: 0.7794 - binary_accuracy: 0.7260 - val_loss: 0.7135 - val_auc_11: 0.6029 - val_binary_accuracy: 0.6568\n",
            "Epoch 111/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5050 - auc_11: 0.7847 - binary_accuracy: 0.7347 - val_loss: 0.6993 - val_auc_11: 0.6182 - val_binary_accuracy: 0.6515\n",
            "Epoch 112/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5015 - auc_11: 0.7902 - binary_accuracy: 0.7320 - val_loss: 0.7015 - val_auc_11: 0.6123 - val_binary_accuracy: 0.6676\n",
            "Epoch 113/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.4934 - auc_11: 0.7973 - binary_accuracy: 0.7488 - val_loss: 0.7129 - val_auc_11: 0.6157 - val_binary_accuracy: 0.6676\n",
            "Epoch 114/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4904 - auc_11: 0.8036 - binary_accuracy: 0.7401 - val_loss: 0.7144 - val_auc_11: 0.6130 - val_binary_accuracy: 0.6515\n",
            "Epoch 115/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.5035 - auc_11: 0.7869 - binary_accuracy: 0.7347 - val_loss: 0.7172 - val_auc_11: 0.6124 - val_binary_accuracy: 0.6568\n",
            "Epoch 116/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.5029 - auc_11: 0.7872 - binary_accuracy: 0.7367 - val_loss: 0.7171 - val_auc_11: 0.6182 - val_binary_accuracy: 0.6434\n",
            "Epoch 117/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4874 - auc_11: 0.8061 - binary_accuracy: 0.7482 - val_loss: 0.7146 - val_auc_11: 0.6196 - val_binary_accuracy: 0.6729\n",
            "Epoch 118/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.4953 - auc_11: 0.7963 - binary_accuracy: 0.7401 - val_loss: 0.7072 - val_auc_11: 0.6278 - val_binary_accuracy: 0.6568\n",
            "Epoch 119/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4877 - auc_11: 0.8129 - binary_accuracy: 0.7488 - val_loss: 0.7205 - val_auc_11: 0.6114 - val_binary_accuracy: 0.6408\n",
            "Epoch 120/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4903 - auc_11: 0.8045 - binary_accuracy: 0.7428 - val_loss: 0.7058 - val_auc_11: 0.6252 - val_binary_accuracy: 0.6676\n",
            "Epoch 121/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.4869 - auc_11: 0.8041 - binary_accuracy: 0.7441 - val_loss: 0.7091 - val_auc_11: 0.6218 - val_binary_accuracy: 0.6568\n",
            "Epoch 122/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.4847 - auc_11: 0.8038 - binary_accuracy: 0.7502 - val_loss: 0.7100 - val_auc_11: 0.6197 - val_binary_accuracy: 0.6461\n",
            "Epoch 123/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.4795 - auc_11: 0.8141 - binary_accuracy: 0.7488 - val_loss: 0.7254 - val_auc_11: 0.6148 - val_binary_accuracy: 0.6300\n",
            "Epoch 124/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4834 - auc_11: 0.8112 - binary_accuracy: 0.7475 - val_loss: 0.7103 - val_auc_11: 0.6313 - val_binary_accuracy: 0.6702\n",
            "Epoch 125/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.4908 - auc_11: 0.7951 - binary_accuracy: 0.7408 - val_loss: 0.7229 - val_auc_11: 0.6251 - val_binary_accuracy: 0.6542\n",
            "Epoch 126/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4750 - auc_11: 0.8156 - binary_accuracy: 0.7582 - val_loss: 0.7274 - val_auc_11: 0.6184 - val_binary_accuracy: 0.6783\n",
            "Epoch 127/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4918 - auc_11: 0.7938 - binary_accuracy: 0.7428 - val_loss: 0.7208 - val_auc_11: 0.6110 - val_binary_accuracy: 0.6488\n",
            "Epoch 128/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4743 - auc_11: 0.8178 - binary_accuracy: 0.7609 - val_loss: 0.7263 - val_auc_11: 0.6184 - val_binary_accuracy: 0.6300\n",
            "Epoch 129/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.4654 - auc_11: 0.8275 - binary_accuracy: 0.7616 - val_loss: 0.7367 - val_auc_11: 0.6100 - val_binary_accuracy: 0.6702\n",
            "Epoch 130/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4672 - auc_11: 0.8248 - binary_accuracy: 0.7602 - val_loss: 0.7417 - val_auc_11: 0.6135 - val_binary_accuracy: 0.6461\n",
            "Epoch 131/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.4670 - auc_11: 0.8228 - binary_accuracy: 0.7555 - val_loss: 0.7378 - val_auc_11: 0.6212 - val_binary_accuracy: 0.6327\n",
            "Epoch 132/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4602 - auc_11: 0.8329 - binary_accuracy: 0.7703 - val_loss: 0.7280 - val_auc_11: 0.6342 - val_binary_accuracy: 0.6461\n",
            "Epoch 133/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4689 - auc_11: 0.8250 - binary_accuracy: 0.7696 - val_loss: 0.7151 - val_auc_11: 0.6338 - val_binary_accuracy: 0.6568\n",
            "Epoch 134/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4650 - auc_11: 0.8265 - binary_accuracy: 0.7616 - val_loss: 0.7472 - val_auc_11: 0.6226 - val_binary_accuracy: 0.6434\n",
            "Epoch 135/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.4715 - auc_11: 0.8203 - binary_accuracy: 0.7576 - val_loss: 0.7400 - val_auc_11: 0.6301 - val_binary_accuracy: 0.6622\n",
            "Epoch 136/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4612 - auc_11: 0.8311 - binary_accuracy: 0.7609 - val_loss: 0.7409 - val_auc_11: 0.6142 - val_binary_accuracy: 0.6327\n",
            "Epoch 137/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4420 - auc_11: 0.8513 - binary_accuracy: 0.7690 - val_loss: 0.7452 - val_auc_11: 0.6255 - val_binary_accuracy: 0.6649\n",
            "Epoch 138/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.4538 - auc_11: 0.8371 - binary_accuracy: 0.7764 - val_loss: 0.7593 - val_auc_11: 0.6090 - val_binary_accuracy: 0.6354\n",
            "Epoch 139/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4541 - auc_11: 0.8369 - binary_accuracy: 0.7663 - val_loss: 0.7311 - val_auc_11: 0.6325 - val_binary_accuracy: 0.6461\n",
            "Epoch 140/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4541 - auc_11: 0.8361 - binary_accuracy: 0.7717 - val_loss: 0.7314 - val_auc_11: 0.6249 - val_binary_accuracy: 0.6300\n",
            "Epoch 141/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.4450 - auc_11: 0.8438 - binary_accuracy: 0.7743 - val_loss: 0.7328 - val_auc_11: 0.6329 - val_binary_accuracy: 0.6568\n",
            "Epoch 142/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4465 - auc_11: 0.8436 - binary_accuracy: 0.7737 - val_loss: 0.7767 - val_auc_11: 0.5939 - val_binary_accuracy: 0.6220\n",
            "Epoch 143/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.4465 - auc_11: 0.8435 - binary_accuracy: 0.7750 - val_loss: 0.7405 - val_auc_11: 0.6295 - val_binary_accuracy: 0.6327\n",
            "Epoch 144/200\n",
            "47/47 [==============================] - 0s 11ms/step - loss: 0.4409 - auc_11: 0.8496 - binary_accuracy: 0.7784 - val_loss: 0.7440 - val_auc_11: 0.6366 - val_binary_accuracy: 0.6595\n",
            "Epoch 145/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.4645 - auc_11: 0.8300 - binary_accuracy: 0.7764 - val_loss: 0.7477 - val_auc_11: 0.6238 - val_binary_accuracy: 0.6247\n",
            "Epoch 146/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4348 - auc_11: 0.8538 - binary_accuracy: 0.7764 - val_loss: 0.7510 - val_auc_11: 0.6217 - val_binary_accuracy: 0.6247\n",
            "Epoch 147/200\n",
            "47/47 [==============================] - 0s 11ms/step - loss: 0.4311 - auc_11: 0.8568 - binary_accuracy: 0.7811 - val_loss: 0.7627 - val_auc_11: 0.6214 - val_binary_accuracy: 0.6273\n",
            "Epoch 148/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4217 - auc_11: 0.8651 - binary_accuracy: 0.7925 - val_loss: 0.7337 - val_auc_11: 0.6347 - val_binary_accuracy: 0.6354\n",
            "Epoch 149/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.4417 - auc_11: 0.8445 - binary_accuracy: 0.7871 - val_loss: 0.7624 - val_auc_11: 0.6151 - val_binary_accuracy: 0.6461\n",
            "Epoch 150/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.4463 - auc_11: 0.8380 - binary_accuracy: 0.7817 - val_loss: 0.7554 - val_auc_11: 0.6314 - val_binary_accuracy: 0.6408\n",
            "Epoch 151/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.4340 - auc_11: 0.8552 - binary_accuracy: 0.7871 - val_loss: 0.7455 - val_auc_11: 0.6189 - val_binary_accuracy: 0.6247\n",
            "Epoch 152/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.4303 - auc_11: 0.8576 - binary_accuracy: 0.7851 - val_loss: 0.7584 - val_auc_11: 0.6254 - val_binary_accuracy: 0.6381\n",
            "Epoch 153/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4177 - auc_11: 0.8669 - binary_accuracy: 0.7844 - val_loss: 0.7583 - val_auc_11: 0.6233 - val_binary_accuracy: 0.6381\n",
            "Epoch 154/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.4159 - auc_11: 0.8705 - binary_accuracy: 0.7938 - val_loss: 0.7556 - val_auc_11: 0.6269 - val_binary_accuracy: 0.6542\n",
            "Epoch 155/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4345 - auc_11: 0.8528 - binary_accuracy: 0.7750 - val_loss: 0.7760 - val_auc_11: 0.6182 - val_binary_accuracy: 0.6434\n",
            "Epoch 156/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.4204 - auc_11: 0.8633 - binary_accuracy: 0.7864 - val_loss: 0.7640 - val_auc_11: 0.6338 - val_binary_accuracy: 0.6568\n",
            "Epoch 157/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4188 - auc_11: 0.8676 - binary_accuracy: 0.8005 - val_loss: 0.7880 - val_auc_11: 0.6226 - val_binary_accuracy: 0.6327\n",
            "Epoch 158/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.4219 - auc_11: 0.8645 - binary_accuracy: 0.7911 - val_loss: 0.7545 - val_auc_11: 0.6361 - val_binary_accuracy: 0.6488\n",
            "Epoch 159/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.3994 - auc_11: 0.8832 - binary_accuracy: 0.8059 - val_loss: 0.7786 - val_auc_11: 0.6258 - val_binary_accuracy: 0.6434\n",
            "Epoch 160/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4151 - auc_11: 0.8657 - binary_accuracy: 0.7945 - val_loss: 0.7861 - val_auc_11: 0.6158 - val_binary_accuracy: 0.6327\n",
            "Epoch 161/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4176 - auc_11: 0.8703 - binary_accuracy: 0.8039 - val_loss: 0.7889 - val_auc_11: 0.6058 - val_binary_accuracy: 0.6220\n",
            "Epoch 162/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.4193 - auc_11: 0.8639 - binary_accuracy: 0.7824 - val_loss: 0.7894 - val_auc_11: 0.6109 - val_binary_accuracy: 0.6434\n",
            "Epoch 163/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.4063 - auc_11: 0.8752 - binary_accuracy: 0.7871 - val_loss: 0.7852 - val_auc_11: 0.6194 - val_binary_accuracy: 0.6434\n",
            "Epoch 164/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4140 - auc_11: 0.8685 - binary_accuracy: 0.7891 - val_loss: 0.7973 - val_auc_11: 0.6255 - val_binary_accuracy: 0.6434\n",
            "Epoch 165/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4051 - auc_11: 0.8789 - binary_accuracy: 0.7985 - val_loss: 0.7846 - val_auc_11: 0.6273 - val_binary_accuracy: 0.6488\n",
            "Epoch 166/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4138 - auc_11: 0.8726 - binary_accuracy: 0.7985 - val_loss: 0.7896 - val_auc_11: 0.6204 - val_binary_accuracy: 0.6381\n",
            "Epoch 167/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.4041 - auc_11: 0.8762 - binary_accuracy: 0.8079 - val_loss: 0.8073 - val_auc_11: 0.6011 - val_binary_accuracy: 0.6139\n",
            "Epoch 168/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.3963 - auc_11: 0.8855 - binary_accuracy: 0.8012 - val_loss: 0.8206 - val_auc_11: 0.6130 - val_binary_accuracy: 0.6381\n",
            "Epoch 169/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.3942 - auc_11: 0.8853 - binary_accuracy: 0.8079 - val_loss: 0.8081 - val_auc_11: 0.6184 - val_binary_accuracy: 0.6488\n",
            "Epoch 170/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4087 - auc_11: 0.8756 - binary_accuracy: 0.7999 - val_loss: 0.8086 - val_auc_11: 0.6127 - val_binary_accuracy: 0.6247\n",
            "Epoch 171/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.3992 - auc_11: 0.8787 - binary_accuracy: 0.8059 - val_loss: 0.7917 - val_auc_11: 0.6186 - val_binary_accuracy: 0.6247\n",
            "Epoch 172/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4050 - auc_11: 0.8757 - binary_accuracy: 0.8032 - val_loss: 0.7751 - val_auc_11: 0.6298 - val_binary_accuracy: 0.6488\n",
            "Epoch 173/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.3839 - auc_11: 0.8914 - binary_accuracy: 0.8093 - val_loss: 0.7928 - val_auc_11: 0.6093 - val_binary_accuracy: 0.6461\n",
            "Epoch 174/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.3897 - auc_11: 0.8874 - binary_accuracy: 0.8113 - val_loss: 0.7927 - val_auc_11: 0.6179 - val_binary_accuracy: 0.6354\n",
            "Epoch 175/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.3863 - auc_11: 0.8906 - binary_accuracy: 0.8026 - val_loss: 0.8020 - val_auc_11: 0.6105 - val_binary_accuracy: 0.6408\n",
            "Epoch 176/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.3929 - auc_11: 0.8834 - binary_accuracy: 0.8086 - val_loss: 0.7942 - val_auc_11: 0.6195 - val_binary_accuracy: 0.6408\n",
            "Epoch 177/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.3922 - auc_11: 0.8850 - binary_accuracy: 0.7999 - val_loss: 0.7895 - val_auc_11: 0.6204 - val_binary_accuracy: 0.6327\n",
            "Epoch 178/200\n",
            "47/47 [==============================] - 1s 10ms/step - loss: 0.3890 - auc_11: 0.8876 - binary_accuracy: 0.7972 - val_loss: 0.7955 - val_auc_11: 0.6188 - val_binary_accuracy: 0.6273\n",
            "Epoch 179/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.4021 - auc_11: 0.8794 - binary_accuracy: 0.8026 - val_loss: 0.7708 - val_auc_11: 0.6371 - val_binary_accuracy: 0.6515\n",
            "Epoch 180/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.3928 - auc_11: 0.8859 - binary_accuracy: 0.8059 - val_loss: 0.7989 - val_auc_11: 0.6170 - val_binary_accuracy: 0.6488\n",
            "Epoch 181/200\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 0.3963 - auc_11: 0.8848 - binary_accuracy: 0.8079 - val_loss: 0.8018 - val_auc_11: 0.6115 - val_binary_accuracy: 0.6166\n",
            "Epoch 182/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.4023 - auc_11: 0.8779 - binary_accuracy: 0.8113 - val_loss: 0.7885 - val_auc_11: 0.6174 - val_binary_accuracy: 0.6381\n",
            "Epoch 183/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.3848 - auc_11: 0.8901 - binary_accuracy: 0.8113 - val_loss: 0.7920 - val_auc_11: 0.6242 - val_binary_accuracy: 0.6461\n",
            "Epoch 184/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.3744 - auc_11: 0.8968 - binary_accuracy: 0.8120 - val_loss: 0.8015 - val_auc_11: 0.6247 - val_binary_accuracy: 0.6381\n",
            "Epoch 185/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.3887 - auc_11: 0.8858 - binary_accuracy: 0.8126 - val_loss: 0.8042 - val_auc_11: 0.6187 - val_binary_accuracy: 0.6488\n",
            "Epoch 186/200\n",
            "47/47 [==============================] - 0s 11ms/step - loss: 0.3730 - auc_11: 0.9000 - binary_accuracy: 0.8180 - val_loss: 0.8018 - val_auc_11: 0.6220 - val_binary_accuracy: 0.6300\n",
            "Epoch 187/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.3876 - auc_11: 0.8861 - binary_accuracy: 0.8113 - val_loss: 0.8006 - val_auc_11: 0.6300 - val_binary_accuracy: 0.6354\n",
            "Epoch 188/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.3688 - auc_11: 0.9026 - binary_accuracy: 0.8261 - val_loss: 0.8130 - val_auc_11: 0.6259 - val_binary_accuracy: 0.6354\n",
            "Epoch 189/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.3656 - auc_11: 0.8999 - binary_accuracy: 0.8153 - val_loss: 0.8105 - val_auc_11: 0.6299 - val_binary_accuracy: 0.6408\n",
            "Epoch 190/200\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 0.3891 - auc_11: 0.8908 - binary_accuracy: 0.8039 - val_loss: 0.8049 - val_auc_11: 0.6205 - val_binary_accuracy: 0.6408\n",
            "Epoch 191/200\n",
            "47/47 [==============================] - 1s 10ms/step - loss: 0.3671 - auc_11: 0.9022 - binary_accuracy: 0.8207 - val_loss: 0.8121 - val_auc_11: 0.6330 - val_binary_accuracy: 0.6542\n",
            "Epoch 192/200\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 0.3706 - auc_11: 0.9019 - binary_accuracy: 0.8355 - val_loss: 0.8058 - val_auc_11: 0.6332 - val_binary_accuracy: 0.6408\n",
            "Epoch 193/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.3719 - auc_11: 0.8985 - binary_accuracy: 0.8167 - val_loss: 0.8214 - val_auc_11: 0.6294 - val_binary_accuracy: 0.6595\n",
            "Epoch 194/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.3613 - auc_11: 0.9056 - binary_accuracy: 0.8146 - val_loss: 0.8121 - val_auc_11: 0.6298 - val_binary_accuracy: 0.6434\n",
            "Epoch 195/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.3520 - auc_11: 0.9131 - binary_accuracy: 0.8321 - val_loss: 0.8230 - val_auc_11: 0.6234 - val_binary_accuracy: 0.6408\n",
            "Epoch 196/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.3744 - auc_11: 0.8971 - binary_accuracy: 0.8281 - val_loss: 0.8413 - val_auc_11: 0.6179 - val_binary_accuracy: 0.6434\n",
            "Epoch 197/200\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 0.3545 - auc_11: 0.9083 - binary_accuracy: 0.8301 - val_loss: 0.8242 - val_auc_11: 0.6232 - val_binary_accuracy: 0.6461\n",
            "Epoch 198/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.3443 - auc_11: 0.9194 - binary_accuracy: 0.8462 - val_loss: 0.8318 - val_auc_11: 0.6162 - val_binary_accuracy: 0.6408\n",
            "Epoch 199/200\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 0.3610 - auc_11: 0.9046 - binary_accuracy: 0.8234 - val_loss: 0.8301 - val_auc_11: 0.6323 - val_binary_accuracy: 0.6488\n",
            "Epoch 200/200\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.3421 - auc_11: 0.9162 - binary_accuracy: 0.8355 - val_loss: 0.8358 - val_auc_11: 0.6342 - val_binary_accuracy: 0.6542\n",
            "12/12 [==============================] - 1s 4ms/step - loss: 0.5999 - auc_12: 0.6606 - binary_accuracy: 0.6890\n",
            "12/12 [==============================] - 1s 3ms/step - loss: 0.6071 - auc_13: 0.6490 - binary_accuracy: 0.6676\n",
            "12/12 [==============================] - 1s 4ms/step - loss: 0.6045 - auc_14: 0.6561 - binary_accuracy: 0.6676\n",
            "12/12 [==============================] - 1s 3ms/step - loss: 0.6027 - auc_15: 0.6579 - binary_accuracy: 0.6702\n"
          ]
        }
      ],
      "source": [
        "# Conduct the gridsearch over hyperparameters.\n",
        "results_4 = {}\n",
        "\n",
        "for params_i in params_grid:\n",
        "\n",
        "  # Create a LSTM model with the specific parameter setting params_i\n",
        "  time_series_lstm = create_model_lstm_mooc_binary(num_features, 1, params_i)\n",
        "\n",
        "  save_model_name = params_i['best_model_weights'] + \"_\" + str(params_i['recurrent_units']) + \"_\" + str(n)\n",
        "\n",
        "  # Save the best version of the model through the training epochs\n",
        "  ckp_callback = tf.keras.callbacks.ModelCheckpoint(save_model_name, \n",
        "                                                    save_best_only=True, save_weights_only=True)\n",
        "\n",
        "  # Fit the model on the training data with the appropriate parameters  \n",
        "  time_series_lstm.fit(df_x_binary_train_val_4, \n",
        "                        df_y_binary_train_val_4, \n",
        "                        epochs=params_i['epochs'],\n",
        "                        validation_data=(df_x_binary_val_4, df_y_binary_val_4),\n",
        "                        callbacks=[ckp_callback], \n",
        "                        verbose=params_i['verbose'])\n",
        "#Once each model has been fully trained, evaluate their best version on the validation set to choose the best parameter\n",
        "for params_i in params_grid:\n",
        "  time_series_lstm = create_model_lstm_mooc_binary(num_features, 1, params_i)\n",
        "  save_model_name = params_i['best_model_weights'] + \"_\" + str(params_i['recurrent_units']) + \"_\" + str(n)\n",
        "  time_series_lstm.load_weights(save_model_name)\n",
        "  # Evaluate the model performance\n",
        "  results_4[params_i['recurrent_units']] = time_series_lstm.evaluate(df_x_binary_val_4, \n",
        "                                                                    df_y_binary_val_4,\n",
        "                                                                    verbose=params_i['verbose'], \n",
        "                                                                    return_dict=True)"
      ],
      "id": "9dsnZGbDODBQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NoabuLKUODBR",
        "outputId": "45db9413-59d2-4f63-f492-d21be584280d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sort candidate parameters according to their accuracy\n",
        "results_sorted = sorted(results_4.items(), key=lambda x: x[1]['binary_accuracy'], reverse=True)\n",
        "\n",
        "# Obtain the best parameters\n",
        "best_params_4 = results_sorted[0][0]\n",
        "best_params_4"
      ],
      "id": "NoabuLKUODBR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TxDn9WzrdPM"
      },
      "source": [
        "###3rd LSTM NN: Training on Weeks 1 to 8: "
      ],
      "id": "5TxDn9WzrdPM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "faNEOxHmZpKm"
      },
      "outputs": [],
      "source": [
        "#Parameters for the dataset of weeks 1 to 8; same procedure as for week 1 and weeks 1 to 4\n",
        "n = 8\n",
        "df_x, labels = week_up_to_n(df_weekly_merged, n)\n",
        "df_x.fillna(0, inplace = True)\n",
        "df_x = df_standarize(df_x)\n",
        "df_x_binary = df_x.drop(columns=[\"user_id\",\"week\",\"last_week_of_activity\"]).values.reshape(-1, n, num_features)\n",
        "df_y_binary = labels.drop(columns=[\"user_id\"]).values.reshape(-1, 1)"
      ],
      "id": "faNEOxHmZpKm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DfkCj4Y9ZpKn"
      },
      "outputs": [],
      "source": [
        "# Split into training and test sets.\n",
        "df_x_binary_train_8, df_x_binary_test_8, df_y_binary_train_8, df_y_binary_test_8 = train_test_split(\n",
        "                                                                            df_x_binary, \n",
        "                                                                            df_y_binary,\n",
        "                                                                            test_size=0.2, \n",
        "                                                                            random_state=0, \n",
        "                                                                            stratify=df_y_binary)\n",
        "\n",
        "# Split training into training and validation sets.\n",
        "df_x_binary_train_val_8, df_x_binary_val_8, df_y_binary_train_val_8, df_y_binary_val_8 = train_test_split(\n",
        "                                                                            df_x_binary_train_8, \n",
        "                                                                            df_y_binary_train_8, \n",
        "                                                                            test_size=0.2,\n",
        "                                                                            random_state=0, \n",
        "                                                                            stratify=df_y_binary_train_8)"
      ],
      "id": "DfkCj4Y9ZpKn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cRAXULVvZpKn"
      },
      "outputs": [],
      "source": [
        "#Parameters of the model\n",
        "params = {}\n",
        "\n",
        "params['batch_size'] = 32\n",
        "params['verbose'] = 1\n",
        "params['best_model_weights'] = 'weights/bestmodel' \n",
        "params['optimizer'] = 'adam'\n",
        "params['recurrent_units'] = 16\n",
        "#Same principle as for weeks 1 to 4; less users means faster epoch, and we have to \n",
        "#run more f them for the model to overfit\n",
        "params['epochs'] = 500\n",
        "params['dropout_rate'] = 0.1"
      ],
      "id": "cRAXULVvZpKn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C1LIkcEPZpKo"
      },
      "outputs": [],
      "source": [
        "#Grid search on the number of recurrent units in the LSTM model, between 16 and 128\n",
        "params_space = {param: [value] for param, value in params.items()}\n",
        "params_space['recurrent_units'] = [16, 32, 64, 128]\n",
        "params_grid = ParameterGrid(params_space)"
      ],
      "id": "C1LIkcEPZpKo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-HMzpJLZZpKo",
        "outputId": "63b2ade5-3334-4082-9987-0b93e55b00f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            " 1/10 [==>...........................] - ETA: 20s - loss: 0.6892 - auc_16: 0.5556 - binary_accuracy: 0.5312WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
            "10/10 [==============================] - 4s 142ms/step - loss: 0.6844 - auc_16: 0.5672 - binary_accuracy: 0.5743 - val_loss: 0.6800 - val_auc_16: 0.5601 - val_binary_accuracy: 0.7027\n",
            "Epoch 2/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6697 - auc_16: 0.5901 - binary_accuracy: 0.6622 - val_loss: 0.6657 - val_auc_16: 0.5823 - val_binary_accuracy: 0.6892\n",
            "Epoch 3/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6565 - auc_16: 0.6184 - binary_accuracy: 0.6892 - val_loss: 0.6541 - val_auc_16: 0.6019 - val_binary_accuracy: 0.6892\n",
            "Epoch 4/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6421 - auc_16: 0.6428 - binary_accuracy: 0.6858 - val_loss: 0.6429 - val_auc_16: 0.6027 - val_binary_accuracy: 0.6892\n",
            "Epoch 5/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6301 - auc_16: 0.6474 - binary_accuracy: 0.6824 - val_loss: 0.6317 - val_auc_16: 0.6053 - val_binary_accuracy: 0.6892\n",
            "Epoch 6/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6170 - auc_16: 0.6624 - binary_accuracy: 0.6824 - val_loss: 0.6219 - val_auc_16: 0.6189 - val_binary_accuracy: 0.6892\n",
            "Epoch 7/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6047 - auc_16: 0.6805 - binary_accuracy: 0.6824 - val_loss: 0.6131 - val_auc_16: 0.6206 - val_binary_accuracy: 0.6892\n",
            "Epoch 8/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5970 - auc_16: 0.6806 - binary_accuracy: 0.6824 - val_loss: 0.6071 - val_auc_16: 0.6266 - val_binary_accuracy: 0.6892\n",
            "Epoch 9/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5912 - auc_16: 0.6818 - binary_accuracy: 0.6824 - val_loss: 0.6048 - val_auc_16: 0.6292 - val_binary_accuracy: 0.6892\n",
            "Epoch 10/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5846 - auc_16: 0.6898 - binary_accuracy: 0.6824 - val_loss: 0.6045 - val_auc_16: 0.6313 - val_binary_accuracy: 0.6892\n",
            "Epoch 11/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5781 - auc_16: 0.6999 - binary_accuracy: 0.6824 - val_loss: 0.6038 - val_auc_16: 0.6368 - val_binary_accuracy: 0.6892\n",
            "Epoch 12/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5717 - auc_16: 0.7104 - binary_accuracy: 0.6858 - val_loss: 0.6045 - val_auc_16: 0.6402 - val_binary_accuracy: 0.6892\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5805 - auc_16: 0.6878 - binary_accuracy: 0.6791 - val_loss: 0.6036 - val_auc_16: 0.6466 - val_binary_accuracy: 0.6892\n",
            "Epoch 14/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5773 - auc_16: 0.6943 - binary_accuracy: 0.6858 - val_loss: 0.6034 - val_auc_16: 0.6505 - val_binary_accuracy: 0.7027\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5754 - auc_16: 0.6912 - binary_accuracy: 0.6926 - val_loss: 0.6003 - val_auc_16: 0.6500 - val_binary_accuracy: 0.6892\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5713 - auc_16: 0.7052 - binary_accuracy: 0.6926 - val_loss: 0.5999 - val_auc_16: 0.6496 - val_binary_accuracy: 0.7027\n",
            "Epoch 17/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5704 - auc_16: 0.6997 - binary_accuracy: 0.6959 - val_loss: 0.5955 - val_auc_16: 0.6547 - val_binary_accuracy: 0.7027\n",
            "Epoch 18/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5647 - auc_16: 0.7111 - binary_accuracy: 0.7027 - val_loss: 0.5934 - val_auc_16: 0.6564 - val_binary_accuracy: 0.7027\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5706 - auc_16: 0.6986 - binary_accuracy: 0.6757 - val_loss: 0.5931 - val_auc_16: 0.6556 - val_binary_accuracy: 0.7027\n",
            "Epoch 20/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5648 - auc_16: 0.7112 - binary_accuracy: 0.7061 - val_loss: 0.5941 - val_auc_16: 0.6564 - val_binary_accuracy: 0.7027\n",
            "Epoch 21/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5692 - auc_16: 0.7007 - binary_accuracy: 0.7027 - val_loss: 0.5895 - val_auc_16: 0.6620 - val_binary_accuracy: 0.7027\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5633 - auc_16: 0.7148 - binary_accuracy: 0.7264 - val_loss: 0.5887 - val_auc_16: 0.6633 - val_binary_accuracy: 0.7027\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5685 - auc_16: 0.7031 - binary_accuracy: 0.7128 - val_loss: 0.5884 - val_auc_16: 0.6637 - val_binary_accuracy: 0.7027\n",
            "Epoch 24/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5651 - auc_16: 0.7113 - binary_accuracy: 0.7095 - val_loss: 0.5864 - val_auc_16: 0.6667 - val_binary_accuracy: 0.7027\n",
            "Epoch 25/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5660 - auc_16: 0.7080 - binary_accuracy: 0.7027 - val_loss: 0.5859 - val_auc_16: 0.6709 - val_binary_accuracy: 0.7027\n",
            "Epoch 26/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5657 - auc_16: 0.7107 - binary_accuracy: 0.6959 - val_loss: 0.5838 - val_auc_16: 0.6735 - val_binary_accuracy: 0.7027\n",
            "Epoch 27/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5564 - auc_16: 0.7234 - binary_accuracy: 0.7128 - val_loss: 0.5806 - val_auc_16: 0.6820 - val_binary_accuracy: 0.7027\n",
            "Epoch 28/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5593 - auc_16: 0.7169 - binary_accuracy: 0.6892 - val_loss: 0.5798 - val_auc_16: 0.6812 - val_binary_accuracy: 0.7027\n",
            "Epoch 29/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5580 - auc_16: 0.7208 - binary_accuracy: 0.7162 - val_loss: 0.5793 - val_auc_16: 0.6824 - val_binary_accuracy: 0.7027\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5638 - auc_16: 0.7119 - binary_accuracy: 0.7264 - val_loss: 0.5778 - val_auc_16: 0.6816 - val_binary_accuracy: 0.6892\n",
            "Epoch 31/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5603 - auc_16: 0.7187 - binary_accuracy: 0.7095 - val_loss: 0.5768 - val_auc_16: 0.6884 - val_binary_accuracy: 0.7027\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5561 - auc_16: 0.7276 - binary_accuracy: 0.7196 - val_loss: 0.5758 - val_auc_16: 0.6863 - val_binary_accuracy: 0.7027\n",
            "Epoch 33/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5614 - auc_16: 0.7138 - binary_accuracy: 0.7061 - val_loss: 0.5716 - val_auc_16: 0.6939 - val_binary_accuracy: 0.7162\n",
            "Epoch 34/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5587 - auc_16: 0.7203 - binary_accuracy: 0.6993 - val_loss: 0.5694 - val_auc_16: 0.6948 - val_binary_accuracy: 0.7162\n",
            "Epoch 35/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5620 - auc_16: 0.7140 - binary_accuracy: 0.7128 - val_loss: 0.5667 - val_auc_16: 0.7016 - val_binary_accuracy: 0.7162\n",
            "Epoch 36/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5493 - auc_16: 0.7364 - binary_accuracy: 0.7230 - val_loss: 0.5662 - val_auc_16: 0.7046 - val_binary_accuracy: 0.7162\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5496 - auc_16: 0.7382 - binary_accuracy: 0.7297 - val_loss: 0.5658 - val_auc_16: 0.7042 - val_binary_accuracy: 0.7162\n",
            "Epoch 38/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5476 - auc_16: 0.7383 - binary_accuracy: 0.7230 - val_loss: 0.5642 - val_auc_16: 0.7025 - val_binary_accuracy: 0.7297\n",
            "Epoch 39/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5588 - auc_16: 0.7194 - binary_accuracy: 0.7061 - val_loss: 0.5642 - val_auc_16: 0.7080 - val_binary_accuracy: 0.7297\n",
            "Epoch 40/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5526 - auc_16: 0.7329 - binary_accuracy: 0.7230 - val_loss: 0.5629 - val_auc_16: 0.7089 - val_binary_accuracy: 0.7297\n",
            "Epoch 41/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5460 - auc_16: 0.7428 - binary_accuracy: 0.7230 - val_loss: 0.5588 - val_auc_16: 0.7136 - val_binary_accuracy: 0.7297\n",
            "Epoch 42/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5548 - auc_16: 0.7304 - binary_accuracy: 0.7162 - val_loss: 0.5553 - val_auc_16: 0.7204 - val_binary_accuracy: 0.7297\n",
            "Epoch 43/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5398 - auc_16: 0.7540 - binary_accuracy: 0.7162 - val_loss: 0.5523 - val_auc_16: 0.7238 - val_binary_accuracy: 0.7297\n",
            "Epoch 44/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5452 - auc_16: 0.7435 - binary_accuracy: 0.7264 - val_loss: 0.5520 - val_auc_16: 0.7229 - val_binary_accuracy: 0.7432\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5474 - auc_16: 0.7372 - binary_accuracy: 0.7196 - val_loss: 0.5480 - val_auc_16: 0.7336 - val_binary_accuracy: 0.7432\n",
            "Epoch 46/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5424 - auc_16: 0.7494 - binary_accuracy: 0.7196 - val_loss: 0.5466 - val_auc_16: 0.7357 - val_binary_accuracy: 0.7297\n",
            "Epoch 47/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5448 - auc_16: 0.7429 - binary_accuracy: 0.7365 - val_loss: 0.5498 - val_auc_16: 0.7289 - val_binary_accuracy: 0.7297\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5419 - auc_16: 0.7445 - binary_accuracy: 0.7331 - val_loss: 0.5474 - val_auc_16: 0.7336 - val_binary_accuracy: 0.7432\n",
            "Epoch 49/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.5473 - auc_16: 0.7382 - binary_accuracy: 0.7061 - val_loss: 0.5437 - val_auc_16: 0.7379 - val_binary_accuracy: 0.7568\n",
            "Epoch 50/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5454 - auc_16: 0.7409 - binary_accuracy: 0.7297 - val_loss: 0.5453 - val_auc_16: 0.7336 - val_binary_accuracy: 0.7297\n",
            "Epoch 51/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5363 - auc_16: 0.7557 - binary_accuracy: 0.7230 - val_loss: 0.5434 - val_auc_16: 0.7400 - val_binary_accuracy: 0.7432\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5445 - auc_16: 0.7410 - binary_accuracy: 0.7061 - val_loss: 0.5420 - val_auc_16: 0.7396 - val_binary_accuracy: 0.7568\n",
            "Epoch 53/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5435 - auc_16: 0.7417 - binary_accuracy: 0.7196 - val_loss: 0.5362 - val_auc_16: 0.7460 - val_binary_accuracy: 0.7432\n",
            "Epoch 54/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5423 - auc_16: 0.7444 - binary_accuracy: 0.7061 - val_loss: 0.5356 - val_auc_16: 0.7442 - val_binary_accuracy: 0.7162\n",
            "Epoch 55/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5381 - auc_16: 0.7491 - binary_accuracy: 0.7095 - val_loss: 0.5314 - val_auc_16: 0.7566 - val_binary_accuracy: 0.7432\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5377 - auc_16: 0.7530 - binary_accuracy: 0.7264 - val_loss: 0.5275 - val_auc_16: 0.7617 - val_binary_accuracy: 0.7432\n",
            "Epoch 57/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5404 - auc_16: 0.7440 - binary_accuracy: 0.7095 - val_loss: 0.5281 - val_auc_16: 0.7630 - val_binary_accuracy: 0.7568\n",
            "Epoch 58/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5381 - auc_16: 0.7484 - binary_accuracy: 0.7432 - val_loss: 0.5278 - val_auc_16: 0.7621 - val_binary_accuracy: 0.7432\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5296 - auc_16: 0.7620 - binary_accuracy: 0.7365 - val_loss: 0.5250 - val_auc_16: 0.7656 - val_binary_accuracy: 0.7432\n",
            "Epoch 60/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5310 - auc_16: 0.7602 - binary_accuracy: 0.7264 - val_loss: 0.5214 - val_auc_16: 0.7694 - val_binary_accuracy: 0.7568\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5235 - auc_16: 0.7731 - binary_accuracy: 0.7399 - val_loss: 0.5195 - val_auc_16: 0.7715 - val_binary_accuracy: 0.7568\n",
            "Epoch 62/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5290 - auc_16: 0.7627 - binary_accuracy: 0.7399 - val_loss: 0.5181 - val_auc_16: 0.7741 - val_binary_accuracy: 0.7568\n",
            "Epoch 63/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5220 - auc_16: 0.7703 - binary_accuracy: 0.7500 - val_loss: 0.5179 - val_auc_16: 0.7732 - val_binary_accuracy: 0.7703\n",
            "Epoch 64/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5355 - auc_16: 0.7489 - binary_accuracy: 0.7128 - val_loss: 0.5199 - val_auc_16: 0.7707 - val_binary_accuracy: 0.7568\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5202 - auc_16: 0.7705 - binary_accuracy: 0.7331 - val_loss: 0.5184 - val_auc_16: 0.7707 - val_binary_accuracy: 0.7432\n",
            "Epoch 66/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5271 - auc_16: 0.7637 - binary_accuracy: 0.7297 - val_loss: 0.5121 - val_auc_16: 0.7775 - val_binary_accuracy: 0.7703\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5274 - auc_16: 0.7616 - binary_accuracy: 0.7432 - val_loss: 0.5113 - val_auc_16: 0.7809 - val_binary_accuracy: 0.7703\n",
            "Epoch 68/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5111 - auc_16: 0.7889 - binary_accuracy: 0.7466 - val_loss: 0.5087 - val_auc_16: 0.7813 - val_binary_accuracy: 0.7703\n",
            "Epoch 69/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5178 - auc_16: 0.7795 - binary_accuracy: 0.7568 - val_loss: 0.5068 - val_auc_16: 0.7843 - val_binary_accuracy: 0.7838\n",
            "Epoch 70/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5104 - auc_16: 0.7832 - binary_accuracy: 0.7399 - val_loss: 0.5023 - val_auc_16: 0.7899 - val_binary_accuracy: 0.7568\n",
            "Epoch 71/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5195 - auc_16: 0.7702 - binary_accuracy: 0.7297 - val_loss: 0.5059 - val_auc_16: 0.7839 - val_binary_accuracy: 0.7568\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5208 - auc_16: 0.7665 - binary_accuracy: 0.7432 - val_loss: 0.4979 - val_auc_16: 0.7954 - val_binary_accuracy: 0.7568\n",
            "Epoch 73/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5024 - auc_16: 0.7952 - binary_accuracy: 0.7500 - val_loss: 0.4964 - val_auc_16: 0.7975 - val_binary_accuracy: 0.7568\n",
            "Epoch 74/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5199 - auc_16: 0.7693 - binary_accuracy: 0.7568 - val_loss: 0.4977 - val_auc_16: 0.7933 - val_binary_accuracy: 0.7432\n",
            "Epoch 75/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5143 - auc_16: 0.7789 - binary_accuracy: 0.7297 - val_loss: 0.4938 - val_auc_16: 0.8026 - val_binary_accuracy: 0.7568\n",
            "Epoch 76/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5209 - auc_16: 0.7682 - binary_accuracy: 0.7331 - val_loss: 0.4917 - val_auc_16: 0.8022 - val_binary_accuracy: 0.7568\n",
            "Epoch 77/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5152 - auc_16: 0.7743 - binary_accuracy: 0.7500 - val_loss: 0.4921 - val_auc_16: 0.8035 - val_binary_accuracy: 0.7432\n",
            "Epoch 78/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5091 - auc_16: 0.7846 - binary_accuracy: 0.7601 - val_loss: 0.4962 - val_auc_16: 0.7988 - val_binary_accuracy: 0.7297\n",
            "Epoch 79/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5076 - auc_16: 0.7855 - binary_accuracy: 0.7601 - val_loss: 0.4933 - val_auc_16: 0.8039 - val_binary_accuracy: 0.7432\n",
            "Epoch 80/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5104 - auc_16: 0.7823 - binary_accuracy: 0.7500 - val_loss: 0.4865 - val_auc_16: 0.8103 - val_binary_accuracy: 0.7432\n",
            "Epoch 81/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5030 - auc_16: 0.7915 - binary_accuracy: 0.7635 - val_loss: 0.4836 - val_auc_16: 0.8167 - val_binary_accuracy: 0.7568\n",
            "Epoch 82/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5106 - auc_16: 0.7833 - binary_accuracy: 0.7432 - val_loss: 0.4873 - val_auc_16: 0.8065 - val_binary_accuracy: 0.7703\n",
            "Epoch 83/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5017 - auc_16: 0.7945 - binary_accuracy: 0.7703 - val_loss: 0.4889 - val_auc_16: 0.8035 - val_binary_accuracy: 0.7568\n",
            "Epoch 84/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4991 - auc_16: 0.7949 - binary_accuracy: 0.7297 - val_loss: 0.4958 - val_auc_16: 0.7954 - val_binary_accuracy: 0.7432\n",
            "Epoch 85/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4967 - auc_16: 0.7987 - binary_accuracy: 0.7466 - val_loss: 0.4897 - val_auc_16: 0.8031 - val_binary_accuracy: 0.7432\n",
            "Epoch 86/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4943 - auc_16: 0.7977 - binary_accuracy: 0.7500 - val_loss: 0.4816 - val_auc_16: 0.8120 - val_binary_accuracy: 0.7568\n",
            "Epoch 87/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5102 - auc_16: 0.7800 - binary_accuracy: 0.7365 - val_loss: 0.4815 - val_auc_16: 0.8103 - val_binary_accuracy: 0.7703\n",
            "Epoch 88/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4932 - auc_16: 0.7997 - binary_accuracy: 0.7432 - val_loss: 0.4821 - val_auc_16: 0.8146 - val_binary_accuracy: 0.7838\n",
            "Epoch 89/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4836 - auc_16: 0.8132 - binary_accuracy: 0.7534 - val_loss: 0.4816 - val_auc_16: 0.8163 - val_binary_accuracy: 0.7838\n",
            "Epoch 90/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4985 - auc_16: 0.7931 - binary_accuracy: 0.7365 - val_loss: 0.4843 - val_auc_16: 0.8116 - val_binary_accuracy: 0.7432\n",
            "Epoch 91/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5019 - auc_16: 0.7887 - binary_accuracy: 0.7297 - val_loss: 0.4885 - val_auc_16: 0.8103 - val_binary_accuracy: 0.7838\n",
            "Epoch 92/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4852 - auc_16: 0.8112 - binary_accuracy: 0.7432 - val_loss: 0.4849 - val_auc_16: 0.8124 - val_binary_accuracy: 0.7703\n",
            "Epoch 93/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4830 - auc_16: 0.8174 - binary_accuracy: 0.7432 - val_loss: 0.4785 - val_auc_16: 0.8201 - val_binary_accuracy: 0.7703\n",
            "Epoch 94/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4876 - auc_16: 0.8114 - binary_accuracy: 0.7534 - val_loss: 0.4754 - val_auc_16: 0.8205 - val_binary_accuracy: 0.7703\n",
            "Epoch 95/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4888 - auc_16: 0.8019 - binary_accuracy: 0.7365 - val_loss: 0.4830 - val_auc_16: 0.8129 - val_binary_accuracy: 0.7838\n",
            "Epoch 96/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4938 - auc_16: 0.7977 - binary_accuracy: 0.7534 - val_loss: 0.4861 - val_auc_16: 0.8137 - val_binary_accuracy: 0.7703\n",
            "Epoch 97/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4930 - auc_16: 0.7960 - binary_accuracy: 0.7432 - val_loss: 0.4862 - val_auc_16: 0.8124 - val_binary_accuracy: 0.7703\n",
            "Epoch 98/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5030 - auc_16: 0.7848 - binary_accuracy: 0.7635 - val_loss: 0.4781 - val_auc_16: 0.8218 - val_binary_accuracy: 0.7973\n",
            "Epoch 99/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4755 - auc_16: 0.8180 - binary_accuracy: 0.7432 - val_loss: 0.4784 - val_auc_16: 0.8171 - val_binary_accuracy: 0.7973\n",
            "Epoch 100/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4886 - auc_16: 0.8009 - binary_accuracy: 0.7399 - val_loss: 0.4821 - val_auc_16: 0.8159 - val_binary_accuracy: 0.7973\n",
            "Epoch 101/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4997 - auc_16: 0.7857 - binary_accuracy: 0.7230 - val_loss: 0.4854 - val_auc_16: 0.8201 - val_binary_accuracy: 0.7838\n",
            "Epoch 102/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4753 - auc_16: 0.8181 - binary_accuracy: 0.7466 - val_loss: 0.4836 - val_auc_16: 0.8214 - val_binary_accuracy: 0.7973\n",
            "Epoch 103/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4806 - auc_16: 0.8107 - binary_accuracy: 0.7331 - val_loss: 0.4840 - val_auc_16: 0.8205 - val_binary_accuracy: 0.7973\n",
            "Epoch 104/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4789 - auc_16: 0.8138 - binary_accuracy: 0.7534 - val_loss: 0.4822 - val_auc_16: 0.8201 - val_binary_accuracy: 0.7973\n",
            "Epoch 105/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4862 - auc_16: 0.8027 - binary_accuracy: 0.7365 - val_loss: 0.4877 - val_auc_16: 0.8107 - val_binary_accuracy: 0.7838\n",
            "Epoch 106/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4762 - auc_16: 0.8162 - binary_accuracy: 0.7466 - val_loss: 0.4797 - val_auc_16: 0.8210 - val_binary_accuracy: 0.7973\n",
            "Epoch 107/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4825 - auc_16: 0.8097 - binary_accuracy: 0.7264 - val_loss: 0.4810 - val_auc_16: 0.8193 - val_binary_accuracy: 0.7973\n",
            "Epoch 108/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4703 - auc_16: 0.8213 - binary_accuracy: 0.7500 - val_loss: 0.4825 - val_auc_16: 0.8167 - val_binary_accuracy: 0.8108\n",
            "Epoch 109/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4703 - auc_16: 0.8209 - binary_accuracy: 0.7432 - val_loss: 0.4892 - val_auc_16: 0.8146 - val_binary_accuracy: 0.7973\n",
            "Epoch 110/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4660 - auc_16: 0.8219 - binary_accuracy: 0.7196 - val_loss: 0.4880 - val_auc_16: 0.8146 - val_binary_accuracy: 0.7838\n",
            "Epoch 111/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4607 - auc_16: 0.8355 - binary_accuracy: 0.7601 - val_loss: 0.4819 - val_auc_16: 0.8193 - val_binary_accuracy: 0.7973\n",
            "Epoch 112/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4804 - auc_16: 0.8119 - binary_accuracy: 0.7399 - val_loss: 0.4846 - val_auc_16: 0.8197 - val_binary_accuracy: 0.7973\n",
            "Epoch 113/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4636 - auc_16: 0.8245 - binary_accuracy: 0.7500 - val_loss: 0.4981 - val_auc_16: 0.8069 - val_binary_accuracy: 0.7838\n",
            "Epoch 114/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4708 - auc_16: 0.8173 - binary_accuracy: 0.7432 - val_loss: 0.4886 - val_auc_16: 0.8176 - val_binary_accuracy: 0.7838\n",
            "Epoch 115/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4480 - auc_16: 0.8450 - binary_accuracy: 0.7601 - val_loss: 0.4843 - val_auc_16: 0.8163 - val_binary_accuracy: 0.7973\n",
            "Epoch 116/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4682 - auc_16: 0.8232 - binary_accuracy: 0.7466 - val_loss: 0.4805 - val_auc_16: 0.8227 - val_binary_accuracy: 0.7973\n",
            "Epoch 117/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4674 - auc_16: 0.8219 - binary_accuracy: 0.7601 - val_loss: 0.4841 - val_auc_16: 0.8180 - val_binary_accuracy: 0.7838\n",
            "Epoch 118/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4858 - auc_16: 0.8000 - binary_accuracy: 0.7432 - val_loss: 0.5036 - val_auc_16: 0.8103 - val_binary_accuracy: 0.7568\n",
            "Epoch 119/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4531 - auc_16: 0.8393 - binary_accuracy: 0.7601 - val_loss: 0.4853 - val_auc_16: 0.8159 - val_binary_accuracy: 0.7973\n",
            "Epoch 120/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4697 - auc_16: 0.8218 - binary_accuracy: 0.7365 - val_loss: 0.4818 - val_auc_16: 0.8218 - val_binary_accuracy: 0.8108\n",
            "Epoch 121/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4507 - auc_16: 0.8417 - binary_accuracy: 0.7500 - val_loss: 0.4888 - val_auc_16: 0.8146 - val_binary_accuracy: 0.7838\n",
            "Epoch 122/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4723 - auc_16: 0.8188 - binary_accuracy: 0.7500 - val_loss: 0.4838 - val_auc_16: 0.8210 - val_binary_accuracy: 0.7838\n",
            "Epoch 123/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4457 - auc_16: 0.8474 - binary_accuracy: 0.7669 - val_loss: 0.4763 - val_auc_16: 0.8265 - val_binary_accuracy: 0.8108\n",
            "Epoch 124/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4727 - auc_16: 0.8173 - binary_accuracy: 0.7466 - val_loss: 0.4696 - val_auc_16: 0.8338 - val_binary_accuracy: 0.8108\n",
            "Epoch 125/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4659 - auc_16: 0.8214 - binary_accuracy: 0.7466 - val_loss: 0.4745 - val_auc_16: 0.8308 - val_binary_accuracy: 0.7838\n",
            "Epoch 126/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4757 - auc_16: 0.8131 - binary_accuracy: 0.7399 - val_loss: 0.4759 - val_auc_16: 0.8252 - val_binary_accuracy: 0.7973\n",
            "Epoch 127/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4625 - auc_16: 0.8261 - binary_accuracy: 0.7635 - val_loss: 0.4660 - val_auc_16: 0.8338 - val_binary_accuracy: 0.8108\n",
            "Epoch 128/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4467 - auc_16: 0.8415 - binary_accuracy: 0.7466 - val_loss: 0.4666 - val_auc_16: 0.8312 - val_binary_accuracy: 0.8108\n",
            "Epoch 129/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4565 - auc_16: 0.8269 - binary_accuracy: 0.7399 - val_loss: 0.4607 - val_auc_16: 0.8393 - val_binary_accuracy: 0.8243\n",
            "Epoch 130/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4486 - auc_16: 0.8428 - binary_accuracy: 0.7500 - val_loss: 0.4686 - val_auc_16: 0.8346 - val_binary_accuracy: 0.7838\n",
            "Epoch 131/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4504 - auc_16: 0.8402 - binary_accuracy: 0.7736 - val_loss: 0.4794 - val_auc_16: 0.8257 - val_binary_accuracy: 0.7568\n",
            "Epoch 132/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4397 - auc_16: 0.8503 - binary_accuracy: 0.7770 - val_loss: 0.4720 - val_auc_16: 0.8325 - val_binary_accuracy: 0.7973\n",
            "Epoch 133/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4484 - auc_16: 0.8412 - binary_accuracy: 0.7500 - val_loss: 0.4680 - val_auc_16: 0.8308 - val_binary_accuracy: 0.7973\n",
            "Epoch 134/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4480 - auc_16: 0.8392 - binary_accuracy: 0.7534 - val_loss: 0.4726 - val_auc_16: 0.8316 - val_binary_accuracy: 0.7973\n",
            "Epoch 135/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4519 - auc_16: 0.8382 - binary_accuracy: 0.7568 - val_loss: 0.4717 - val_auc_16: 0.8312 - val_binary_accuracy: 0.7838\n",
            "Epoch 136/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4465 - auc_16: 0.8395 - binary_accuracy: 0.7432 - val_loss: 0.4734 - val_auc_16: 0.8291 - val_binary_accuracy: 0.7838\n",
            "Epoch 137/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4460 - auc_16: 0.8349 - binary_accuracy: 0.7162 - val_loss: 0.4660 - val_auc_16: 0.8355 - val_binary_accuracy: 0.7973\n",
            "Epoch 138/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4363 - auc_16: 0.8483 - binary_accuracy: 0.7838 - val_loss: 0.4699 - val_auc_16: 0.8316 - val_binary_accuracy: 0.7838\n",
            "Epoch 139/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4322 - auc_16: 0.8520 - binary_accuracy: 0.7635 - val_loss: 0.4721 - val_auc_16: 0.8321 - val_binary_accuracy: 0.7568\n",
            "Epoch 140/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4391 - auc_16: 0.8489 - binary_accuracy: 0.7601 - val_loss: 0.4721 - val_auc_16: 0.8303 - val_binary_accuracy: 0.7568\n",
            "Epoch 141/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4509 - auc_16: 0.8313 - binary_accuracy: 0.7568 - val_loss: 0.4666 - val_auc_16: 0.8329 - val_binary_accuracy: 0.8108\n",
            "Epoch 142/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4331 - auc_16: 0.8476 - binary_accuracy: 0.7466 - val_loss: 0.4635 - val_auc_16: 0.8355 - val_binary_accuracy: 0.8108\n",
            "Epoch 143/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4376 - auc_16: 0.8452 - binary_accuracy: 0.7534 - val_loss: 0.4641 - val_auc_16: 0.8338 - val_binary_accuracy: 0.8108\n",
            "Epoch 144/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4593 - auc_16: 0.8269 - binary_accuracy: 0.7601 - val_loss: 0.4619 - val_auc_16: 0.8342 - val_binary_accuracy: 0.7838\n",
            "Epoch 145/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4347 - auc_16: 0.8525 - binary_accuracy: 0.7770 - val_loss: 0.4704 - val_auc_16: 0.8367 - val_binary_accuracy: 0.7838\n",
            "Epoch 146/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4512 - auc_16: 0.8359 - binary_accuracy: 0.7703 - val_loss: 0.4619 - val_auc_16: 0.8427 - val_binary_accuracy: 0.8243\n",
            "Epoch 147/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4306 - auc_16: 0.8568 - binary_accuracy: 0.7601 - val_loss: 0.4592 - val_auc_16: 0.8444 - val_binary_accuracy: 0.8108\n",
            "Epoch 148/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4436 - auc_16: 0.8408 - binary_accuracy: 0.7635 - val_loss: 0.4632 - val_auc_16: 0.8372 - val_binary_accuracy: 0.7568\n",
            "Epoch 149/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4391 - auc_16: 0.8487 - binary_accuracy: 0.7770 - val_loss: 0.4610 - val_auc_16: 0.8346 - val_binary_accuracy: 0.7973\n",
            "Epoch 150/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4277 - auc_16: 0.8570 - binary_accuracy: 0.7872 - val_loss: 0.4585 - val_auc_16: 0.8397 - val_binary_accuracy: 0.8378\n",
            "Epoch 151/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4462 - auc_16: 0.8384 - binary_accuracy: 0.7432 - val_loss: 0.4638 - val_auc_16: 0.8342 - val_binary_accuracy: 0.7838\n",
            "Epoch 152/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4286 - auc_16: 0.8559 - binary_accuracy: 0.7736 - val_loss: 0.4688 - val_auc_16: 0.8333 - val_binary_accuracy: 0.7973\n",
            "Epoch 153/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4118 - auc_16: 0.8693 - binary_accuracy: 0.7939 - val_loss: 0.4681 - val_auc_16: 0.8350 - val_binary_accuracy: 0.7973\n",
            "Epoch 154/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4131 - auc_16: 0.8684 - binary_accuracy: 0.7804 - val_loss: 0.4628 - val_auc_16: 0.8363 - val_binary_accuracy: 0.8243\n",
            "Epoch 155/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4288 - auc_16: 0.8559 - binary_accuracy: 0.7635 - val_loss: 0.4626 - val_auc_16: 0.8372 - val_binary_accuracy: 0.8243\n",
            "Epoch 156/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4227 - auc_16: 0.8595 - binary_accuracy: 0.7736 - val_loss: 0.4639 - val_auc_16: 0.8372 - val_binary_accuracy: 0.7973\n",
            "Epoch 157/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4354 - auc_16: 0.8448 - binary_accuracy: 0.7534 - val_loss: 0.4694 - val_auc_16: 0.8333 - val_binary_accuracy: 0.8108\n",
            "Epoch 158/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4177 - auc_16: 0.8668 - binary_accuracy: 0.7973 - val_loss: 0.4719 - val_auc_16: 0.8303 - val_binary_accuracy: 0.7973\n",
            "Epoch 159/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4118 - auc_16: 0.8738 - binary_accuracy: 0.8007 - val_loss: 0.4679 - val_auc_16: 0.8338 - val_binary_accuracy: 0.8108\n",
            "Epoch 160/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4256 - auc_16: 0.8582 - binary_accuracy: 0.7635 - val_loss: 0.4715 - val_auc_16: 0.8303 - val_binary_accuracy: 0.7973\n",
            "Epoch 161/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4203 - auc_16: 0.8657 - binary_accuracy: 0.7838 - val_loss: 0.4744 - val_auc_16: 0.8316 - val_binary_accuracy: 0.7838\n",
            "Epoch 162/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4296 - auc_16: 0.8504 - binary_accuracy: 0.7703 - val_loss: 0.4686 - val_auc_16: 0.8355 - val_binary_accuracy: 0.8378\n",
            "Epoch 163/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4214 - auc_16: 0.8624 - binary_accuracy: 0.7736 - val_loss: 0.4712 - val_auc_16: 0.8359 - val_binary_accuracy: 0.7973\n",
            "Epoch 164/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4222 - auc_16: 0.8621 - binary_accuracy: 0.7804 - val_loss: 0.4762 - val_auc_16: 0.8355 - val_binary_accuracy: 0.7838\n",
            "Epoch 165/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4241 - auc_16: 0.8515 - binary_accuracy: 0.7568 - val_loss: 0.4789 - val_auc_16: 0.8321 - val_binary_accuracy: 0.7838\n",
            "Epoch 166/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4199 - auc_16: 0.8629 - binary_accuracy: 0.7905 - val_loss: 0.4706 - val_auc_16: 0.8363 - val_binary_accuracy: 0.8108\n",
            "Epoch 167/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4177 - auc_16: 0.8650 - binary_accuracy: 0.7838 - val_loss: 0.4723 - val_auc_16: 0.8355 - val_binary_accuracy: 0.7568\n",
            "Epoch 168/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4133 - auc_16: 0.8679 - binary_accuracy: 0.7838 - val_loss: 0.4716 - val_auc_16: 0.8363 - val_binary_accuracy: 0.7568\n",
            "Epoch 169/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4223 - auc_16: 0.8599 - binary_accuracy: 0.7838 - val_loss: 0.4701 - val_auc_16: 0.8367 - val_binary_accuracy: 0.7703\n",
            "Epoch 170/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4117 - auc_16: 0.8705 - binary_accuracy: 0.7872 - val_loss: 0.4754 - val_auc_16: 0.8329 - val_binary_accuracy: 0.7838\n",
            "Epoch 171/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4318 - auc_16: 0.8542 - binary_accuracy: 0.7703 - val_loss: 0.4773 - val_auc_16: 0.8312 - val_binary_accuracy: 0.7568\n",
            "Epoch 172/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4078 - auc_16: 0.8771 - binary_accuracy: 0.7973 - val_loss: 0.4843 - val_auc_16: 0.8312 - val_binary_accuracy: 0.7432\n",
            "Epoch 173/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4203 - auc_16: 0.8648 - binary_accuracy: 0.7838 - val_loss: 0.4711 - val_auc_16: 0.8346 - val_binary_accuracy: 0.7838\n",
            "Epoch 174/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3979 - auc_16: 0.8798 - binary_accuracy: 0.7973 - val_loss: 0.4715 - val_auc_16: 0.8363 - val_binary_accuracy: 0.7973\n",
            "Epoch 175/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4144 - auc_16: 0.8697 - binary_accuracy: 0.7804 - val_loss: 0.4724 - val_auc_16: 0.8363 - val_binary_accuracy: 0.7973\n",
            "Epoch 176/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4134 - auc_16: 0.8641 - binary_accuracy: 0.7770 - val_loss: 0.4795 - val_auc_16: 0.8342 - val_binary_accuracy: 0.7432\n",
            "Epoch 177/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3990 - auc_16: 0.8800 - binary_accuracy: 0.8007 - val_loss: 0.4822 - val_auc_16: 0.8333 - val_binary_accuracy: 0.7703\n",
            "Epoch 178/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4231 - auc_16: 0.8628 - binary_accuracy: 0.7905 - val_loss: 0.4791 - val_auc_16: 0.8325 - val_binary_accuracy: 0.7838\n",
            "Epoch 179/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4186 - auc_16: 0.8632 - binary_accuracy: 0.7838 - val_loss: 0.4821 - val_auc_16: 0.8333 - val_binary_accuracy: 0.7703\n",
            "Epoch 180/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4180 - auc_16: 0.8587 - binary_accuracy: 0.7770 - val_loss: 0.4884 - val_auc_16: 0.8338 - val_binary_accuracy: 0.7568\n",
            "Epoch 181/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4256 - auc_16: 0.8601 - binary_accuracy: 0.7905 - val_loss: 0.4754 - val_auc_16: 0.8342 - val_binary_accuracy: 0.7838\n",
            "Epoch 182/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4183 - auc_16: 0.8689 - binary_accuracy: 0.7905 - val_loss: 0.4708 - val_auc_16: 0.8453 - val_binary_accuracy: 0.8378\n",
            "Epoch 183/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4137 - auc_16: 0.8673 - binary_accuracy: 0.7804 - val_loss: 0.4737 - val_auc_16: 0.8414 - val_binary_accuracy: 0.7838\n",
            "Epoch 184/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4011 - auc_16: 0.8791 - binary_accuracy: 0.7939 - val_loss: 0.4727 - val_auc_16: 0.8419 - val_binary_accuracy: 0.7973\n",
            "Epoch 185/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4150 - auc_16: 0.8667 - binary_accuracy: 0.7872 - val_loss: 0.4749 - val_auc_16: 0.8406 - val_binary_accuracy: 0.7838\n",
            "Epoch 186/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4059 - auc_16: 0.8692 - binary_accuracy: 0.7905 - val_loss: 0.4733 - val_auc_16: 0.8453 - val_binary_accuracy: 0.8108\n",
            "Epoch 187/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3940 - auc_16: 0.8830 - binary_accuracy: 0.7973 - val_loss: 0.4738 - val_auc_16: 0.8444 - val_binary_accuracy: 0.7973\n",
            "Epoch 188/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4133 - auc_16: 0.8640 - binary_accuracy: 0.7838 - val_loss: 0.4704 - val_auc_16: 0.8465 - val_binary_accuracy: 0.8243\n",
            "Epoch 189/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4003 - auc_16: 0.8767 - binary_accuracy: 0.8007 - val_loss: 0.4777 - val_auc_16: 0.8384 - val_binary_accuracy: 0.8108\n",
            "Epoch 190/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3923 - auc_16: 0.8884 - binary_accuracy: 0.8108 - val_loss: 0.4767 - val_auc_16: 0.8419 - val_binary_accuracy: 0.7838\n",
            "Epoch 191/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4085 - auc_16: 0.8694 - binary_accuracy: 0.7905 - val_loss: 0.4729 - val_auc_16: 0.8448 - val_binary_accuracy: 0.8243\n",
            "Epoch 192/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3870 - auc_16: 0.8922 - binary_accuracy: 0.8108 - val_loss: 0.4794 - val_auc_16: 0.8376 - val_binary_accuracy: 0.7973\n",
            "Epoch 193/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3957 - auc_16: 0.8791 - binary_accuracy: 0.7905 - val_loss: 0.4851 - val_auc_16: 0.8338 - val_binary_accuracy: 0.7838\n",
            "Epoch 194/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3999 - auc_16: 0.8798 - binary_accuracy: 0.8176 - val_loss: 0.4829 - val_auc_16: 0.8367 - val_binary_accuracy: 0.7973\n",
            "Epoch 195/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3922 - auc_16: 0.8808 - binary_accuracy: 0.8176 - val_loss: 0.4782 - val_auc_16: 0.8427 - val_binary_accuracy: 0.7973\n",
            "Epoch 196/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3974 - auc_16: 0.8810 - binary_accuracy: 0.7905 - val_loss: 0.4780 - val_auc_16: 0.8444 - val_binary_accuracy: 0.7973\n",
            "Epoch 197/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3915 - auc_16: 0.8851 - binary_accuracy: 0.8007 - val_loss: 0.4730 - val_auc_16: 0.8406 - val_binary_accuracy: 0.8243\n",
            "Epoch 198/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3835 - auc_16: 0.8917 - binary_accuracy: 0.8041 - val_loss: 0.4803 - val_auc_16: 0.8359 - val_binary_accuracy: 0.8108\n",
            "Epoch 199/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3816 - auc_16: 0.8930 - binary_accuracy: 0.8176 - val_loss: 0.4797 - val_auc_16: 0.8342 - val_binary_accuracy: 0.8108\n",
            "Epoch 200/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3888 - auc_16: 0.8868 - binary_accuracy: 0.8074 - val_loss: 0.4780 - val_auc_16: 0.8380 - val_binary_accuracy: 0.8108\n",
            "Epoch 201/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3798 - auc_16: 0.8953 - binary_accuracy: 0.8108 - val_loss: 0.4834 - val_auc_16: 0.8363 - val_binary_accuracy: 0.7973\n",
            "Epoch 202/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3818 - auc_16: 0.8931 - binary_accuracy: 0.8142 - val_loss: 0.4843 - val_auc_16: 0.8329 - val_binary_accuracy: 0.7838\n",
            "Epoch 203/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3930 - auc_16: 0.8786 - binary_accuracy: 0.8176 - val_loss: 0.4778 - val_auc_16: 0.8355 - val_binary_accuracy: 0.7973\n",
            "Epoch 204/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3822 - auc_16: 0.8922 - binary_accuracy: 0.8176 - val_loss: 0.4803 - val_auc_16: 0.8397 - val_binary_accuracy: 0.8108\n",
            "Epoch 205/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3831 - auc_16: 0.8916 - binary_accuracy: 0.8007 - val_loss: 0.4833 - val_auc_16: 0.8367 - val_binary_accuracy: 0.7973\n",
            "Epoch 206/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4056 - auc_16: 0.8749 - binary_accuracy: 0.7905 - val_loss: 0.4814 - val_auc_16: 0.8359 - val_binary_accuracy: 0.8108\n",
            "Epoch 207/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3960 - auc_16: 0.8824 - binary_accuracy: 0.8108 - val_loss: 0.4853 - val_auc_16: 0.8299 - val_binary_accuracy: 0.7973\n",
            "Epoch 208/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3868 - auc_16: 0.8907 - binary_accuracy: 0.8074 - val_loss: 0.4837 - val_auc_16: 0.8291 - val_binary_accuracy: 0.7973\n",
            "Epoch 209/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3897 - auc_16: 0.8853 - binary_accuracy: 0.8007 - val_loss: 0.4825 - val_auc_16: 0.8338 - val_binary_accuracy: 0.7973\n",
            "Epoch 210/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3909 - auc_16: 0.8863 - binary_accuracy: 0.8277 - val_loss: 0.4737 - val_auc_16: 0.8376 - val_binary_accuracy: 0.8108\n",
            "Epoch 211/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3976 - auc_16: 0.8840 - binary_accuracy: 0.8074 - val_loss: 0.4698 - val_auc_16: 0.8440 - val_binary_accuracy: 0.8378\n",
            "Epoch 212/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4171 - auc_16: 0.8711 - binary_accuracy: 0.8007 - val_loss: 0.4731 - val_auc_16: 0.8431 - val_binary_accuracy: 0.8108\n",
            "Epoch 213/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3987 - auc_16: 0.8753 - binary_accuracy: 0.7939 - val_loss: 0.4745 - val_auc_16: 0.8423 - val_binary_accuracy: 0.8108\n",
            "Epoch 214/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3726 - auc_16: 0.8980 - binary_accuracy: 0.8041 - val_loss: 0.4687 - val_auc_16: 0.8474 - val_binary_accuracy: 0.8243\n",
            "Epoch 215/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3680 - auc_16: 0.8974 - binary_accuracy: 0.8142 - val_loss: 0.4786 - val_auc_16: 0.8406 - val_binary_accuracy: 0.7973\n",
            "Epoch 216/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3759 - auc_16: 0.9017 - binary_accuracy: 0.8277 - val_loss: 0.4767 - val_auc_16: 0.8423 - val_binary_accuracy: 0.8108\n",
            "Epoch 217/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3686 - auc_16: 0.8982 - binary_accuracy: 0.8345 - val_loss: 0.4744 - val_auc_16: 0.8414 - val_binary_accuracy: 0.8108\n",
            "Epoch 218/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3785 - auc_16: 0.8939 - binary_accuracy: 0.8243 - val_loss: 0.4703 - val_auc_16: 0.8448 - val_binary_accuracy: 0.8108\n",
            "Epoch 219/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3916 - auc_16: 0.8862 - binary_accuracy: 0.8007 - val_loss: 0.4698 - val_auc_16: 0.8436 - val_binary_accuracy: 0.8108\n",
            "Epoch 220/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3720 - auc_16: 0.8977 - binary_accuracy: 0.8311 - val_loss: 0.4717 - val_auc_16: 0.8431 - val_binary_accuracy: 0.8243\n",
            "Epoch 221/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3881 - auc_16: 0.8836 - binary_accuracy: 0.8108 - val_loss: 0.4732 - val_auc_16: 0.8440 - val_binary_accuracy: 0.8108\n",
            "Epoch 222/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3612 - auc_16: 0.9017 - binary_accuracy: 0.8243 - val_loss: 0.4709 - val_auc_16: 0.8453 - val_binary_accuracy: 0.8243\n",
            "Epoch 223/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3949 - auc_16: 0.8765 - binary_accuracy: 0.7872 - val_loss: 0.4702 - val_auc_16: 0.8457 - val_binary_accuracy: 0.8378\n",
            "Epoch 224/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3583 - auc_16: 0.9068 - binary_accuracy: 0.8074 - val_loss: 0.4711 - val_auc_16: 0.8410 - val_binary_accuracy: 0.8108\n",
            "Epoch 225/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3589 - auc_16: 0.9064 - binary_accuracy: 0.8243 - val_loss: 0.4855 - val_auc_16: 0.8278 - val_binary_accuracy: 0.7973\n",
            "Epoch 226/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3794 - auc_16: 0.8963 - binary_accuracy: 0.8311 - val_loss: 0.4814 - val_auc_16: 0.8325 - val_binary_accuracy: 0.7973\n",
            "Epoch 227/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3673 - auc_16: 0.8995 - binary_accuracy: 0.8243 - val_loss: 0.4785 - val_auc_16: 0.8372 - val_binary_accuracy: 0.8243\n",
            "Epoch 228/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3703 - auc_16: 0.9024 - binary_accuracy: 0.8345 - val_loss: 0.4868 - val_auc_16: 0.8282 - val_binary_accuracy: 0.8108\n",
            "Epoch 229/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3507 - auc_16: 0.9137 - binary_accuracy: 0.8615 - val_loss: 0.4815 - val_auc_16: 0.8359 - val_binary_accuracy: 0.8243\n",
            "Epoch 230/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3515 - auc_16: 0.9125 - binary_accuracy: 0.8345 - val_loss: 0.4832 - val_auc_16: 0.8338 - val_binary_accuracy: 0.8108\n",
            "Epoch 231/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3646 - auc_16: 0.9087 - binary_accuracy: 0.8277 - val_loss: 0.4732 - val_auc_16: 0.8419 - val_binary_accuracy: 0.8243\n",
            "Epoch 232/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3528 - auc_16: 0.9154 - binary_accuracy: 0.8277 - val_loss: 0.4734 - val_auc_16: 0.8419 - val_binary_accuracy: 0.8243\n",
            "Epoch 233/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3419 - auc_16: 0.9191 - binary_accuracy: 0.8345 - val_loss: 0.4796 - val_auc_16: 0.8384 - val_binary_accuracy: 0.8243\n",
            "Epoch 234/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3651 - auc_16: 0.9028 - binary_accuracy: 0.8277 - val_loss: 0.4822 - val_auc_16: 0.8384 - val_binary_accuracy: 0.8108\n",
            "Epoch 235/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3855 - auc_16: 0.8931 - binary_accuracy: 0.8142 - val_loss: 0.4852 - val_auc_16: 0.8342 - val_binary_accuracy: 0.8108\n",
            "Epoch 236/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3569 - auc_16: 0.9104 - binary_accuracy: 0.8378 - val_loss: 0.4796 - val_auc_16: 0.8410 - val_binary_accuracy: 0.8108\n",
            "Epoch 237/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3720 - auc_16: 0.8974 - binary_accuracy: 0.8108 - val_loss: 0.4833 - val_auc_16: 0.8359 - val_binary_accuracy: 0.7838\n",
            "Epoch 238/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3597 - auc_16: 0.9100 - binary_accuracy: 0.8243 - val_loss: 0.4758 - val_auc_16: 0.8372 - val_binary_accuracy: 0.8108\n",
            "Epoch 239/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3451 - auc_16: 0.9144 - binary_accuracy: 0.8378 - val_loss: 0.4734 - val_auc_16: 0.8448 - val_binary_accuracy: 0.8243\n",
            "Epoch 240/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3753 - auc_16: 0.8909 - binary_accuracy: 0.8176 - val_loss: 0.4862 - val_auc_16: 0.8363 - val_binary_accuracy: 0.7703\n",
            "Epoch 241/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3797 - auc_16: 0.8999 - binary_accuracy: 0.8243 - val_loss: 0.4742 - val_auc_16: 0.8410 - val_binary_accuracy: 0.8108\n",
            "Epoch 242/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3594 - auc_16: 0.9061 - binary_accuracy: 0.8142 - val_loss: 0.4693 - val_auc_16: 0.8470 - val_binary_accuracy: 0.8108\n",
            "Epoch 243/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3511 - auc_16: 0.9097 - binary_accuracy: 0.8176 - val_loss: 0.4720 - val_auc_16: 0.8440 - val_binary_accuracy: 0.8108\n",
            "Epoch 244/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3642 - auc_16: 0.9056 - binary_accuracy: 0.8277 - val_loss: 0.4780 - val_auc_16: 0.8423 - val_binary_accuracy: 0.8108\n",
            "Epoch 245/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3502 - auc_16: 0.9148 - binary_accuracy: 0.8311 - val_loss: 0.4695 - val_auc_16: 0.8529 - val_binary_accuracy: 0.8378\n",
            "Epoch 246/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3562 - auc_16: 0.9093 - binary_accuracy: 0.8176 - val_loss: 0.4676 - val_auc_16: 0.8529 - val_binary_accuracy: 0.8243\n",
            "Epoch 247/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3525 - auc_16: 0.9098 - binary_accuracy: 0.8311 - val_loss: 0.4800 - val_auc_16: 0.8359 - val_binary_accuracy: 0.7838\n",
            "Epoch 248/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3622 - auc_16: 0.9030 - binary_accuracy: 0.8243 - val_loss: 0.4807 - val_auc_16: 0.8393 - val_binary_accuracy: 0.7838\n",
            "Epoch 249/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3888 - auc_16: 0.8891 - binary_accuracy: 0.8176 - val_loss: 0.4756 - val_auc_16: 0.8495 - val_binary_accuracy: 0.8378\n",
            "Epoch 250/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3677 - auc_16: 0.8999 - binary_accuracy: 0.8176 - val_loss: 0.4754 - val_auc_16: 0.8465 - val_binary_accuracy: 0.8243\n",
            "Epoch 251/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3602 - auc_16: 0.9083 - binary_accuracy: 0.8209 - val_loss: 0.4775 - val_auc_16: 0.8444 - val_binary_accuracy: 0.7973\n",
            "Epoch 252/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3620 - auc_16: 0.9042 - binary_accuracy: 0.8378 - val_loss: 0.4820 - val_auc_16: 0.8453 - val_binary_accuracy: 0.7973\n",
            "Epoch 253/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3645 - auc_16: 0.9031 - binary_accuracy: 0.8209 - val_loss: 0.4848 - val_auc_16: 0.8363 - val_binary_accuracy: 0.8243\n",
            "Epoch 254/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3606 - auc_16: 0.9082 - binary_accuracy: 0.8378 - val_loss: 0.4940 - val_auc_16: 0.8295 - val_binary_accuracy: 0.7703\n",
            "Epoch 255/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3486 - auc_16: 0.9155 - binary_accuracy: 0.8209 - val_loss: 0.4865 - val_auc_16: 0.8355 - val_binary_accuracy: 0.7973\n",
            "Epoch 256/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3489 - auc_16: 0.9176 - binary_accuracy: 0.8480 - val_loss: 0.4920 - val_auc_16: 0.8333 - val_binary_accuracy: 0.8108\n",
            "Epoch 257/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3701 - auc_16: 0.8986 - binary_accuracy: 0.8277 - val_loss: 0.4848 - val_auc_16: 0.8448 - val_binary_accuracy: 0.8243\n",
            "Epoch 258/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3381 - auc_16: 0.9189 - binary_accuracy: 0.8412 - val_loss: 0.4788 - val_auc_16: 0.8474 - val_binary_accuracy: 0.8243\n",
            "Epoch 259/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3384 - auc_16: 0.9226 - binary_accuracy: 0.8649 - val_loss: 0.4916 - val_auc_16: 0.8295 - val_binary_accuracy: 0.7703\n",
            "Epoch 260/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3484 - auc_16: 0.9160 - binary_accuracy: 0.8345 - val_loss: 0.4979 - val_auc_16: 0.8257 - val_binary_accuracy: 0.7838\n",
            "Epoch 261/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3549 - auc_16: 0.9152 - binary_accuracy: 0.8311 - val_loss: 0.4977 - val_auc_16: 0.8312 - val_binary_accuracy: 0.7838\n",
            "Epoch 262/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3725 - auc_16: 0.8966 - binary_accuracy: 0.8108 - val_loss: 0.4998 - val_auc_16: 0.8350 - val_binary_accuracy: 0.7838\n",
            "Epoch 263/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3649 - auc_16: 0.8995 - binary_accuracy: 0.8378 - val_loss: 0.4910 - val_auc_16: 0.8402 - val_binary_accuracy: 0.8243\n",
            "Epoch 264/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3338 - auc_16: 0.9271 - binary_accuracy: 0.8581 - val_loss: 0.4868 - val_auc_16: 0.8410 - val_binary_accuracy: 0.8108\n",
            "Epoch 265/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3397 - auc_16: 0.9164 - binary_accuracy: 0.8277 - val_loss: 0.4891 - val_auc_16: 0.8406 - val_binary_accuracy: 0.8108\n",
            "Epoch 266/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3707 - auc_16: 0.9012 - binary_accuracy: 0.8378 - val_loss: 0.5019 - val_auc_16: 0.8261 - val_binary_accuracy: 0.7973\n",
            "Epoch 267/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3564 - auc_16: 0.9089 - binary_accuracy: 0.8176 - val_loss: 0.4971 - val_auc_16: 0.8299 - val_binary_accuracy: 0.7568\n",
            "Epoch 268/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3411 - auc_16: 0.9213 - binary_accuracy: 0.8480 - val_loss: 0.4862 - val_auc_16: 0.8453 - val_binary_accuracy: 0.8243\n",
            "Epoch 269/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3607 - auc_16: 0.9065 - binary_accuracy: 0.8345 - val_loss: 0.4915 - val_auc_16: 0.8431 - val_binary_accuracy: 0.8243\n",
            "Epoch 270/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3761 - auc_16: 0.8999 - binary_accuracy: 0.8243 - val_loss: 0.4875 - val_auc_16: 0.8406 - val_binary_accuracy: 0.8108\n",
            "Epoch 271/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3389 - auc_16: 0.9226 - binary_accuracy: 0.8412 - val_loss: 0.4916 - val_auc_16: 0.8389 - val_binary_accuracy: 0.7973\n",
            "Epoch 272/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3662 - auc_16: 0.8998 - binary_accuracy: 0.8176 - val_loss: 0.5004 - val_auc_16: 0.8286 - val_binary_accuracy: 0.7973\n",
            "Epoch 273/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3441 - auc_16: 0.9162 - binary_accuracy: 0.8412 - val_loss: 0.4868 - val_auc_16: 0.8448 - val_binary_accuracy: 0.7973\n",
            "Epoch 274/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3422 - auc_16: 0.9160 - binary_accuracy: 0.8412 - val_loss: 0.4784 - val_auc_16: 0.8564 - val_binary_accuracy: 0.8108\n",
            "Epoch 275/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3324 - auc_16: 0.9220 - binary_accuracy: 0.8480 - val_loss: 0.4885 - val_auc_16: 0.8457 - val_binary_accuracy: 0.7973\n",
            "Epoch 276/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3372 - auc_16: 0.9196 - binary_accuracy: 0.8446 - val_loss: 0.4942 - val_auc_16: 0.8367 - val_binary_accuracy: 0.7973\n",
            "Epoch 277/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3455 - auc_16: 0.9149 - binary_accuracy: 0.8480 - val_loss: 0.4867 - val_auc_16: 0.8423 - val_binary_accuracy: 0.7973\n",
            "Epoch 278/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3469 - auc_16: 0.9135 - binary_accuracy: 0.8209 - val_loss: 0.4757 - val_auc_16: 0.8564 - val_binary_accuracy: 0.8514\n",
            "Epoch 279/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3377 - auc_16: 0.9212 - binary_accuracy: 0.8581 - val_loss: 0.4851 - val_auc_16: 0.8525 - val_binary_accuracy: 0.8108\n",
            "Epoch 280/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3311 - auc_16: 0.9254 - binary_accuracy: 0.8649 - val_loss: 0.5050 - val_auc_16: 0.8316 - val_binary_accuracy: 0.7973\n",
            "Epoch 281/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3316 - auc_16: 0.9293 - binary_accuracy: 0.8649 - val_loss: 0.5229 - val_auc_16: 0.8163 - val_binary_accuracy: 0.7703\n",
            "Epoch 282/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3402 - auc_16: 0.9214 - binary_accuracy: 0.8412 - val_loss: 0.5131 - val_auc_16: 0.8227 - val_binary_accuracy: 0.7703\n",
            "Epoch 283/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3336 - auc_16: 0.9240 - binary_accuracy: 0.8480 - val_loss: 0.5002 - val_auc_16: 0.8372 - val_binary_accuracy: 0.7973\n",
            "Epoch 284/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3401 - auc_16: 0.9140 - binary_accuracy: 0.8480 - val_loss: 0.4958 - val_auc_16: 0.8389 - val_binary_accuracy: 0.7838\n",
            "Epoch 285/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3194 - auc_16: 0.9290 - binary_accuracy: 0.8446 - val_loss: 0.4971 - val_auc_16: 0.8402 - val_binary_accuracy: 0.8108\n",
            "Epoch 286/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3365 - auc_16: 0.9164 - binary_accuracy: 0.8243 - val_loss: 0.4905 - val_auc_16: 0.8419 - val_binary_accuracy: 0.8108\n",
            "Epoch 287/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3368 - auc_16: 0.9153 - binary_accuracy: 0.8277 - val_loss: 0.5011 - val_auc_16: 0.8393 - val_binary_accuracy: 0.7973\n",
            "Epoch 288/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3252 - auc_16: 0.9302 - binary_accuracy: 0.8446 - val_loss: 0.4959 - val_auc_16: 0.8393 - val_binary_accuracy: 0.7973\n",
            "Epoch 289/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3470 - auc_16: 0.9120 - binary_accuracy: 0.8277 - val_loss: 0.4999 - val_auc_16: 0.8384 - val_binary_accuracy: 0.7973\n",
            "Epoch 290/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3224 - auc_16: 0.9294 - binary_accuracy: 0.8514 - val_loss: 0.4964 - val_auc_16: 0.8406 - val_binary_accuracy: 0.7973\n",
            "Epoch 291/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3524 - auc_16: 0.9121 - binary_accuracy: 0.8446 - val_loss: 0.5102 - val_auc_16: 0.8282 - val_binary_accuracy: 0.7838\n",
            "Epoch 292/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3355 - auc_16: 0.9292 - binary_accuracy: 0.8649 - val_loss: 0.5188 - val_auc_16: 0.8269 - val_binary_accuracy: 0.7568\n",
            "Epoch 293/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3205 - auc_16: 0.9353 - binary_accuracy: 0.8378 - val_loss: 0.4918 - val_auc_16: 0.8448 - val_binary_accuracy: 0.8108\n",
            "Epoch 294/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3346 - auc_16: 0.9207 - binary_accuracy: 0.8378 - val_loss: 0.4963 - val_auc_16: 0.8380 - val_binary_accuracy: 0.7973\n",
            "Epoch 295/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3382 - auc_16: 0.9173 - binary_accuracy: 0.8514 - val_loss: 0.5034 - val_auc_16: 0.8325 - val_binary_accuracy: 0.7703\n",
            "Epoch 296/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3305 - auc_16: 0.9235 - binary_accuracy: 0.8446 - val_loss: 0.5022 - val_auc_16: 0.8372 - val_binary_accuracy: 0.7838\n",
            "Epoch 297/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3312 - auc_16: 0.9191 - binary_accuracy: 0.8480 - val_loss: 0.5091 - val_auc_16: 0.8333 - val_binary_accuracy: 0.7703\n",
            "Epoch 298/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3281 - auc_16: 0.9313 - binary_accuracy: 0.8750 - val_loss: 0.5217 - val_auc_16: 0.8214 - val_binary_accuracy: 0.7703\n",
            "Epoch 299/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3351 - auc_16: 0.9195 - binary_accuracy: 0.8547 - val_loss: 0.5074 - val_auc_16: 0.8321 - val_binary_accuracy: 0.7703\n",
            "Epoch 300/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3547 - auc_16: 0.9113 - binary_accuracy: 0.8480 - val_loss: 0.5059 - val_auc_16: 0.8325 - val_binary_accuracy: 0.7838\n",
            "Epoch 301/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3160 - auc_16: 0.9318 - binary_accuracy: 0.8378 - val_loss: 0.5164 - val_auc_16: 0.8257 - val_binary_accuracy: 0.7568\n",
            "Epoch 302/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3381 - auc_16: 0.9161 - binary_accuracy: 0.8412 - val_loss: 0.5161 - val_auc_16: 0.8295 - val_binary_accuracy: 0.7568\n",
            "Epoch 303/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3429 - auc_16: 0.9154 - binary_accuracy: 0.8378 - val_loss: 0.5151 - val_auc_16: 0.8295 - val_binary_accuracy: 0.7703\n",
            "Epoch 304/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3161 - auc_16: 0.9331 - binary_accuracy: 0.8716 - val_loss: 0.5040 - val_auc_16: 0.8359 - val_binary_accuracy: 0.7838\n",
            "Epoch 305/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3268 - auc_16: 0.9269 - binary_accuracy: 0.8682 - val_loss: 0.5030 - val_auc_16: 0.8380 - val_binary_accuracy: 0.7838\n",
            "Epoch 306/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3489 - auc_16: 0.9084 - binary_accuracy: 0.8345 - val_loss: 0.5054 - val_auc_16: 0.8338 - val_binary_accuracy: 0.7838\n",
            "Epoch 307/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3195 - auc_16: 0.9301 - binary_accuracy: 0.8682 - val_loss: 0.5097 - val_auc_16: 0.8350 - val_binary_accuracy: 0.7703\n",
            "Epoch 308/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3441 - auc_16: 0.9198 - binary_accuracy: 0.8412 - val_loss: 0.5150 - val_auc_16: 0.8325 - val_binary_accuracy: 0.7568\n",
            "Epoch 309/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3059 - auc_16: 0.9371 - binary_accuracy: 0.8615 - val_loss: 0.5176 - val_auc_16: 0.8303 - val_binary_accuracy: 0.7568\n",
            "Epoch 310/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3263 - auc_16: 0.9222 - binary_accuracy: 0.8581 - val_loss: 0.5223 - val_auc_16: 0.8261 - val_binary_accuracy: 0.7568\n",
            "Epoch 311/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3270 - auc_16: 0.9238 - binary_accuracy: 0.8412 - val_loss: 0.5285 - val_auc_16: 0.8235 - val_binary_accuracy: 0.7703\n",
            "Epoch 312/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3630 - auc_16: 0.9042 - binary_accuracy: 0.8277 - val_loss: 0.5186 - val_auc_16: 0.8257 - val_binary_accuracy: 0.7703\n",
            "Epoch 313/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3271 - auc_16: 0.9287 - binary_accuracy: 0.8446 - val_loss: 0.5174 - val_auc_16: 0.8299 - val_binary_accuracy: 0.7568\n",
            "Epoch 314/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3101 - auc_16: 0.9348 - binary_accuracy: 0.8649 - val_loss: 0.5233 - val_auc_16: 0.8257 - val_binary_accuracy: 0.7568\n",
            "Epoch 315/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3393 - auc_16: 0.9219 - binary_accuracy: 0.8446 - val_loss: 0.5323 - val_auc_16: 0.8150 - val_binary_accuracy: 0.7568\n",
            "Epoch 316/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2934 - auc_16: 0.9509 - binary_accuracy: 0.8750 - val_loss: 0.5311 - val_auc_16: 0.8184 - val_binary_accuracy: 0.7432\n",
            "Epoch 317/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3227 - auc_16: 0.9342 - binary_accuracy: 0.8885 - val_loss: 0.5212 - val_auc_16: 0.8282 - val_binary_accuracy: 0.7568\n",
            "Epoch 318/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3126 - auc_16: 0.9376 - binary_accuracy: 0.8716 - val_loss: 0.5123 - val_auc_16: 0.8342 - val_binary_accuracy: 0.7568\n",
            "Epoch 319/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3171 - auc_16: 0.9329 - binary_accuracy: 0.8649 - val_loss: 0.5074 - val_auc_16: 0.8402 - val_binary_accuracy: 0.7703\n",
            "Epoch 320/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3142 - auc_16: 0.9291 - binary_accuracy: 0.8446 - val_loss: 0.5137 - val_auc_16: 0.8342 - val_binary_accuracy: 0.7703\n",
            "Epoch 321/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3116 - auc_16: 0.9322 - binary_accuracy: 0.8682 - val_loss: 0.5143 - val_auc_16: 0.8308 - val_binary_accuracy: 0.7703\n",
            "Epoch 322/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3118 - auc_16: 0.9317 - binary_accuracy: 0.8581 - val_loss: 0.5206 - val_auc_16: 0.8286 - val_binary_accuracy: 0.7703\n",
            "Epoch 323/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3187 - auc_16: 0.9295 - binary_accuracy: 0.8581 - val_loss: 0.5117 - val_auc_16: 0.8346 - val_binary_accuracy: 0.7703\n",
            "Epoch 324/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3059 - auc_16: 0.9367 - binary_accuracy: 0.8547 - val_loss: 0.5150 - val_auc_16: 0.8312 - val_binary_accuracy: 0.7703\n",
            "Epoch 325/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2971 - auc_16: 0.9422 - binary_accuracy: 0.8682 - val_loss: 0.5207 - val_auc_16: 0.8308 - val_binary_accuracy: 0.7568\n",
            "Epoch 326/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3124 - auc_16: 0.9302 - binary_accuracy: 0.8480 - val_loss: 0.5242 - val_auc_16: 0.8257 - val_binary_accuracy: 0.7568\n",
            "Epoch 327/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3246 - auc_16: 0.9229 - binary_accuracy: 0.8581 - val_loss: 0.5182 - val_auc_16: 0.8282 - val_binary_accuracy: 0.7432\n",
            "Epoch 328/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2805 - auc_16: 0.9503 - binary_accuracy: 0.8716 - val_loss: 0.5092 - val_auc_16: 0.8355 - val_binary_accuracy: 0.7703\n",
            "Epoch 329/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3290 - auc_16: 0.9258 - binary_accuracy: 0.8682 - val_loss: 0.5129 - val_auc_16: 0.8308 - val_binary_accuracy: 0.7838\n",
            "Epoch 330/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3152 - auc_16: 0.9283 - binary_accuracy: 0.8514 - val_loss: 0.5171 - val_auc_16: 0.8282 - val_binary_accuracy: 0.7432\n",
            "Epoch 331/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3224 - auc_16: 0.9284 - binary_accuracy: 0.8480 - val_loss: 0.5236 - val_auc_16: 0.8248 - val_binary_accuracy: 0.7568\n",
            "Epoch 332/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3021 - auc_16: 0.9411 - binary_accuracy: 0.8649 - val_loss: 0.5462 - val_auc_16: 0.8103 - val_binary_accuracy: 0.7568\n",
            "Epoch 333/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3265 - auc_16: 0.9241 - binary_accuracy: 0.8547 - val_loss: 0.5357 - val_auc_16: 0.8205 - val_binary_accuracy: 0.7703\n",
            "Epoch 334/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3111 - auc_16: 0.9351 - binary_accuracy: 0.8615 - val_loss: 0.5239 - val_auc_16: 0.8235 - val_binary_accuracy: 0.7703\n",
            "Epoch 335/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3357 - auc_16: 0.9196 - binary_accuracy: 0.8446 - val_loss: 0.5187 - val_auc_16: 0.8265 - val_binary_accuracy: 0.7703\n",
            "Epoch 336/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3038 - auc_16: 0.9387 - binary_accuracy: 0.8851 - val_loss: 0.5366 - val_auc_16: 0.8184 - val_binary_accuracy: 0.7432\n",
            "Epoch 337/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3231 - auc_16: 0.9264 - binary_accuracy: 0.8311 - val_loss: 0.5320 - val_auc_16: 0.8184 - val_binary_accuracy: 0.7703\n",
            "Epoch 338/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3109 - auc_16: 0.9321 - binary_accuracy: 0.8649 - val_loss: 0.5430 - val_auc_16: 0.8107 - val_binary_accuracy: 0.7568\n",
            "Epoch 339/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3328 - auc_16: 0.9235 - binary_accuracy: 0.8716 - val_loss: 0.5363 - val_auc_16: 0.8188 - val_binary_accuracy: 0.7568\n",
            "Epoch 340/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3183 - auc_16: 0.9263 - binary_accuracy: 0.8514 - val_loss: 0.5287 - val_auc_16: 0.8257 - val_binary_accuracy: 0.7703\n",
            "Epoch 341/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3087 - auc_16: 0.9336 - binary_accuracy: 0.8682 - val_loss: 0.5359 - val_auc_16: 0.8197 - val_binary_accuracy: 0.7703\n",
            "Epoch 342/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3089 - auc_16: 0.9334 - binary_accuracy: 0.8682 - val_loss: 0.5457 - val_auc_16: 0.8137 - val_binary_accuracy: 0.7432\n",
            "Epoch 343/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3033 - auc_16: 0.9358 - binary_accuracy: 0.8682 - val_loss: 0.5413 - val_auc_16: 0.8184 - val_binary_accuracy: 0.7703\n",
            "Epoch 344/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2901 - auc_16: 0.9404 - binary_accuracy: 0.8716 - val_loss: 0.5439 - val_auc_16: 0.8124 - val_binary_accuracy: 0.7703\n",
            "Epoch 345/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2997 - auc_16: 0.9408 - binary_accuracy: 0.8818 - val_loss: 0.5521 - val_auc_16: 0.8112 - val_binary_accuracy: 0.7432\n",
            "Epoch 346/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3100 - auc_16: 0.9319 - binary_accuracy: 0.8716 - val_loss: 0.5605 - val_auc_16: 0.8082 - val_binary_accuracy: 0.7297\n",
            "Epoch 347/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2702 - auc_16: 0.9552 - binary_accuracy: 0.8986 - val_loss: 0.5499 - val_auc_16: 0.8129 - val_binary_accuracy: 0.7568\n",
            "Epoch 348/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3118 - auc_16: 0.9355 - binary_accuracy: 0.8716 - val_loss: 0.5457 - val_auc_16: 0.8150 - val_binary_accuracy: 0.7568\n",
            "Epoch 349/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2774 - auc_16: 0.9528 - binary_accuracy: 0.8919 - val_loss: 0.5394 - val_auc_16: 0.8223 - val_binary_accuracy: 0.7568\n",
            "Epoch 350/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2738 - auc_16: 0.9535 - binary_accuracy: 0.8750 - val_loss: 0.5363 - val_auc_16: 0.8197 - val_binary_accuracy: 0.7568\n",
            "Epoch 351/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3029 - auc_16: 0.9399 - binary_accuracy: 0.8547 - val_loss: 0.5491 - val_auc_16: 0.8146 - val_binary_accuracy: 0.7432\n",
            "Epoch 352/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2919 - auc_16: 0.9451 - binary_accuracy: 0.8750 - val_loss: 0.5379 - val_auc_16: 0.8205 - val_binary_accuracy: 0.7838\n",
            "Epoch 353/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3022 - auc_16: 0.9390 - binary_accuracy: 0.8784 - val_loss: 0.5358 - val_auc_16: 0.8240 - val_binary_accuracy: 0.7838\n",
            "Epoch 354/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2864 - auc_16: 0.9477 - binary_accuracy: 0.8851 - val_loss: 0.5496 - val_auc_16: 0.8129 - val_binary_accuracy: 0.7568\n",
            "Epoch 355/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2776 - auc_16: 0.9526 - binary_accuracy: 0.8750 - val_loss: 0.5394 - val_auc_16: 0.8214 - val_binary_accuracy: 0.7838\n",
            "Epoch 356/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3002 - auc_16: 0.9387 - binary_accuracy: 0.8649 - val_loss: 0.5415 - val_auc_16: 0.8231 - val_binary_accuracy: 0.7568\n",
            "Epoch 357/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2904 - auc_16: 0.9458 - binary_accuracy: 0.8885 - val_loss: 0.5486 - val_auc_16: 0.8197 - val_binary_accuracy: 0.7432\n",
            "Epoch 358/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3019 - auc_16: 0.9373 - binary_accuracy: 0.8615 - val_loss: 0.5387 - val_auc_16: 0.8261 - val_binary_accuracy: 0.7838\n",
            "Epoch 359/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3305 - auc_16: 0.9201 - binary_accuracy: 0.8412 - val_loss: 0.5544 - val_auc_16: 0.8176 - val_binary_accuracy: 0.7432\n",
            "Epoch 360/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2952 - auc_16: 0.9398 - binary_accuracy: 0.8682 - val_loss: 0.5333 - val_auc_16: 0.8261 - val_binary_accuracy: 0.7703\n",
            "Epoch 361/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2846 - auc_16: 0.9486 - binary_accuracy: 0.8649 - val_loss: 0.5317 - val_auc_16: 0.8274 - val_binary_accuracy: 0.7838\n",
            "Epoch 362/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3096 - auc_16: 0.9320 - binary_accuracy: 0.8649 - val_loss: 0.5280 - val_auc_16: 0.8308 - val_binary_accuracy: 0.7838\n",
            "Epoch 363/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2988 - auc_16: 0.9388 - binary_accuracy: 0.8547 - val_loss: 0.5276 - val_auc_16: 0.8338 - val_binary_accuracy: 0.7838\n",
            "Epoch 364/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2854 - auc_16: 0.9467 - binary_accuracy: 0.8682 - val_loss: 0.5429 - val_auc_16: 0.8214 - val_binary_accuracy: 0.7432\n",
            "Epoch 365/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2917 - auc_16: 0.9423 - binary_accuracy: 0.8784 - val_loss: 0.5541 - val_auc_16: 0.8167 - val_binary_accuracy: 0.7432\n",
            "Epoch 366/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2772 - auc_16: 0.9501 - binary_accuracy: 0.8919 - val_loss: 0.5580 - val_auc_16: 0.8159 - val_binary_accuracy: 0.7432\n",
            "Epoch 367/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3071 - auc_16: 0.9376 - binary_accuracy: 0.8851 - val_loss: 0.5644 - val_auc_16: 0.8056 - val_binary_accuracy: 0.7162\n",
            "Epoch 368/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2910 - auc_16: 0.9456 - binary_accuracy: 0.8851 - val_loss: 0.5415 - val_auc_16: 0.8223 - val_binary_accuracy: 0.7432\n",
            "Epoch 369/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2717 - auc_16: 0.9490 - binary_accuracy: 0.8649 - val_loss: 0.5344 - val_auc_16: 0.8269 - val_binary_accuracy: 0.7432\n",
            "Epoch 370/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3223 - auc_16: 0.9196 - binary_accuracy: 0.8514 - val_loss: 0.5552 - val_auc_16: 0.8129 - val_binary_accuracy: 0.7162\n",
            "Epoch 371/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3185 - auc_16: 0.9324 - binary_accuracy: 0.8581 - val_loss: 0.5652 - val_auc_16: 0.8082 - val_binary_accuracy: 0.7568\n",
            "Epoch 372/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2648 - auc_16: 0.9598 - binary_accuracy: 0.8986 - val_loss: 0.5693 - val_auc_16: 0.8048 - val_binary_accuracy: 0.7432\n",
            "Epoch 373/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2699 - auc_16: 0.9536 - binary_accuracy: 0.8750 - val_loss: 0.5689 - val_auc_16: 0.8065 - val_binary_accuracy: 0.7162\n",
            "Epoch 374/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2730 - auc_16: 0.9486 - binary_accuracy: 0.8953 - val_loss: 0.5525 - val_auc_16: 0.8197 - val_binary_accuracy: 0.7432\n",
            "Epoch 375/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2892 - auc_16: 0.9416 - binary_accuracy: 0.8851 - val_loss: 0.5516 - val_auc_16: 0.8210 - val_binary_accuracy: 0.7432\n",
            "Epoch 376/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2949 - auc_16: 0.9415 - binary_accuracy: 0.8784 - val_loss: 0.5568 - val_auc_16: 0.8171 - val_binary_accuracy: 0.7432\n",
            "Epoch 377/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2849 - auc_16: 0.9472 - binary_accuracy: 0.8784 - val_loss: 0.5907 - val_auc_16: 0.7988 - val_binary_accuracy: 0.7162\n",
            "Epoch 378/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2942 - auc_16: 0.9420 - binary_accuracy: 0.8682 - val_loss: 0.5919 - val_auc_16: 0.7988 - val_binary_accuracy: 0.7297\n",
            "Epoch 379/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2983 - auc_16: 0.9388 - binary_accuracy: 0.8784 - val_loss: 0.5771 - val_auc_16: 0.8099 - val_binary_accuracy: 0.7162\n",
            "Epoch 380/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2640 - auc_16: 0.9542 - binary_accuracy: 0.8953 - val_loss: 0.5700 - val_auc_16: 0.8112 - val_binary_accuracy: 0.7297\n",
            "Epoch 381/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2831 - auc_16: 0.9445 - binary_accuracy: 0.8615 - val_loss: 0.5602 - val_auc_16: 0.8171 - val_binary_accuracy: 0.7703\n",
            "Epoch 382/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2387 - auc_16: 0.9694 - binary_accuracy: 0.9020 - val_loss: 0.5592 - val_auc_16: 0.8248 - val_binary_accuracy: 0.7568\n",
            "Epoch 383/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2794 - auc_16: 0.9425 - binary_accuracy: 0.8784 - val_loss: 0.5724 - val_auc_16: 0.8137 - val_binary_accuracy: 0.7568\n",
            "Epoch 384/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2912 - auc_16: 0.9449 - binary_accuracy: 0.8818 - val_loss: 0.5959 - val_auc_16: 0.7980 - val_binary_accuracy: 0.7162\n",
            "Epoch 385/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2754 - auc_16: 0.9539 - binary_accuracy: 0.8851 - val_loss: 0.5937 - val_auc_16: 0.7988 - val_binary_accuracy: 0.7297\n",
            "Epoch 386/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2908 - auc_16: 0.9421 - binary_accuracy: 0.9020 - val_loss: 0.5726 - val_auc_16: 0.8099 - val_binary_accuracy: 0.7432\n",
            "Epoch 387/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2920 - auc_16: 0.9398 - binary_accuracy: 0.8649 - val_loss: 0.5799 - val_auc_16: 0.8073 - val_binary_accuracy: 0.7297\n",
            "Epoch 388/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2971 - auc_16: 0.9376 - binary_accuracy: 0.8649 - val_loss: 0.5787 - val_auc_16: 0.8048 - val_binary_accuracy: 0.7297\n",
            "Epoch 389/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2875 - auc_16: 0.9426 - binary_accuracy: 0.8649 - val_loss: 0.5672 - val_auc_16: 0.8205 - val_binary_accuracy: 0.7432\n",
            "Epoch 390/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2685 - auc_16: 0.9509 - binary_accuracy: 0.8953 - val_loss: 0.5631 - val_auc_16: 0.8205 - val_binary_accuracy: 0.7297\n",
            "Epoch 391/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3157 - auc_16: 0.9306 - binary_accuracy: 0.8750 - val_loss: 0.5858 - val_auc_16: 0.8035 - val_binary_accuracy: 0.7297\n",
            "Epoch 392/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2963 - auc_16: 0.9385 - binary_accuracy: 0.8682 - val_loss: 0.5863 - val_auc_16: 0.8090 - val_binary_accuracy: 0.7297\n",
            "Epoch 393/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3054 - auc_16: 0.9309 - binary_accuracy: 0.8750 - val_loss: 0.5735 - val_auc_16: 0.8120 - val_binary_accuracy: 0.7162\n",
            "Epoch 394/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3093 - auc_16: 0.9311 - binary_accuracy: 0.8446 - val_loss: 0.5647 - val_auc_16: 0.8146 - val_binary_accuracy: 0.7432\n",
            "Epoch 395/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2645 - auc_16: 0.9563 - binary_accuracy: 0.8885 - val_loss: 0.5630 - val_auc_16: 0.8137 - val_binary_accuracy: 0.7297\n",
            "Epoch 396/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2859 - auc_16: 0.9428 - binary_accuracy: 0.8615 - val_loss: 0.5635 - val_auc_16: 0.8107 - val_binary_accuracy: 0.7432\n",
            "Epoch 397/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2866 - auc_16: 0.9457 - binary_accuracy: 0.8818 - val_loss: 0.5657 - val_auc_16: 0.8197 - val_binary_accuracy: 0.7297\n",
            "Epoch 398/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2523 - auc_16: 0.9619 - binary_accuracy: 0.8986 - val_loss: 0.5535 - val_auc_16: 0.8278 - val_binary_accuracy: 0.7703\n",
            "Epoch 399/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2713 - auc_16: 0.9536 - binary_accuracy: 0.8851 - val_loss: 0.5787 - val_auc_16: 0.8116 - val_binary_accuracy: 0.7297\n",
            "Epoch 400/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3010 - auc_16: 0.9389 - binary_accuracy: 0.8750 - val_loss: 0.6121 - val_auc_16: 0.7937 - val_binary_accuracy: 0.7162\n",
            "Epoch 401/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2700 - auc_16: 0.9527 - binary_accuracy: 0.8851 - val_loss: 0.6032 - val_auc_16: 0.7971 - val_binary_accuracy: 0.7432\n",
            "Epoch 402/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3199 - auc_16: 0.9295 - binary_accuracy: 0.8581 - val_loss: 0.5895 - val_auc_16: 0.8082 - val_binary_accuracy: 0.7297\n",
            "Epoch 403/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2820 - auc_16: 0.9508 - binary_accuracy: 0.8919 - val_loss: 0.6050 - val_auc_16: 0.8018 - val_binary_accuracy: 0.7027\n",
            "Epoch 404/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2470 - auc_16: 0.9632 - binary_accuracy: 0.8919 - val_loss: 0.6064 - val_auc_16: 0.7992 - val_binary_accuracy: 0.7027\n",
            "Epoch 405/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2809 - auc_16: 0.9461 - binary_accuracy: 0.8784 - val_loss: 0.6030 - val_auc_16: 0.8014 - val_binary_accuracy: 0.7297\n",
            "Epoch 406/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2851 - auc_16: 0.9441 - binary_accuracy: 0.8851 - val_loss: 0.5974 - val_auc_16: 0.8043 - val_binary_accuracy: 0.7297\n",
            "Epoch 407/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3104 - auc_16: 0.9338 - binary_accuracy: 0.8750 - val_loss: 0.6316 - val_auc_16: 0.7822 - val_binary_accuracy: 0.6892\n",
            "Epoch 408/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3039 - auc_16: 0.9371 - binary_accuracy: 0.8986 - val_loss: 0.6203 - val_auc_16: 0.7899 - val_binary_accuracy: 0.7027\n",
            "Epoch 409/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2772 - auc_16: 0.9488 - binary_accuracy: 0.8885 - val_loss: 0.6032 - val_auc_16: 0.7954 - val_binary_accuracy: 0.7297\n",
            "Epoch 410/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2887 - auc_16: 0.9481 - binary_accuracy: 0.8953 - val_loss: 0.5952 - val_auc_16: 0.8056 - val_binary_accuracy: 0.7432\n",
            "Epoch 411/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2803 - auc_16: 0.9470 - binary_accuracy: 0.8919 - val_loss: 0.6049 - val_auc_16: 0.8043 - val_binary_accuracy: 0.7162\n",
            "Epoch 412/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3015 - auc_16: 0.9352 - binary_accuracy: 0.8514 - val_loss: 0.5986 - val_auc_16: 0.8065 - val_binary_accuracy: 0.7162\n",
            "Epoch 413/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2922 - auc_16: 0.9384 - binary_accuracy: 0.8784 - val_loss: 0.5916 - val_auc_16: 0.8035 - val_binary_accuracy: 0.7432\n",
            "Epoch 414/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2759 - auc_16: 0.9495 - binary_accuracy: 0.8716 - val_loss: 0.6050 - val_auc_16: 0.7950 - val_binary_accuracy: 0.7297\n",
            "Epoch 415/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2745 - auc_16: 0.9485 - binary_accuracy: 0.8885 - val_loss: 0.6022 - val_auc_16: 0.7945 - val_binary_accuracy: 0.7297\n",
            "Epoch 416/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2677 - auc_16: 0.9542 - binary_accuracy: 0.8784 - val_loss: 0.6126 - val_auc_16: 0.7882 - val_binary_accuracy: 0.7162\n",
            "Epoch 417/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2581 - auc_16: 0.9577 - binary_accuracy: 0.8885 - val_loss: 0.6025 - val_auc_16: 0.7980 - val_binary_accuracy: 0.7027\n",
            "Epoch 418/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2746 - auc_16: 0.9488 - binary_accuracy: 0.8953 - val_loss: 0.5943 - val_auc_16: 0.8065 - val_binary_accuracy: 0.7297\n",
            "Epoch 419/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2411 - auc_16: 0.9630 - binary_accuracy: 0.9223 - val_loss: 0.5842 - val_auc_16: 0.8069 - val_binary_accuracy: 0.7297\n",
            "Epoch 420/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2855 - auc_16: 0.9452 - binary_accuracy: 0.8919 - val_loss: 0.5795 - val_auc_16: 0.8099 - val_binary_accuracy: 0.7432\n",
            "Epoch 421/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2789 - auc_16: 0.9464 - binary_accuracy: 0.8750 - val_loss: 0.5702 - val_auc_16: 0.8159 - val_binary_accuracy: 0.7297\n",
            "Epoch 422/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2735 - auc_16: 0.9490 - binary_accuracy: 0.8953 - val_loss: 0.5614 - val_auc_16: 0.8240 - val_binary_accuracy: 0.7703\n",
            "Epoch 423/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2689 - auc_16: 0.9531 - binary_accuracy: 0.9020 - val_loss: 0.5692 - val_auc_16: 0.8188 - val_binary_accuracy: 0.7568\n",
            "Epoch 424/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2760 - auc_16: 0.9474 - binary_accuracy: 0.8818 - val_loss: 0.5724 - val_auc_16: 0.8193 - val_binary_accuracy: 0.7568\n",
            "Epoch 425/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2344 - auc_16: 0.9672 - binary_accuracy: 0.9054 - val_loss: 0.5774 - val_auc_16: 0.8171 - val_binary_accuracy: 0.7432\n",
            "Epoch 426/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2568 - auc_16: 0.9573 - binary_accuracy: 0.9054 - val_loss: 0.5871 - val_auc_16: 0.8133 - val_binary_accuracy: 0.7297\n",
            "Epoch 427/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2450 - auc_16: 0.9617 - binary_accuracy: 0.9054 - val_loss: 0.5943 - val_auc_16: 0.8086 - val_binary_accuracy: 0.7297\n",
            "Epoch 428/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2987 - auc_16: 0.9370 - binary_accuracy: 0.8716 - val_loss: 0.5956 - val_auc_16: 0.8022 - val_binary_accuracy: 0.7297\n",
            "Epoch 429/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2746 - auc_16: 0.9522 - binary_accuracy: 0.8986 - val_loss: 0.5945 - val_auc_16: 0.8069 - val_binary_accuracy: 0.7297\n",
            "Epoch 430/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2998 - auc_16: 0.9376 - binary_accuracy: 0.8818 - val_loss: 0.5883 - val_auc_16: 0.8103 - val_binary_accuracy: 0.7432\n",
            "Epoch 431/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2772 - auc_16: 0.9473 - binary_accuracy: 0.9054 - val_loss: 0.5991 - val_auc_16: 0.8086 - val_binary_accuracy: 0.7297\n",
            "Epoch 432/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2508 - auc_16: 0.9616 - binary_accuracy: 0.9155 - val_loss: 0.5915 - val_auc_16: 0.8120 - val_binary_accuracy: 0.7297\n",
            "Epoch 433/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2828 - auc_16: 0.9425 - binary_accuracy: 0.8750 - val_loss: 0.6105 - val_auc_16: 0.7967 - val_binary_accuracy: 0.7297\n",
            "Epoch 434/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2390 - auc_16: 0.9664 - binary_accuracy: 0.9122 - val_loss: 0.5980 - val_auc_16: 0.8035 - val_binary_accuracy: 0.7568\n",
            "Epoch 435/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2679 - auc_16: 0.9503 - binary_accuracy: 0.8784 - val_loss: 0.5956 - val_auc_16: 0.8078 - val_binary_accuracy: 0.7568\n",
            "Epoch 436/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2700 - auc_16: 0.9536 - binary_accuracy: 0.8885 - val_loss: 0.6025 - val_auc_16: 0.8022 - val_binary_accuracy: 0.7568\n",
            "Epoch 437/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2606 - auc_16: 0.9559 - binary_accuracy: 0.8919 - val_loss: 0.6042 - val_auc_16: 0.8009 - val_binary_accuracy: 0.7297\n",
            "Epoch 438/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2944 - auc_16: 0.9374 - binary_accuracy: 0.8615 - val_loss: 0.5960 - val_auc_16: 0.8095 - val_binary_accuracy: 0.7432\n",
            "Epoch 439/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2440 - auc_16: 0.9635 - binary_accuracy: 0.9054 - val_loss: 0.5809 - val_auc_16: 0.8167 - val_binary_accuracy: 0.7568\n",
            "Epoch 440/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2750 - auc_16: 0.9452 - binary_accuracy: 0.8953 - val_loss: 0.5968 - val_auc_16: 0.8056 - val_binary_accuracy: 0.7297\n",
            "Epoch 441/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2544 - auc_16: 0.9574 - binary_accuracy: 0.9054 - val_loss: 0.6116 - val_auc_16: 0.8018 - val_binary_accuracy: 0.7568\n",
            "Epoch 442/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2384 - auc_16: 0.9665 - binary_accuracy: 0.9088 - val_loss: 0.6124 - val_auc_16: 0.7992 - val_binary_accuracy: 0.7703\n",
            "Epoch 443/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2724 - auc_16: 0.9493 - binary_accuracy: 0.8716 - val_loss: 0.6354 - val_auc_16: 0.7937 - val_binary_accuracy: 0.7027\n",
            "Epoch 444/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2593 - auc_16: 0.9549 - binary_accuracy: 0.9054 - val_loss: 0.6369 - val_auc_16: 0.7950 - val_binary_accuracy: 0.7027\n",
            "Epoch 445/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2764 - auc_16: 0.9451 - binary_accuracy: 0.8750 - val_loss: 0.6114 - val_auc_16: 0.8031 - val_binary_accuracy: 0.7162\n",
            "Epoch 446/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2805 - auc_16: 0.9436 - binary_accuracy: 0.8750 - val_loss: 0.6010 - val_auc_16: 0.8086 - val_binary_accuracy: 0.7568\n",
            "Epoch 447/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2614 - auc_16: 0.9500 - binary_accuracy: 0.8851 - val_loss: 0.5890 - val_auc_16: 0.8133 - val_binary_accuracy: 0.7432\n",
            "Epoch 448/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2483 - auc_16: 0.9579 - binary_accuracy: 0.9054 - val_loss: 0.6111 - val_auc_16: 0.8005 - val_binary_accuracy: 0.7162\n",
            "Epoch 449/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2830 - auc_16: 0.9443 - binary_accuracy: 0.8682 - val_loss: 0.6165 - val_auc_16: 0.8018 - val_binary_accuracy: 0.7027\n",
            "Epoch 450/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2578 - auc_16: 0.9559 - binary_accuracy: 0.8953 - val_loss: 0.6053 - val_auc_16: 0.8056 - val_binary_accuracy: 0.7432\n",
            "Epoch 451/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3058 - auc_16: 0.9324 - binary_accuracy: 0.8716 - val_loss: 0.6033 - val_auc_16: 0.8073 - val_binary_accuracy: 0.7432\n",
            "Epoch 452/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2658 - auc_16: 0.9591 - binary_accuracy: 0.8818 - val_loss: 0.6291 - val_auc_16: 0.7903 - val_binary_accuracy: 0.6892\n",
            "Epoch 453/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2750 - auc_16: 0.9478 - binary_accuracy: 0.8784 - val_loss: 0.6280 - val_auc_16: 0.7962 - val_binary_accuracy: 0.7297\n",
            "Epoch 454/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2554 - auc_16: 0.9586 - binary_accuracy: 0.8986 - val_loss: 0.6112 - val_auc_16: 0.8026 - val_binary_accuracy: 0.7162\n",
            "Epoch 455/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2607 - auc_16: 0.9523 - binary_accuracy: 0.8649 - val_loss: 0.6182 - val_auc_16: 0.8009 - val_binary_accuracy: 0.7703\n",
            "Epoch 456/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2506 - auc_16: 0.9620 - binary_accuracy: 0.9020 - val_loss: 0.6180 - val_auc_16: 0.7997 - val_binary_accuracy: 0.7432\n",
            "Epoch 457/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2219 - auc_16: 0.9730 - binary_accuracy: 0.9054 - val_loss: 0.6069 - val_auc_16: 0.8061 - val_binary_accuracy: 0.7432\n",
            "Epoch 458/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2759 - auc_16: 0.9484 - binary_accuracy: 0.8784 - val_loss: 0.6081 - val_auc_16: 0.8031 - val_binary_accuracy: 0.7432\n",
            "Epoch 459/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2309 - auc_16: 0.9685 - binary_accuracy: 0.9155 - val_loss: 0.6178 - val_auc_16: 0.8009 - val_binary_accuracy: 0.7432\n",
            "Epoch 460/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2720 - auc_16: 0.9488 - binary_accuracy: 0.8986 - val_loss: 0.6260 - val_auc_16: 0.8022 - val_binary_accuracy: 0.7432\n",
            "Epoch 461/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2779 - auc_16: 0.9458 - binary_accuracy: 0.8784 - val_loss: 0.6142 - val_auc_16: 0.8026 - val_binary_accuracy: 0.7297\n",
            "Epoch 462/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2822 - auc_16: 0.9488 - binary_accuracy: 0.8885 - val_loss: 0.6086 - val_auc_16: 0.8065 - val_binary_accuracy: 0.7027\n",
            "Epoch 463/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2425 - auc_16: 0.9636 - binary_accuracy: 0.9088 - val_loss: 0.6075 - val_auc_16: 0.8061 - val_binary_accuracy: 0.7027\n",
            "Epoch 464/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2631 - auc_16: 0.9539 - binary_accuracy: 0.9189 - val_loss: 0.5954 - val_auc_16: 0.8129 - val_binary_accuracy: 0.7162\n",
            "Epoch 465/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2441 - auc_16: 0.9619 - binary_accuracy: 0.9122 - val_loss: 0.5889 - val_auc_16: 0.8176 - val_binary_accuracy: 0.7568\n",
            "Epoch 466/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2133 - auc_16: 0.9751 - binary_accuracy: 0.9155 - val_loss: 0.6033 - val_auc_16: 0.8107 - val_binary_accuracy: 0.7162\n",
            "Epoch 467/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2460 - auc_16: 0.9594 - binary_accuracy: 0.9088 - val_loss: 0.6146 - val_auc_16: 0.8069 - val_binary_accuracy: 0.7162\n",
            "Epoch 468/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2433 - auc_16: 0.9615 - binary_accuracy: 0.9088 - val_loss: 0.6120 - val_auc_16: 0.8069 - val_binary_accuracy: 0.7162\n",
            "Epoch 469/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2470 - auc_16: 0.9583 - binary_accuracy: 0.8986 - val_loss: 0.6142 - val_auc_16: 0.8078 - val_binary_accuracy: 0.7432\n",
            "Epoch 470/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2308 - auc_16: 0.9668 - binary_accuracy: 0.9088 - val_loss: 0.6149 - val_auc_16: 0.8124 - val_binary_accuracy: 0.7703\n",
            "Epoch 471/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2851 - auc_16: 0.9434 - binary_accuracy: 0.8851 - val_loss: 0.6318 - val_auc_16: 0.8001 - val_binary_accuracy: 0.7297\n",
            "Epoch 472/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2422 - auc_16: 0.9650 - binary_accuracy: 0.8953 - val_loss: 0.6351 - val_auc_16: 0.8005 - val_binary_accuracy: 0.7162\n",
            "Epoch 473/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2510 - auc_16: 0.9552 - binary_accuracy: 0.8986 - val_loss: 0.6406 - val_auc_16: 0.8009 - val_binary_accuracy: 0.7432\n",
            "Epoch 474/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3039 - auc_16: 0.9357 - binary_accuracy: 0.8885 - val_loss: 0.6566 - val_auc_16: 0.7933 - val_binary_accuracy: 0.7162\n",
            "Epoch 475/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2844 - auc_16: 0.9482 - binary_accuracy: 0.8615 - val_loss: 0.6510 - val_auc_16: 0.7958 - val_binary_accuracy: 0.7432\n",
            "Epoch 476/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2571 - auc_16: 0.9586 - binary_accuracy: 0.9088 - val_loss: 0.6060 - val_auc_16: 0.8124 - val_binary_accuracy: 0.7297\n",
            "Epoch 477/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2279 - auc_16: 0.9678 - binary_accuracy: 0.9054 - val_loss: 0.5879 - val_auc_16: 0.8269 - val_binary_accuracy: 0.7568\n",
            "Epoch 478/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2903 - auc_16: 0.9429 - binary_accuracy: 0.8851 - val_loss: 0.5971 - val_auc_16: 0.8176 - val_binary_accuracy: 0.7568\n",
            "Epoch 479/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2636 - auc_16: 0.9532 - binary_accuracy: 0.8851 - val_loss: 0.6211 - val_auc_16: 0.8061 - val_binary_accuracy: 0.7297\n",
            "Epoch 480/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2326 - auc_16: 0.9637 - binary_accuracy: 0.9223 - val_loss: 0.6267 - val_auc_16: 0.8061 - val_binary_accuracy: 0.7297\n",
            "Epoch 481/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2321 - auc_16: 0.9650 - binary_accuracy: 0.9088 - val_loss: 0.6291 - val_auc_16: 0.8026 - val_binary_accuracy: 0.7432\n",
            "Epoch 482/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2501 - auc_16: 0.9592 - binary_accuracy: 0.9122 - val_loss: 0.6336 - val_auc_16: 0.7997 - val_binary_accuracy: 0.7297\n",
            "Epoch 483/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2738 - auc_16: 0.9496 - binary_accuracy: 0.8851 - val_loss: 0.6615 - val_auc_16: 0.7890 - val_binary_accuracy: 0.7162\n",
            "Epoch 484/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2412 - auc_16: 0.9664 - binary_accuracy: 0.9054 - val_loss: 0.6603 - val_auc_16: 0.7864 - val_binary_accuracy: 0.7432\n",
            "Epoch 485/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2508 - auc_16: 0.9579 - binary_accuracy: 0.9088 - val_loss: 0.6455 - val_auc_16: 0.7962 - val_binary_accuracy: 0.7568\n",
            "Epoch 486/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2452 - auc_16: 0.9591 - binary_accuracy: 0.8851 - val_loss: 0.6206 - val_auc_16: 0.8090 - val_binary_accuracy: 0.7568\n",
            "Epoch 487/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2390 - auc_16: 0.9602 - binary_accuracy: 0.8851 - val_loss: 0.6364 - val_auc_16: 0.8022 - val_binary_accuracy: 0.7432\n",
            "Epoch 488/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2596 - auc_16: 0.9533 - binary_accuracy: 0.9189 - val_loss: 0.6481 - val_auc_16: 0.8001 - val_binary_accuracy: 0.7297\n",
            "Epoch 489/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2374 - auc_16: 0.9617 - binary_accuracy: 0.8919 - val_loss: 0.6405 - val_auc_16: 0.8001 - val_binary_accuracy: 0.7162\n",
            "Epoch 490/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2309 - auc_16: 0.9632 - binary_accuracy: 0.9122 - val_loss: 0.6430 - val_auc_16: 0.8026 - val_binary_accuracy: 0.7027\n",
            "Epoch 491/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2286 - auc_16: 0.9659 - binary_accuracy: 0.9088 - val_loss: 0.6443 - val_auc_16: 0.8052 - val_binary_accuracy: 0.7568\n",
            "Epoch 492/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2513 - auc_16: 0.9561 - binary_accuracy: 0.8986 - val_loss: 0.6624 - val_auc_16: 0.7886 - val_binary_accuracy: 0.7297\n",
            "Epoch 493/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2183 - auc_16: 0.9716 - binary_accuracy: 0.9155 - val_loss: 0.6874 - val_auc_16: 0.7860 - val_binary_accuracy: 0.7027\n",
            "Epoch 494/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2397 - auc_16: 0.9619 - binary_accuracy: 0.8986 - val_loss: 0.6720 - val_auc_16: 0.7920 - val_binary_accuracy: 0.7027\n",
            "Epoch 495/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2369 - auc_16: 0.9617 - binary_accuracy: 0.8986 - val_loss: 0.6531 - val_auc_16: 0.8001 - val_binary_accuracy: 0.7162\n",
            "Epoch 496/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2322 - auc_16: 0.9650 - binary_accuracy: 0.9020 - val_loss: 0.6497 - val_auc_16: 0.8022 - val_binary_accuracy: 0.7162\n",
            "Epoch 497/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2399 - auc_16: 0.9606 - binary_accuracy: 0.9020 - val_loss: 0.6425 - val_auc_16: 0.8014 - val_binary_accuracy: 0.7568\n",
            "Epoch 498/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2431 - auc_16: 0.9628 - binary_accuracy: 0.9088 - val_loss: 0.6493 - val_auc_16: 0.7980 - val_binary_accuracy: 0.7432\n",
            "Epoch 499/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2118 - auc_16: 0.9732 - binary_accuracy: 0.9088 - val_loss: 0.7017 - val_auc_16: 0.7805 - val_binary_accuracy: 0.6757\n",
            "Epoch 500/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2573 - auc_16: 0.9531 - binary_accuracy: 0.8986 - val_loss: 0.7163 - val_auc_16: 0.7715 - val_binary_accuracy: 0.7162\n",
            "Epoch 1/500\n",
            "10/10 [==============================] - 3s 90ms/step - loss: 0.6793 - auc_17: 0.4997 - binary_accuracy: 0.6115 - val_loss: 0.6715 - val_auc_17: 0.4557 - val_binary_accuracy: 0.6757\n",
            "Epoch 2/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.6571 - auc_17: 0.6022 - binary_accuracy: 0.6757 - val_loss: 0.6497 - val_auc_17: 0.5605 - val_binary_accuracy: 0.6892\n",
            "Epoch 3/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6373 - auc_17: 0.6392 - binary_accuracy: 0.6791 - val_loss: 0.6277 - val_auc_17: 0.6292 - val_binary_accuracy: 0.6892\n",
            "Epoch 4/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6129 - auc_17: 0.6799 - binary_accuracy: 0.6892 - val_loss: 0.6076 - val_auc_17: 0.6552 - val_binary_accuracy: 0.6757\n",
            "Epoch 5/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5966 - auc_17: 0.6763 - binary_accuracy: 0.6824 - val_loss: 0.5952 - val_auc_17: 0.6581 - val_binary_accuracy: 0.6757\n",
            "Epoch 6/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5822 - auc_17: 0.6847 - binary_accuracy: 0.6858 - val_loss: 0.5922 - val_auc_17: 0.6624 - val_binary_accuracy: 0.6757\n",
            "Epoch 7/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5808 - auc_17: 0.6856 - binary_accuracy: 0.6824 - val_loss: 0.5968 - val_auc_17: 0.6573 - val_binary_accuracy: 0.6757\n",
            "Epoch 8/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5837 - auc_17: 0.6849 - binary_accuracy: 0.6959 - val_loss: 0.6017 - val_auc_17: 0.6526 - val_binary_accuracy: 0.6757\n",
            "Epoch 9/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5798 - auc_17: 0.6892 - binary_accuracy: 0.6824 - val_loss: 0.5995 - val_auc_17: 0.6513 - val_binary_accuracy: 0.7027\n",
            "Epoch 10/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5737 - auc_17: 0.6948 - binary_accuracy: 0.6892 - val_loss: 0.6003 - val_auc_17: 0.6543 - val_binary_accuracy: 0.7027\n",
            "Epoch 11/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5739 - auc_17: 0.6951 - binary_accuracy: 0.6791 - val_loss: 0.5983 - val_auc_17: 0.6556 - val_binary_accuracy: 0.7027\n",
            "Epoch 12/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5742 - auc_17: 0.6956 - binary_accuracy: 0.6993 - val_loss: 0.5996 - val_auc_17: 0.6530 - val_binary_accuracy: 0.6892\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5668 - auc_17: 0.7053 - binary_accuracy: 0.7095 - val_loss: 0.5997 - val_auc_17: 0.6556 - val_binary_accuracy: 0.6892\n",
            "Epoch 14/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5700 - auc_17: 0.7021 - binary_accuracy: 0.6926 - val_loss: 0.6015 - val_auc_17: 0.6624 - val_binary_accuracy: 0.7027\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5693 - auc_17: 0.7033 - binary_accuracy: 0.7027 - val_loss: 0.6027 - val_auc_17: 0.6620 - val_binary_accuracy: 0.7027\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5644 - auc_17: 0.7100 - binary_accuracy: 0.6926 - val_loss: 0.6032 - val_auc_17: 0.6624 - val_binary_accuracy: 0.7027\n",
            "Epoch 17/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5646 - auc_17: 0.7117 - binary_accuracy: 0.7027 - val_loss: 0.6016 - val_auc_17: 0.6594 - val_binary_accuracy: 0.7027\n",
            "Epoch 18/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5685 - auc_17: 0.7003 - binary_accuracy: 0.6993 - val_loss: 0.5977 - val_auc_17: 0.6616 - val_binary_accuracy: 0.7027\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5616 - auc_17: 0.7158 - binary_accuracy: 0.6926 - val_loss: 0.5976 - val_auc_17: 0.6645 - val_binary_accuracy: 0.7027\n",
            "Epoch 20/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5634 - auc_17: 0.7101 - binary_accuracy: 0.6757 - val_loss: 0.5983 - val_auc_17: 0.6675 - val_binary_accuracy: 0.7027\n",
            "Epoch 21/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5686 - auc_17: 0.7046 - binary_accuracy: 0.7027 - val_loss: 0.6006 - val_auc_17: 0.6667 - val_binary_accuracy: 0.6892\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5579 - auc_17: 0.7173 - binary_accuracy: 0.6892 - val_loss: 0.5973 - val_auc_17: 0.6684 - val_binary_accuracy: 0.6892\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5618 - auc_17: 0.7135 - binary_accuracy: 0.6959 - val_loss: 0.5953 - val_auc_17: 0.6692 - val_binary_accuracy: 0.6892\n",
            "Epoch 24/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5531 - auc_17: 0.7291 - binary_accuracy: 0.7027 - val_loss: 0.5935 - val_auc_17: 0.6697 - val_binary_accuracy: 0.6892\n",
            "Epoch 25/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5637 - auc_17: 0.7076 - binary_accuracy: 0.6892 - val_loss: 0.5937 - val_auc_17: 0.6722 - val_binary_accuracy: 0.6757\n",
            "Epoch 26/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5529 - auc_17: 0.7296 - binary_accuracy: 0.7095 - val_loss: 0.5880 - val_auc_17: 0.6769 - val_binary_accuracy: 0.6892\n",
            "Epoch 27/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5590 - auc_17: 0.7198 - binary_accuracy: 0.7027 - val_loss: 0.5849 - val_auc_17: 0.6799 - val_binary_accuracy: 0.6892\n",
            "Epoch 28/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5618 - auc_17: 0.7143 - binary_accuracy: 0.7128 - val_loss: 0.5862 - val_auc_17: 0.6790 - val_binary_accuracy: 0.6892\n",
            "Epoch 29/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5572 - auc_17: 0.7206 - binary_accuracy: 0.7027 - val_loss: 0.5897 - val_auc_17: 0.6735 - val_binary_accuracy: 0.6622\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5443 - auc_17: 0.7462 - binary_accuracy: 0.7196 - val_loss: 0.5836 - val_auc_17: 0.6807 - val_binary_accuracy: 0.6892\n",
            "Epoch 31/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5553 - auc_17: 0.7274 - binary_accuracy: 0.7128 - val_loss: 0.5863 - val_auc_17: 0.6841 - val_binary_accuracy: 0.6892\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.5523 - auc_17: 0.7303 - binary_accuracy: 0.7095 - val_loss: 0.5792 - val_auc_17: 0.6961 - val_binary_accuracy: 0.6892\n",
            "Epoch 33/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5444 - auc_17: 0.7519 - binary_accuracy: 0.7095 - val_loss: 0.5819 - val_auc_17: 0.6944 - val_binary_accuracy: 0.6892\n",
            "Epoch 34/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5511 - auc_17: 0.7360 - binary_accuracy: 0.7095 - val_loss: 0.5832 - val_auc_17: 0.6854 - val_binary_accuracy: 0.6757\n",
            "Epoch 35/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5507 - auc_17: 0.7326 - binary_accuracy: 0.7264 - val_loss: 0.5899 - val_auc_17: 0.6799 - val_binary_accuracy: 0.7027\n",
            "Epoch 36/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5483 - auc_17: 0.7387 - binary_accuracy: 0.7331 - val_loss: 0.5817 - val_auc_17: 0.6897 - val_binary_accuracy: 0.6757\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5467 - auc_17: 0.7383 - binary_accuracy: 0.7162 - val_loss: 0.5769 - val_auc_17: 0.6952 - val_binary_accuracy: 0.7027\n",
            "Epoch 38/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5464 - auc_17: 0.7342 - binary_accuracy: 0.7162 - val_loss: 0.5716 - val_auc_17: 0.7042 - val_binary_accuracy: 0.7162\n",
            "Epoch 39/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5419 - auc_17: 0.7476 - binary_accuracy: 0.7128 - val_loss: 0.5655 - val_auc_17: 0.7114 - val_binary_accuracy: 0.7297\n",
            "Epoch 40/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5392 - auc_17: 0.7530 - binary_accuracy: 0.7162 - val_loss: 0.5657 - val_auc_17: 0.7127 - val_binary_accuracy: 0.7027\n",
            "Epoch 41/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5333 - auc_17: 0.7577 - binary_accuracy: 0.7297 - val_loss: 0.5579 - val_auc_17: 0.7178 - val_binary_accuracy: 0.7162\n",
            "Epoch 42/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5401 - auc_17: 0.7443 - binary_accuracy: 0.7196 - val_loss: 0.5563 - val_auc_17: 0.7195 - val_binary_accuracy: 0.7432\n",
            "Epoch 43/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5255 - auc_17: 0.7656 - binary_accuracy: 0.7297 - val_loss: 0.5545 - val_auc_17: 0.7234 - val_binary_accuracy: 0.7297\n",
            "Epoch 44/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5314 - auc_17: 0.7561 - binary_accuracy: 0.7095 - val_loss: 0.5596 - val_auc_17: 0.7246 - val_binary_accuracy: 0.7162\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5242 - auc_17: 0.7655 - binary_accuracy: 0.7162 - val_loss: 0.5449 - val_auc_17: 0.7387 - val_binary_accuracy: 0.7162\n",
            "Epoch 46/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5384 - auc_17: 0.7483 - binary_accuracy: 0.7365 - val_loss: 0.5333 - val_auc_17: 0.7528 - val_binary_accuracy: 0.7162\n",
            "Epoch 47/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5367 - auc_17: 0.7506 - binary_accuracy: 0.7432 - val_loss: 0.5510 - val_auc_17: 0.7276 - val_binary_accuracy: 0.7297\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5310 - auc_17: 0.7595 - binary_accuracy: 0.7399 - val_loss: 0.5359 - val_auc_17: 0.7523 - val_binary_accuracy: 0.7297\n",
            "Epoch 49/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5200 - auc_17: 0.7701 - binary_accuracy: 0.7230 - val_loss: 0.5317 - val_auc_17: 0.7583 - val_binary_accuracy: 0.7162\n",
            "Epoch 50/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5298 - auc_17: 0.7558 - binary_accuracy: 0.7027 - val_loss: 0.5403 - val_auc_17: 0.7451 - val_binary_accuracy: 0.7027\n",
            "Epoch 51/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5214 - auc_17: 0.7658 - binary_accuracy: 0.7466 - val_loss: 0.5512 - val_auc_17: 0.7396 - val_binary_accuracy: 0.7432\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5240 - auc_17: 0.7608 - binary_accuracy: 0.7162 - val_loss: 0.5287 - val_auc_17: 0.7647 - val_binary_accuracy: 0.7162\n",
            "Epoch 53/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5087 - auc_17: 0.7910 - binary_accuracy: 0.7399 - val_loss: 0.5250 - val_auc_17: 0.7702 - val_binary_accuracy: 0.7297\n",
            "Epoch 54/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5126 - auc_17: 0.7750 - binary_accuracy: 0.7264 - val_loss: 0.5345 - val_auc_17: 0.7515 - val_binary_accuracy: 0.7162\n",
            "Epoch 55/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5029 - auc_17: 0.7874 - binary_accuracy: 0.7331 - val_loss: 0.5193 - val_auc_17: 0.7766 - val_binary_accuracy: 0.7162\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4988 - auc_17: 0.8006 - binary_accuracy: 0.7432 - val_loss: 0.5193 - val_auc_17: 0.7754 - val_binary_accuracy: 0.7162\n",
            "Epoch 57/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5010 - auc_17: 0.7838 - binary_accuracy: 0.7399 - val_loss: 0.5309 - val_auc_17: 0.7583 - val_binary_accuracy: 0.7162\n",
            "Epoch 58/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5163 - auc_17: 0.7671 - binary_accuracy: 0.7399 - val_loss: 0.5175 - val_auc_17: 0.7809 - val_binary_accuracy: 0.7162\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5039 - auc_17: 0.7855 - binary_accuracy: 0.7500 - val_loss: 0.5162 - val_auc_17: 0.7839 - val_binary_accuracy: 0.6892\n",
            "Epoch 60/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4938 - auc_17: 0.8021 - binary_accuracy: 0.7264 - val_loss: 0.5149 - val_auc_17: 0.7852 - val_binary_accuracy: 0.7162\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4877 - auc_17: 0.8034 - binary_accuracy: 0.7500 - val_loss: 0.5240 - val_auc_17: 0.7779 - val_binary_accuracy: 0.7162\n",
            "Epoch 62/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4804 - auc_17: 0.8086 - binary_accuracy: 0.7466 - val_loss: 0.5150 - val_auc_17: 0.7958 - val_binary_accuracy: 0.7162\n",
            "Epoch 63/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4818 - auc_17: 0.7984 - binary_accuracy: 0.7162 - val_loss: 0.5137 - val_auc_17: 0.7928 - val_binary_accuracy: 0.7297\n",
            "Epoch 64/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4727 - auc_17: 0.8161 - binary_accuracy: 0.7500 - val_loss: 0.5083 - val_auc_17: 0.8001 - val_binary_accuracy: 0.7162\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4814 - auc_17: 0.8115 - binary_accuracy: 0.7500 - val_loss: 0.4989 - val_auc_17: 0.8048 - val_binary_accuracy: 0.7162\n",
            "Epoch 66/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4861 - auc_17: 0.8032 - binary_accuracy: 0.7534 - val_loss: 0.5017 - val_auc_17: 0.7971 - val_binary_accuracy: 0.7162\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4828 - auc_17: 0.8040 - binary_accuracy: 0.7331 - val_loss: 0.5144 - val_auc_17: 0.7873 - val_binary_accuracy: 0.7162\n",
            "Epoch 68/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4844 - auc_17: 0.8005 - binary_accuracy: 0.7264 - val_loss: 0.4992 - val_auc_17: 0.8103 - val_binary_accuracy: 0.7297\n",
            "Epoch 69/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4897 - auc_17: 0.7949 - binary_accuracy: 0.7297 - val_loss: 0.5005 - val_auc_17: 0.8022 - val_binary_accuracy: 0.7297\n",
            "Epoch 70/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4742 - auc_17: 0.8161 - binary_accuracy: 0.7432 - val_loss: 0.5088 - val_auc_17: 0.8005 - val_binary_accuracy: 0.7162\n",
            "Epoch 71/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4720 - auc_17: 0.8120 - binary_accuracy: 0.7331 - val_loss: 0.5143 - val_auc_17: 0.7971 - val_binary_accuracy: 0.7162\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4643 - auc_17: 0.8219 - binary_accuracy: 0.7399 - val_loss: 0.5192 - val_auc_17: 0.7962 - val_binary_accuracy: 0.7162\n",
            "Epoch 73/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4687 - auc_17: 0.8248 - binary_accuracy: 0.7669 - val_loss: 0.5133 - val_auc_17: 0.8069 - val_binary_accuracy: 0.7297\n",
            "Epoch 74/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4698 - auc_17: 0.8116 - binary_accuracy: 0.7399 - val_loss: 0.5156 - val_auc_17: 0.8005 - val_binary_accuracy: 0.7297\n",
            "Epoch 75/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4687 - auc_17: 0.8154 - binary_accuracy: 0.7365 - val_loss: 0.5200 - val_auc_17: 0.7958 - val_binary_accuracy: 0.7162\n",
            "Epoch 76/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4562 - auc_17: 0.8281 - binary_accuracy: 0.7432 - val_loss: 0.5148 - val_auc_17: 0.7997 - val_binary_accuracy: 0.7027\n",
            "Epoch 77/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4589 - auc_17: 0.8259 - binary_accuracy: 0.7500 - val_loss: 0.5224 - val_auc_17: 0.7997 - val_binary_accuracy: 0.7162\n",
            "Epoch 78/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4761 - auc_17: 0.8093 - binary_accuracy: 0.7297 - val_loss: 0.5049 - val_auc_17: 0.8103 - val_binary_accuracy: 0.7568\n",
            "Epoch 79/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4630 - auc_17: 0.8176 - binary_accuracy: 0.7500 - val_loss: 0.5047 - val_auc_17: 0.8176 - val_binary_accuracy: 0.7568\n",
            "Epoch 80/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4436 - auc_17: 0.8490 - binary_accuracy: 0.7568 - val_loss: 0.4954 - val_auc_17: 0.8176 - val_binary_accuracy: 0.7432\n",
            "Epoch 81/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4525 - auc_17: 0.8321 - binary_accuracy: 0.7365 - val_loss: 0.5107 - val_auc_17: 0.8129 - val_binary_accuracy: 0.7162\n",
            "Epoch 82/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4386 - auc_17: 0.8414 - binary_accuracy: 0.7635 - val_loss: 0.5062 - val_auc_17: 0.8124 - val_binary_accuracy: 0.7297\n",
            "Epoch 83/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4510 - auc_17: 0.8341 - binary_accuracy: 0.7568 - val_loss: 0.4976 - val_auc_17: 0.8201 - val_binary_accuracy: 0.7297\n",
            "Epoch 84/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4589 - auc_17: 0.8228 - binary_accuracy: 0.7500 - val_loss: 0.4900 - val_auc_17: 0.8205 - val_binary_accuracy: 0.7703\n",
            "Epoch 85/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4624 - auc_17: 0.8259 - binary_accuracy: 0.7568 - val_loss: 0.5168 - val_auc_17: 0.7997 - val_binary_accuracy: 0.7297\n",
            "Epoch 86/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4691 - auc_17: 0.8183 - binary_accuracy: 0.7297 - val_loss: 0.4889 - val_auc_17: 0.8159 - val_binary_accuracy: 0.7297\n",
            "Epoch 87/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4602 - auc_17: 0.8252 - binary_accuracy: 0.7770 - val_loss: 0.4782 - val_auc_17: 0.8282 - val_binary_accuracy: 0.7973\n",
            "Epoch 88/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4464 - auc_17: 0.8430 - binary_accuracy: 0.7804 - val_loss: 0.4939 - val_auc_17: 0.8188 - val_binary_accuracy: 0.7297\n",
            "Epoch 89/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4549 - auc_17: 0.8273 - binary_accuracy: 0.7601 - val_loss: 0.4922 - val_auc_17: 0.8154 - val_binary_accuracy: 0.7297\n",
            "Epoch 90/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4599 - auc_17: 0.8247 - binary_accuracy: 0.7466 - val_loss: 0.4869 - val_auc_17: 0.8197 - val_binary_accuracy: 0.7703\n",
            "Epoch 91/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4335 - auc_17: 0.8504 - binary_accuracy: 0.7568 - val_loss: 0.4885 - val_auc_17: 0.8154 - val_binary_accuracy: 0.7432\n",
            "Epoch 92/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4447 - auc_17: 0.8398 - binary_accuracy: 0.7703 - val_loss: 0.4880 - val_auc_17: 0.8124 - val_binary_accuracy: 0.7432\n",
            "Epoch 93/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4358 - auc_17: 0.8476 - binary_accuracy: 0.7601 - val_loss: 0.4851 - val_auc_17: 0.8176 - val_binary_accuracy: 0.7838\n",
            "Epoch 94/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4276 - auc_17: 0.8585 - binary_accuracy: 0.7770 - val_loss: 0.4830 - val_auc_17: 0.8201 - val_binary_accuracy: 0.7838\n",
            "Epoch 95/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4394 - auc_17: 0.8390 - binary_accuracy: 0.7635 - val_loss: 0.5090 - val_auc_17: 0.8009 - val_binary_accuracy: 0.7432\n",
            "Epoch 96/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4469 - auc_17: 0.8298 - binary_accuracy: 0.7601 - val_loss: 0.5040 - val_auc_17: 0.8086 - val_binary_accuracy: 0.7297\n",
            "Epoch 97/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4529 - auc_17: 0.8311 - binary_accuracy: 0.7838 - val_loss: 0.5045 - val_auc_17: 0.8090 - val_binary_accuracy: 0.7432\n",
            "Epoch 98/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4316 - auc_17: 0.8516 - binary_accuracy: 0.7703 - val_loss: 0.4939 - val_auc_17: 0.8193 - val_binary_accuracy: 0.7703\n",
            "Epoch 99/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4379 - auc_17: 0.8441 - binary_accuracy: 0.7466 - val_loss: 0.4969 - val_auc_17: 0.8197 - val_binary_accuracy: 0.7838\n",
            "Epoch 100/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4432 - auc_17: 0.8430 - binary_accuracy: 0.7635 - val_loss: 0.4955 - val_auc_17: 0.8180 - val_binary_accuracy: 0.7703\n",
            "Epoch 101/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4260 - auc_17: 0.8576 - binary_accuracy: 0.7770 - val_loss: 0.5052 - val_auc_17: 0.8137 - val_binary_accuracy: 0.7568\n",
            "Epoch 102/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4303 - auc_17: 0.8511 - binary_accuracy: 0.7872 - val_loss: 0.5154 - val_auc_17: 0.8022 - val_binary_accuracy: 0.7568\n",
            "Epoch 103/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4146 - auc_17: 0.8633 - binary_accuracy: 0.7703 - val_loss: 0.4989 - val_auc_17: 0.8201 - val_binary_accuracy: 0.7703\n",
            "Epoch 104/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4224 - auc_17: 0.8559 - binary_accuracy: 0.7770 - val_loss: 0.4987 - val_auc_17: 0.8137 - val_binary_accuracy: 0.7568\n",
            "Epoch 105/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4391 - auc_17: 0.8466 - binary_accuracy: 0.7736 - val_loss: 0.4992 - val_auc_17: 0.8167 - val_binary_accuracy: 0.7568\n",
            "Epoch 106/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4245 - auc_17: 0.8548 - binary_accuracy: 0.7736 - val_loss: 0.5017 - val_auc_17: 0.8184 - val_binary_accuracy: 0.7568\n",
            "Epoch 107/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4314 - auc_17: 0.8463 - binary_accuracy: 0.7466 - val_loss: 0.4953 - val_auc_17: 0.8223 - val_binary_accuracy: 0.7568\n",
            "Epoch 108/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4529 - auc_17: 0.8375 - binary_accuracy: 0.7703 - val_loss: 0.4986 - val_auc_17: 0.8176 - val_binary_accuracy: 0.7703\n",
            "Epoch 109/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3986 - auc_17: 0.8810 - binary_accuracy: 0.8074 - val_loss: 0.5101 - val_auc_17: 0.8086 - val_binary_accuracy: 0.7568\n",
            "Epoch 110/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4174 - auc_17: 0.8643 - binary_accuracy: 0.7804 - val_loss: 0.4957 - val_auc_17: 0.8201 - val_binary_accuracy: 0.7703\n",
            "Epoch 111/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4120 - auc_17: 0.8649 - binary_accuracy: 0.7703 - val_loss: 0.4888 - val_auc_17: 0.8269 - val_binary_accuracy: 0.7838\n",
            "Epoch 112/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4076 - auc_17: 0.8736 - binary_accuracy: 0.7635 - val_loss: 0.5054 - val_auc_17: 0.8065 - val_binary_accuracy: 0.7568\n",
            "Epoch 113/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4237 - auc_17: 0.8576 - binary_accuracy: 0.7635 - val_loss: 0.5059 - val_auc_17: 0.8069 - val_binary_accuracy: 0.7568\n",
            "Epoch 114/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4108 - auc_17: 0.8679 - binary_accuracy: 0.7838 - val_loss: 0.5071 - val_auc_17: 0.8073 - val_binary_accuracy: 0.7703\n",
            "Epoch 115/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4111 - auc_17: 0.8645 - binary_accuracy: 0.7568 - val_loss: 0.5174 - val_auc_17: 0.8039 - val_binary_accuracy: 0.7297\n",
            "Epoch 116/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4099 - auc_17: 0.8623 - binary_accuracy: 0.7703 - val_loss: 0.5151 - val_auc_17: 0.8082 - val_binary_accuracy: 0.7297\n",
            "Epoch 117/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4150 - auc_17: 0.8708 - binary_accuracy: 0.7973 - val_loss: 0.5020 - val_auc_17: 0.8171 - val_binary_accuracy: 0.7838\n",
            "Epoch 118/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4090 - auc_17: 0.8699 - binary_accuracy: 0.7669 - val_loss: 0.4999 - val_auc_17: 0.8184 - val_binary_accuracy: 0.7838\n",
            "Epoch 119/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4064 - auc_17: 0.8747 - binary_accuracy: 0.8007 - val_loss: 0.5104 - val_auc_17: 0.8099 - val_binary_accuracy: 0.7297\n",
            "Epoch 120/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4133 - auc_17: 0.8649 - binary_accuracy: 0.7905 - val_loss: 0.5094 - val_auc_17: 0.8137 - val_binary_accuracy: 0.7432\n",
            "Epoch 121/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3993 - auc_17: 0.8805 - binary_accuracy: 0.7939 - val_loss: 0.5056 - val_auc_17: 0.8065 - val_binary_accuracy: 0.7432\n",
            "Epoch 122/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4077 - auc_17: 0.8710 - binary_accuracy: 0.7838 - val_loss: 0.5064 - val_auc_17: 0.8065 - val_binary_accuracy: 0.7432\n",
            "Epoch 123/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4093 - auc_17: 0.8681 - binary_accuracy: 0.7804 - val_loss: 0.5131 - val_auc_17: 0.8035 - val_binary_accuracy: 0.7162\n",
            "Epoch 124/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4161 - auc_17: 0.8616 - binary_accuracy: 0.7872 - val_loss: 0.5071 - val_auc_17: 0.8120 - val_binary_accuracy: 0.7432\n",
            "Epoch 125/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3999 - auc_17: 0.8777 - binary_accuracy: 0.8041 - val_loss: 0.5132 - val_auc_17: 0.8180 - val_binary_accuracy: 0.7432\n",
            "Epoch 126/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4033 - auc_17: 0.8739 - binary_accuracy: 0.7905 - val_loss: 0.5163 - val_auc_17: 0.8069 - val_binary_accuracy: 0.7432\n",
            "Epoch 127/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4013 - auc_17: 0.8767 - binary_accuracy: 0.7939 - val_loss: 0.5286 - val_auc_17: 0.7937 - val_binary_accuracy: 0.7162\n",
            "Epoch 128/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4080 - auc_17: 0.8752 - binary_accuracy: 0.7905 - val_loss: 0.5307 - val_auc_17: 0.7933 - val_binary_accuracy: 0.7162\n",
            "Epoch 129/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4027 - auc_17: 0.8724 - binary_accuracy: 0.8041 - val_loss: 0.5188 - val_auc_17: 0.8005 - val_binary_accuracy: 0.7297\n",
            "Epoch 130/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3936 - auc_17: 0.8779 - binary_accuracy: 0.7770 - val_loss: 0.5163 - val_auc_17: 0.8112 - val_binary_accuracy: 0.7432\n",
            "Epoch 131/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4073 - auc_17: 0.8629 - binary_accuracy: 0.7669 - val_loss: 0.5163 - val_auc_17: 0.8090 - val_binary_accuracy: 0.7568\n",
            "Epoch 132/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4140 - auc_17: 0.8614 - binary_accuracy: 0.7804 - val_loss: 0.5155 - val_auc_17: 0.8112 - val_binary_accuracy: 0.7432\n",
            "Epoch 133/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3881 - auc_17: 0.8871 - binary_accuracy: 0.8007 - val_loss: 0.5126 - val_auc_17: 0.8103 - val_binary_accuracy: 0.7432\n",
            "Epoch 134/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4103 - auc_17: 0.8676 - binary_accuracy: 0.7872 - val_loss: 0.4984 - val_auc_17: 0.8205 - val_binary_accuracy: 0.7568\n",
            "Epoch 135/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4036 - auc_17: 0.8747 - binary_accuracy: 0.8041 - val_loss: 0.5181 - val_auc_17: 0.8056 - val_binary_accuracy: 0.7297\n",
            "Epoch 136/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4169 - auc_17: 0.8662 - binary_accuracy: 0.7973 - val_loss: 0.5104 - val_auc_17: 0.8052 - val_binary_accuracy: 0.7432\n",
            "Epoch 137/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3963 - auc_17: 0.8776 - binary_accuracy: 0.7703 - val_loss: 0.5165 - val_auc_17: 0.8018 - val_binary_accuracy: 0.7027\n",
            "Epoch 138/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3977 - auc_17: 0.8736 - binary_accuracy: 0.7939 - val_loss: 0.4986 - val_auc_17: 0.8205 - val_binary_accuracy: 0.7432\n",
            "Epoch 139/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3845 - auc_17: 0.8857 - binary_accuracy: 0.7973 - val_loss: 0.5046 - val_auc_17: 0.8201 - val_binary_accuracy: 0.7432\n",
            "Epoch 140/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3727 - auc_17: 0.8959 - binary_accuracy: 0.8074 - val_loss: 0.5158 - val_auc_17: 0.8129 - val_binary_accuracy: 0.7297\n",
            "Epoch 141/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3854 - auc_17: 0.8871 - binary_accuracy: 0.8176 - val_loss: 0.5271 - val_auc_17: 0.7997 - val_binary_accuracy: 0.7297\n",
            "Epoch 142/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3766 - auc_17: 0.9004 - binary_accuracy: 0.8345 - val_loss: 0.5248 - val_auc_17: 0.8048 - val_binary_accuracy: 0.7297\n",
            "Epoch 143/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3854 - auc_17: 0.8835 - binary_accuracy: 0.7939 - val_loss: 0.5134 - val_auc_17: 0.8035 - val_binary_accuracy: 0.7432\n",
            "Epoch 144/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3807 - auc_17: 0.8924 - binary_accuracy: 0.8041 - val_loss: 0.5108 - val_auc_17: 0.8184 - val_binary_accuracy: 0.7703\n",
            "Epoch 145/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3968 - auc_17: 0.8753 - binary_accuracy: 0.7905 - val_loss: 0.5149 - val_auc_17: 0.8218 - val_binary_accuracy: 0.7432\n",
            "Epoch 146/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3870 - auc_17: 0.8850 - binary_accuracy: 0.7838 - val_loss: 0.5041 - val_auc_17: 0.8205 - val_binary_accuracy: 0.7568\n",
            "Epoch 147/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3902 - auc_17: 0.8855 - binary_accuracy: 0.8074 - val_loss: 0.4992 - val_auc_17: 0.8286 - val_binary_accuracy: 0.7703\n",
            "Epoch 148/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3911 - auc_17: 0.8798 - binary_accuracy: 0.7973 - val_loss: 0.5109 - val_auc_17: 0.8214 - val_binary_accuracy: 0.7432\n",
            "Epoch 149/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3906 - auc_17: 0.8784 - binary_accuracy: 0.7838 - val_loss: 0.5092 - val_auc_17: 0.8099 - val_binary_accuracy: 0.7568\n",
            "Epoch 150/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3810 - auc_17: 0.8870 - binary_accuracy: 0.8142 - val_loss: 0.5121 - val_auc_17: 0.8095 - val_binary_accuracy: 0.7297\n",
            "Epoch 151/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3798 - auc_17: 0.8912 - binary_accuracy: 0.8311 - val_loss: 0.5249 - val_auc_17: 0.8133 - val_binary_accuracy: 0.7162\n",
            "Epoch 152/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3913 - auc_17: 0.8858 - binary_accuracy: 0.7804 - val_loss: 0.5515 - val_auc_17: 0.7911 - val_binary_accuracy: 0.7162\n",
            "Epoch 153/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3936 - auc_17: 0.8787 - binary_accuracy: 0.8074 - val_loss: 0.5357 - val_auc_17: 0.7907 - val_binary_accuracy: 0.7162\n",
            "Epoch 154/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3660 - auc_17: 0.9034 - binary_accuracy: 0.8277 - val_loss: 0.5326 - val_auc_17: 0.8052 - val_binary_accuracy: 0.7162\n",
            "Epoch 155/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3825 - auc_17: 0.8958 - binary_accuracy: 0.8176 - val_loss: 0.5236 - val_auc_17: 0.8167 - val_binary_accuracy: 0.7568\n",
            "Epoch 156/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3625 - auc_17: 0.9027 - binary_accuracy: 0.8243 - val_loss: 0.5136 - val_auc_17: 0.8112 - val_binary_accuracy: 0.7838\n",
            "Epoch 157/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3826 - auc_17: 0.8930 - binary_accuracy: 0.8277 - val_loss: 0.5287 - val_auc_17: 0.8107 - val_binary_accuracy: 0.7297\n",
            "Epoch 158/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3817 - auc_17: 0.8995 - binary_accuracy: 0.8209 - val_loss: 0.5352 - val_auc_17: 0.7980 - val_binary_accuracy: 0.7432\n",
            "Epoch 159/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3895 - auc_17: 0.8857 - binary_accuracy: 0.8007 - val_loss: 0.5293 - val_auc_17: 0.8069 - val_binary_accuracy: 0.7432\n",
            "Epoch 160/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3840 - auc_17: 0.8876 - binary_accuracy: 0.7905 - val_loss: 0.5355 - val_auc_17: 0.8142 - val_binary_accuracy: 0.7162\n",
            "Epoch 161/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3709 - auc_17: 0.8964 - binary_accuracy: 0.8142 - val_loss: 0.5331 - val_auc_17: 0.8014 - val_binary_accuracy: 0.7162\n",
            "Epoch 162/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3628 - auc_17: 0.8994 - binary_accuracy: 0.8108 - val_loss: 0.5294 - val_auc_17: 0.8086 - val_binary_accuracy: 0.7297\n",
            "Epoch 163/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3634 - auc_17: 0.9026 - binary_accuracy: 0.8142 - val_loss: 0.5340 - val_auc_17: 0.8112 - val_binary_accuracy: 0.7162\n",
            "Epoch 164/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3626 - auc_17: 0.8997 - binary_accuracy: 0.8243 - val_loss: 0.5279 - val_auc_17: 0.8052 - val_binary_accuracy: 0.7162\n",
            "Epoch 165/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3849 - auc_17: 0.8857 - binary_accuracy: 0.8176 - val_loss: 0.5309 - val_auc_17: 0.7988 - val_binary_accuracy: 0.7432\n",
            "Epoch 166/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3731 - auc_17: 0.8989 - binary_accuracy: 0.8142 - val_loss: 0.5307 - val_auc_17: 0.8039 - val_binary_accuracy: 0.7162\n",
            "Epoch 167/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3716 - auc_17: 0.8934 - binary_accuracy: 0.7905 - val_loss: 0.5254 - val_auc_17: 0.8043 - val_binary_accuracy: 0.7162\n",
            "Epoch 168/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3818 - auc_17: 0.8825 - binary_accuracy: 0.7838 - val_loss: 0.5259 - val_auc_17: 0.8048 - val_binary_accuracy: 0.7162\n",
            "Epoch 169/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3389 - auc_17: 0.9204 - binary_accuracy: 0.8378 - val_loss: 0.5117 - val_auc_17: 0.8086 - val_binary_accuracy: 0.7568\n",
            "Epoch 170/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3696 - auc_17: 0.8931 - binary_accuracy: 0.8176 - val_loss: 0.5399 - val_auc_17: 0.7971 - val_binary_accuracy: 0.7297\n",
            "Epoch 171/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3722 - auc_17: 0.8951 - binary_accuracy: 0.8007 - val_loss: 0.5159 - val_auc_17: 0.8124 - val_binary_accuracy: 0.7297\n",
            "Epoch 172/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3426 - auc_17: 0.9164 - binary_accuracy: 0.8378 - val_loss: 0.5032 - val_auc_17: 0.8180 - val_binary_accuracy: 0.7838\n",
            "Epoch 173/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3869 - auc_17: 0.8794 - binary_accuracy: 0.8074 - val_loss: 0.5138 - val_auc_17: 0.8210 - val_binary_accuracy: 0.7432\n",
            "Epoch 174/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3662 - auc_17: 0.9015 - binary_accuracy: 0.8007 - val_loss: 0.5146 - val_auc_17: 0.8223 - val_binary_accuracy: 0.7297\n",
            "Epoch 175/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3498 - auc_17: 0.9139 - binary_accuracy: 0.8311 - val_loss: 0.5087 - val_auc_17: 0.8137 - val_binary_accuracy: 0.7432\n",
            "Epoch 176/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3525 - auc_17: 0.9073 - binary_accuracy: 0.8277 - val_loss: 0.5259 - val_auc_17: 0.8129 - val_binary_accuracy: 0.7162\n",
            "Epoch 177/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3435 - auc_17: 0.9144 - binary_accuracy: 0.8378 - val_loss: 0.5216 - val_auc_17: 0.8142 - val_binary_accuracy: 0.7297\n",
            "Epoch 178/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3710 - auc_17: 0.8914 - binary_accuracy: 0.8007 - val_loss: 0.5217 - val_auc_17: 0.8082 - val_binary_accuracy: 0.7297\n",
            "Epoch 179/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3844 - auc_17: 0.8931 - binary_accuracy: 0.8243 - val_loss: 0.5359 - val_auc_17: 0.8005 - val_binary_accuracy: 0.7162\n",
            "Epoch 180/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3734 - auc_17: 0.9003 - binary_accuracy: 0.8311 - val_loss: 0.5271 - val_auc_17: 0.8031 - val_binary_accuracy: 0.7703\n",
            "Epoch 181/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3590 - auc_17: 0.9026 - binary_accuracy: 0.8074 - val_loss: 0.5481 - val_auc_17: 0.8052 - val_binary_accuracy: 0.7027\n",
            "Epoch 182/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3488 - auc_17: 0.9092 - binary_accuracy: 0.8277 - val_loss: 0.5541 - val_auc_17: 0.8014 - val_binary_accuracy: 0.7027\n",
            "Epoch 183/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3559 - auc_17: 0.9103 - binary_accuracy: 0.8480 - val_loss: 0.5157 - val_auc_17: 0.8039 - val_binary_accuracy: 0.7703\n",
            "Epoch 184/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3330 - auc_17: 0.9197 - binary_accuracy: 0.8311 - val_loss: 0.5223 - val_auc_17: 0.7937 - val_binary_accuracy: 0.7432\n",
            "Epoch 185/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3707 - auc_17: 0.8992 - binary_accuracy: 0.8176 - val_loss: 0.5662 - val_auc_17: 0.7894 - val_binary_accuracy: 0.7297\n",
            "Epoch 186/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3928 - auc_17: 0.8902 - binary_accuracy: 0.8074 - val_loss: 0.5656 - val_auc_17: 0.7732 - val_binary_accuracy: 0.6892\n",
            "Epoch 187/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3660 - auc_17: 0.8993 - binary_accuracy: 0.8176 - val_loss: 0.5419 - val_auc_17: 0.8005 - val_binary_accuracy: 0.7838\n",
            "Epoch 188/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3602 - auc_17: 0.9014 - binary_accuracy: 0.8007 - val_loss: 0.5557 - val_auc_17: 0.7980 - val_binary_accuracy: 0.7162\n",
            "Epoch 189/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3306 - auc_17: 0.9247 - binary_accuracy: 0.8378 - val_loss: 0.5412 - val_auc_17: 0.7886 - val_binary_accuracy: 0.7027\n",
            "Epoch 190/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3540 - auc_17: 0.9071 - binary_accuracy: 0.8480 - val_loss: 0.5261 - val_auc_17: 0.7945 - val_binary_accuracy: 0.7432\n",
            "Epoch 191/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3385 - auc_17: 0.9200 - binary_accuracy: 0.8480 - val_loss: 0.5556 - val_auc_17: 0.7864 - val_binary_accuracy: 0.6892\n",
            "Epoch 192/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3175 - auc_17: 0.9361 - binary_accuracy: 0.8750 - val_loss: 0.5385 - val_auc_17: 0.7962 - val_binary_accuracy: 0.7297\n",
            "Epoch 193/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3742 - auc_17: 0.8922 - binary_accuracy: 0.8311 - val_loss: 0.5523 - val_auc_17: 0.7958 - val_binary_accuracy: 0.7162\n",
            "Epoch 194/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3380 - auc_17: 0.9193 - binary_accuracy: 0.8514 - val_loss: 0.5456 - val_auc_17: 0.8014 - val_binary_accuracy: 0.7568\n",
            "Epoch 195/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3435 - auc_17: 0.9133 - binary_accuracy: 0.8311 - val_loss: 0.5632 - val_auc_17: 0.7984 - val_binary_accuracy: 0.7432\n",
            "Epoch 196/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3562 - auc_17: 0.9062 - binary_accuracy: 0.8041 - val_loss: 0.5820 - val_auc_17: 0.7745 - val_binary_accuracy: 0.7162\n",
            "Epoch 197/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3418 - auc_17: 0.9129 - binary_accuracy: 0.8378 - val_loss: 0.5784 - val_auc_17: 0.7916 - val_binary_accuracy: 0.7162\n",
            "Epoch 198/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3298 - auc_17: 0.9214 - binary_accuracy: 0.8446 - val_loss: 0.5672 - val_auc_17: 0.7980 - val_binary_accuracy: 0.7297\n",
            "Epoch 199/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3351 - auc_17: 0.9170 - binary_accuracy: 0.8209 - val_loss: 0.5584 - val_auc_17: 0.7907 - val_binary_accuracy: 0.7162\n",
            "Epoch 200/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3542 - auc_17: 0.9021 - binary_accuracy: 0.8108 - val_loss: 0.5665 - val_auc_17: 0.7920 - val_binary_accuracy: 0.7027\n",
            "Epoch 201/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3466 - auc_17: 0.9096 - binary_accuracy: 0.8074 - val_loss: 0.5923 - val_auc_17: 0.7864 - val_binary_accuracy: 0.6892\n",
            "Epoch 202/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3440 - auc_17: 0.9181 - binary_accuracy: 0.8345 - val_loss: 0.5629 - val_auc_17: 0.8009 - val_binary_accuracy: 0.7568\n",
            "Epoch 203/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3428 - auc_17: 0.9112 - binary_accuracy: 0.8311 - val_loss: 0.5516 - val_auc_17: 0.8078 - val_binary_accuracy: 0.7162\n",
            "Epoch 204/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3332 - auc_17: 0.9152 - binary_accuracy: 0.8243 - val_loss: 0.5535 - val_auc_17: 0.8009 - val_binary_accuracy: 0.7027\n",
            "Epoch 205/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3481 - auc_17: 0.9119 - binary_accuracy: 0.8142 - val_loss: 0.5692 - val_auc_17: 0.7843 - val_binary_accuracy: 0.7162\n",
            "Epoch 206/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3254 - auc_17: 0.9254 - binary_accuracy: 0.8446 - val_loss: 0.5642 - val_auc_17: 0.7958 - val_binary_accuracy: 0.7297\n",
            "Epoch 207/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3442 - auc_17: 0.9113 - binary_accuracy: 0.8209 - val_loss: 0.5675 - val_auc_17: 0.7945 - val_binary_accuracy: 0.7162\n",
            "Epoch 208/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3503 - auc_17: 0.9069 - binary_accuracy: 0.8209 - val_loss: 0.5948 - val_auc_17: 0.7707 - val_binary_accuracy: 0.7027\n",
            "Epoch 209/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3276 - auc_17: 0.9245 - binary_accuracy: 0.8480 - val_loss: 0.5435 - val_auc_17: 0.7971 - val_binary_accuracy: 0.7432\n",
            "Epoch 210/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3572 - auc_17: 0.9132 - binary_accuracy: 0.8446 - val_loss: 0.5368 - val_auc_17: 0.8018 - val_binary_accuracy: 0.7838\n",
            "Epoch 211/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3328 - auc_17: 0.9251 - binary_accuracy: 0.8615 - val_loss: 0.5864 - val_auc_17: 0.7813 - val_binary_accuracy: 0.7027\n",
            "Epoch 212/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3618 - auc_17: 0.9084 - binary_accuracy: 0.8176 - val_loss: 0.5658 - val_auc_17: 0.7950 - val_binary_accuracy: 0.7297\n",
            "Epoch 213/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3216 - auc_17: 0.9244 - binary_accuracy: 0.8446 - val_loss: 0.5332 - val_auc_17: 0.8009 - val_binary_accuracy: 0.7297\n",
            "Epoch 214/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3410 - auc_17: 0.9202 - binary_accuracy: 0.8345 - val_loss: 0.5283 - val_auc_17: 0.8026 - val_binary_accuracy: 0.7432\n",
            "Epoch 215/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3201 - auc_17: 0.9286 - binary_accuracy: 0.8547 - val_loss: 0.5254 - val_auc_17: 0.8176 - val_binary_accuracy: 0.7432\n",
            "Epoch 216/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3349 - auc_17: 0.9220 - binary_accuracy: 0.8446 - val_loss: 0.5560 - val_auc_17: 0.8009 - val_binary_accuracy: 0.7432\n",
            "Epoch 217/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3321 - auc_17: 0.9243 - binary_accuracy: 0.8581 - val_loss: 0.5465 - val_auc_17: 0.8082 - val_binary_accuracy: 0.7432\n",
            "Epoch 218/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3239 - auc_17: 0.9247 - binary_accuracy: 0.8514 - val_loss: 0.5343 - val_auc_17: 0.7937 - val_binary_accuracy: 0.7297\n",
            "Epoch 219/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3460 - auc_17: 0.9116 - binary_accuracy: 0.8345 - val_loss: 0.5662 - val_auc_17: 0.7775 - val_binary_accuracy: 0.7162\n",
            "Epoch 220/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3420 - auc_17: 0.9187 - binary_accuracy: 0.8581 - val_loss: 0.5412 - val_auc_17: 0.8009 - val_binary_accuracy: 0.7432\n",
            "Epoch 221/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3195 - auc_17: 0.9294 - binary_accuracy: 0.8446 - val_loss: 0.5513 - val_auc_17: 0.7971 - val_binary_accuracy: 0.7027\n",
            "Epoch 222/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3244 - auc_17: 0.9277 - binary_accuracy: 0.8378 - val_loss: 0.5654 - val_auc_17: 0.7907 - val_binary_accuracy: 0.6892\n",
            "Epoch 223/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3206 - auc_17: 0.9282 - binary_accuracy: 0.8514 - val_loss: 0.5647 - val_auc_17: 0.7869 - val_binary_accuracy: 0.7027\n",
            "Epoch 224/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3245 - auc_17: 0.9215 - binary_accuracy: 0.8547 - val_loss: 0.5702 - val_auc_17: 0.7903 - val_binary_accuracy: 0.7297\n",
            "Epoch 225/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3225 - auc_17: 0.9246 - binary_accuracy: 0.8514 - val_loss: 0.5873 - val_auc_17: 0.8035 - val_binary_accuracy: 0.7568\n",
            "Epoch 226/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3288 - auc_17: 0.9210 - binary_accuracy: 0.8176 - val_loss: 0.5521 - val_auc_17: 0.7984 - val_binary_accuracy: 0.7297\n",
            "Epoch 227/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3120 - auc_17: 0.9307 - binary_accuracy: 0.8345 - val_loss: 0.5699 - val_auc_17: 0.7813 - val_binary_accuracy: 0.7027\n",
            "Epoch 228/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3371 - auc_17: 0.9237 - binary_accuracy: 0.8480 - val_loss: 0.5651 - val_auc_17: 0.7813 - val_binary_accuracy: 0.7027\n",
            "Epoch 229/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3525 - auc_17: 0.9055 - binary_accuracy: 0.8108 - val_loss: 0.5381 - val_auc_17: 0.8099 - val_binary_accuracy: 0.7432\n",
            "Epoch 230/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3130 - auc_17: 0.9321 - binary_accuracy: 0.8345 - val_loss: 0.5540 - val_auc_17: 0.8082 - val_binary_accuracy: 0.7568\n",
            "Epoch 231/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3135 - auc_17: 0.9267 - binary_accuracy: 0.8412 - val_loss: 0.5528 - val_auc_17: 0.8137 - val_binary_accuracy: 0.7568\n",
            "Epoch 232/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3199 - auc_17: 0.9241 - binary_accuracy: 0.8514 - val_loss: 0.5462 - val_auc_17: 0.8073 - val_binary_accuracy: 0.7297\n",
            "Epoch 233/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3236 - auc_17: 0.9207 - binary_accuracy: 0.8581 - val_loss: 0.5631 - val_auc_17: 0.7980 - val_binary_accuracy: 0.7027\n",
            "Epoch 234/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3127 - auc_17: 0.9259 - binary_accuracy: 0.8615 - val_loss: 0.5907 - val_auc_17: 0.7856 - val_binary_accuracy: 0.7162\n",
            "Epoch 235/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3245 - auc_17: 0.9295 - binary_accuracy: 0.8480 - val_loss: 0.5500 - val_auc_17: 0.7975 - val_binary_accuracy: 0.7432\n",
            "Epoch 236/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3080 - auc_17: 0.9369 - binary_accuracy: 0.8547 - val_loss: 0.5771 - val_auc_17: 0.7903 - val_binary_accuracy: 0.7297\n",
            "Epoch 237/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3370 - auc_17: 0.9142 - binary_accuracy: 0.8311 - val_loss: 0.5705 - val_auc_17: 0.7847 - val_binary_accuracy: 0.7162\n",
            "Epoch 238/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2951 - auc_17: 0.9430 - binary_accuracy: 0.8885 - val_loss: 0.5559 - val_auc_17: 0.7992 - val_binary_accuracy: 0.7162\n",
            "Epoch 239/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3554 - auc_17: 0.9129 - binary_accuracy: 0.8412 - val_loss: 0.5647 - val_auc_17: 0.7882 - val_binary_accuracy: 0.7027\n",
            "Epoch 240/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3372 - auc_17: 0.9196 - binary_accuracy: 0.8378 - val_loss: 0.5670 - val_auc_17: 0.7720 - val_binary_accuracy: 0.7027\n",
            "Epoch 241/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2940 - auc_17: 0.9432 - binary_accuracy: 0.8615 - val_loss: 0.5493 - val_auc_17: 0.7962 - val_binary_accuracy: 0.7162\n",
            "Epoch 242/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3159 - auc_17: 0.9310 - binary_accuracy: 0.8750 - val_loss: 0.5595 - val_auc_17: 0.7886 - val_binary_accuracy: 0.7432\n",
            "Epoch 243/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3042 - auc_17: 0.9327 - binary_accuracy: 0.8547 - val_loss: 0.5746 - val_auc_17: 0.7835 - val_binary_accuracy: 0.7027\n",
            "Epoch 244/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3003 - auc_17: 0.9396 - binary_accuracy: 0.8750 - val_loss: 0.5641 - val_auc_17: 0.7954 - val_binary_accuracy: 0.7432\n",
            "Epoch 245/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3014 - auc_17: 0.9360 - binary_accuracy: 0.8615 - val_loss: 0.5579 - val_auc_17: 0.8018 - val_binary_accuracy: 0.7432\n",
            "Epoch 246/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3104 - auc_17: 0.9274 - binary_accuracy: 0.8649 - val_loss: 0.5772 - val_auc_17: 0.7992 - val_binary_accuracy: 0.7027\n",
            "Epoch 247/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3154 - auc_17: 0.9299 - binary_accuracy: 0.8649 - val_loss: 0.5536 - val_auc_17: 0.7980 - val_binary_accuracy: 0.7432\n",
            "Epoch 248/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3063 - auc_17: 0.9318 - binary_accuracy: 0.8581 - val_loss: 0.5764 - val_auc_17: 0.7945 - val_binary_accuracy: 0.7297\n",
            "Epoch 249/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3100 - auc_17: 0.9344 - binary_accuracy: 0.8615 - val_loss: 0.5814 - val_auc_17: 0.7933 - val_binary_accuracy: 0.7297\n",
            "Epoch 250/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3364 - auc_17: 0.9203 - binary_accuracy: 0.8514 - val_loss: 0.5834 - val_auc_17: 0.7950 - val_binary_accuracy: 0.7297\n",
            "Epoch 251/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2973 - auc_17: 0.9410 - binary_accuracy: 0.8682 - val_loss: 0.5872 - val_auc_17: 0.7945 - val_binary_accuracy: 0.7162\n",
            "Epoch 252/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2925 - auc_17: 0.9417 - binary_accuracy: 0.8750 - val_loss: 0.5704 - val_auc_17: 0.7864 - val_binary_accuracy: 0.7432\n",
            "Epoch 253/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3060 - auc_17: 0.9344 - binary_accuracy: 0.8615 - val_loss: 0.5932 - val_auc_17: 0.7754 - val_binary_accuracy: 0.7432\n",
            "Epoch 254/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3142 - auc_17: 0.9285 - binary_accuracy: 0.8581 - val_loss: 0.6026 - val_auc_17: 0.7822 - val_binary_accuracy: 0.7027\n",
            "Epoch 255/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2991 - auc_17: 0.9369 - binary_accuracy: 0.8615 - val_loss: 0.5856 - val_auc_17: 0.8107 - val_binary_accuracy: 0.7703\n",
            "Epoch 256/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3422 - auc_17: 0.9141 - binary_accuracy: 0.8412 - val_loss: 0.6029 - val_auc_17: 0.7805 - val_binary_accuracy: 0.6892\n",
            "Epoch 257/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3059 - auc_17: 0.9372 - binary_accuracy: 0.8581 - val_loss: 0.6078 - val_auc_17: 0.7749 - val_binary_accuracy: 0.6757\n",
            "Epoch 258/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2851 - auc_17: 0.9479 - binary_accuracy: 0.8716 - val_loss: 0.5737 - val_auc_17: 0.7916 - val_binary_accuracy: 0.7297\n",
            "Epoch 259/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2991 - auc_17: 0.9373 - binary_accuracy: 0.8615 - val_loss: 0.5856 - val_auc_17: 0.7928 - val_binary_accuracy: 0.7162\n",
            "Epoch 260/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3096 - auc_17: 0.9325 - binary_accuracy: 0.8649 - val_loss: 0.5901 - val_auc_17: 0.7805 - val_binary_accuracy: 0.6892\n",
            "Epoch 261/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2983 - auc_17: 0.9369 - binary_accuracy: 0.8716 - val_loss: 0.5934 - val_auc_17: 0.7771 - val_binary_accuracy: 0.6757\n",
            "Epoch 262/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3150 - auc_17: 0.9329 - binary_accuracy: 0.8581 - val_loss: 0.5816 - val_auc_17: 0.7843 - val_binary_accuracy: 0.6892\n",
            "Epoch 263/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3020 - auc_17: 0.9356 - binary_accuracy: 0.8514 - val_loss: 0.5785 - val_auc_17: 0.7886 - val_binary_accuracy: 0.7162\n",
            "Epoch 264/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2999 - auc_17: 0.9354 - binary_accuracy: 0.8682 - val_loss: 0.5942 - val_auc_17: 0.7864 - val_binary_accuracy: 0.6892\n",
            "Epoch 265/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3053 - auc_17: 0.9364 - binary_accuracy: 0.8716 - val_loss: 0.5957 - val_auc_17: 0.7805 - val_binary_accuracy: 0.6892\n",
            "Epoch 266/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3037 - auc_17: 0.9351 - binary_accuracy: 0.8784 - val_loss: 0.5945 - val_auc_17: 0.7792 - val_binary_accuracy: 0.6892\n",
            "Epoch 267/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2948 - auc_17: 0.9349 - binary_accuracy: 0.8547 - val_loss: 0.5925 - val_auc_17: 0.7779 - val_binary_accuracy: 0.6757\n",
            "Epoch 268/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3172 - auc_17: 0.9280 - binary_accuracy: 0.8682 - val_loss: 0.5819 - val_auc_17: 0.7830 - val_binary_accuracy: 0.6892\n",
            "Epoch 269/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2886 - auc_17: 0.9442 - binary_accuracy: 0.8547 - val_loss: 0.5669 - val_auc_17: 0.7873 - val_binary_accuracy: 0.7027\n",
            "Epoch 270/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2999 - auc_17: 0.9366 - binary_accuracy: 0.8716 - val_loss: 0.5656 - val_auc_17: 0.7899 - val_binary_accuracy: 0.7162\n",
            "Epoch 271/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3102 - auc_17: 0.9327 - binary_accuracy: 0.8480 - val_loss: 0.5798 - val_auc_17: 0.7877 - val_binary_accuracy: 0.7162\n",
            "Epoch 272/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2874 - auc_17: 0.9447 - binary_accuracy: 0.8784 - val_loss: 0.5935 - val_auc_17: 0.7626 - val_binary_accuracy: 0.6757\n",
            "Epoch 273/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3002 - auc_17: 0.9386 - binary_accuracy: 0.8716 - val_loss: 0.5964 - val_auc_17: 0.7592 - val_binary_accuracy: 0.6892\n",
            "Epoch 274/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2854 - auc_17: 0.9464 - binary_accuracy: 0.8885 - val_loss: 0.5928 - val_auc_17: 0.7864 - val_binary_accuracy: 0.7027\n",
            "Epoch 275/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2928 - auc_17: 0.9444 - binary_accuracy: 0.8919 - val_loss: 0.6245 - val_auc_17: 0.7737 - val_binary_accuracy: 0.6892\n",
            "Epoch 276/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2942 - auc_17: 0.9389 - binary_accuracy: 0.8750 - val_loss: 0.6147 - val_auc_17: 0.7779 - val_binary_accuracy: 0.6892\n",
            "Epoch 277/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2642 - auc_17: 0.9568 - binary_accuracy: 0.8919 - val_loss: 0.6068 - val_auc_17: 0.7694 - val_binary_accuracy: 0.6892\n",
            "Epoch 278/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2946 - auc_17: 0.9380 - binary_accuracy: 0.8615 - val_loss: 0.5895 - val_auc_17: 0.7954 - val_binary_accuracy: 0.6757\n",
            "Epoch 279/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2892 - auc_17: 0.9362 - binary_accuracy: 0.8547 - val_loss: 0.5999 - val_auc_17: 0.7869 - val_binary_accuracy: 0.6892\n",
            "Epoch 280/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2766 - auc_17: 0.9490 - binary_accuracy: 0.8784 - val_loss: 0.5900 - val_auc_17: 0.7771 - val_binary_accuracy: 0.6892\n",
            "Epoch 281/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2668 - auc_17: 0.9552 - binary_accuracy: 0.8784 - val_loss: 0.6050 - val_auc_17: 0.7813 - val_binary_accuracy: 0.7162\n",
            "Epoch 282/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2646 - auc_17: 0.9563 - binary_accuracy: 0.9054 - val_loss: 0.6114 - val_auc_17: 0.7694 - val_binary_accuracy: 0.6757\n",
            "Epoch 283/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2851 - auc_17: 0.9441 - binary_accuracy: 0.8750 - val_loss: 0.6253 - val_auc_17: 0.7783 - val_binary_accuracy: 0.6892\n",
            "Epoch 284/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2726 - auc_17: 0.9501 - binary_accuracy: 0.8851 - val_loss: 0.6244 - val_auc_17: 0.7702 - val_binary_accuracy: 0.6892\n",
            "Epoch 285/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2666 - auc_17: 0.9538 - binary_accuracy: 0.8919 - val_loss: 0.6219 - val_auc_17: 0.7839 - val_binary_accuracy: 0.6757\n",
            "Epoch 286/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3108 - auc_17: 0.9309 - binary_accuracy: 0.8581 - val_loss: 0.5945 - val_auc_17: 0.7937 - val_binary_accuracy: 0.7027\n",
            "Epoch 287/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2991 - auc_17: 0.9336 - binary_accuracy: 0.8682 - val_loss: 0.5770 - val_auc_17: 0.7873 - val_binary_accuracy: 0.7027\n",
            "Epoch 288/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2856 - auc_17: 0.9439 - binary_accuracy: 0.8784 - val_loss: 0.6087 - val_auc_17: 0.7724 - val_binary_accuracy: 0.7027\n",
            "Epoch 289/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2979 - auc_17: 0.9417 - binary_accuracy: 0.8581 - val_loss: 0.5712 - val_auc_17: 0.7911 - val_binary_accuracy: 0.7027\n",
            "Epoch 290/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2974 - auc_17: 0.9357 - binary_accuracy: 0.8784 - val_loss: 0.5984 - val_auc_17: 0.7860 - val_binary_accuracy: 0.7027\n",
            "Epoch 291/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2945 - auc_17: 0.9408 - binary_accuracy: 0.8547 - val_loss: 0.6138 - val_auc_17: 0.7771 - val_binary_accuracy: 0.6892\n",
            "Epoch 292/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3021 - auc_17: 0.9418 - binary_accuracy: 0.8649 - val_loss: 0.6295 - val_auc_17: 0.7647 - val_binary_accuracy: 0.6892\n",
            "Epoch 293/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2768 - auc_17: 0.9476 - binary_accuracy: 0.8885 - val_loss: 0.6219 - val_auc_17: 0.7843 - val_binary_accuracy: 0.7162\n",
            "Epoch 294/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2759 - auc_17: 0.9514 - binary_accuracy: 0.8818 - val_loss: 0.6189 - val_auc_17: 0.7664 - val_binary_accuracy: 0.6892\n",
            "Epoch 295/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2828 - auc_17: 0.9439 - binary_accuracy: 0.8750 - val_loss: 0.5912 - val_auc_17: 0.7843 - val_binary_accuracy: 0.6757\n",
            "Epoch 296/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2605 - auc_17: 0.9591 - binary_accuracy: 0.9020 - val_loss: 0.5936 - val_auc_17: 0.7852 - val_binary_accuracy: 0.6622\n",
            "Epoch 297/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2779 - auc_17: 0.9477 - binary_accuracy: 0.8784 - val_loss: 0.6092 - val_auc_17: 0.7877 - val_binary_accuracy: 0.6757\n",
            "Epoch 298/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2772 - auc_17: 0.9464 - binary_accuracy: 0.8953 - val_loss: 0.6323 - val_auc_17: 0.7745 - val_binary_accuracy: 0.6622\n",
            "Epoch 299/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2782 - auc_17: 0.9459 - binary_accuracy: 0.8750 - val_loss: 0.6729 - val_auc_17: 0.7481 - val_binary_accuracy: 0.6757\n",
            "Epoch 300/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3077 - auc_17: 0.9276 - binary_accuracy: 0.8682 - val_loss: 0.6819 - val_auc_17: 0.7540 - val_binary_accuracy: 0.6622\n",
            "Epoch 301/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2743 - auc_17: 0.9495 - binary_accuracy: 0.8953 - val_loss: 0.6732 - val_auc_17: 0.7570 - val_binary_accuracy: 0.6622\n",
            "Epoch 302/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2750 - auc_17: 0.9476 - binary_accuracy: 0.8885 - val_loss: 0.6457 - val_auc_17: 0.7698 - val_binary_accuracy: 0.6892\n",
            "Epoch 303/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2727 - auc_17: 0.9463 - binary_accuracy: 0.8986 - val_loss: 0.6629 - val_auc_17: 0.7609 - val_binary_accuracy: 0.6757\n",
            "Epoch 304/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2796 - auc_17: 0.9454 - binary_accuracy: 0.8885 - val_loss: 0.6708 - val_auc_17: 0.7656 - val_binary_accuracy: 0.6892\n",
            "Epoch 305/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2996 - auc_17: 0.9362 - binary_accuracy: 0.8750 - val_loss: 0.6574 - val_auc_17: 0.7720 - val_binary_accuracy: 0.6757\n",
            "Epoch 306/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2983 - auc_17: 0.9388 - binary_accuracy: 0.8716 - val_loss: 0.6420 - val_auc_17: 0.7698 - val_binary_accuracy: 0.6757\n",
            "Epoch 307/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2675 - auc_17: 0.9544 - binary_accuracy: 0.8919 - val_loss: 0.6756 - val_auc_17: 0.7604 - val_binary_accuracy: 0.6757\n",
            "Epoch 308/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2955 - auc_17: 0.9356 - binary_accuracy: 0.8784 - val_loss: 0.6454 - val_auc_17: 0.7720 - val_binary_accuracy: 0.6622\n",
            "Epoch 309/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2693 - auc_17: 0.9490 - binary_accuracy: 0.8919 - val_loss: 0.6223 - val_auc_17: 0.7852 - val_binary_accuracy: 0.7027\n",
            "Epoch 310/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2589 - auc_17: 0.9559 - binary_accuracy: 0.8919 - val_loss: 0.6361 - val_auc_17: 0.7779 - val_binary_accuracy: 0.6892\n",
            "Epoch 311/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2739 - auc_17: 0.9431 - binary_accuracy: 0.8818 - val_loss: 0.6249 - val_auc_17: 0.7864 - val_binary_accuracy: 0.7162\n",
            "Epoch 312/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2830 - auc_17: 0.9442 - binary_accuracy: 0.8581 - val_loss: 0.6284 - val_auc_17: 0.7894 - val_binary_accuracy: 0.6757\n",
            "Epoch 313/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2605 - auc_17: 0.9544 - binary_accuracy: 0.8818 - val_loss: 0.5897 - val_auc_17: 0.7958 - val_binary_accuracy: 0.6622\n",
            "Epoch 314/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2916 - auc_17: 0.9372 - binary_accuracy: 0.8649 - val_loss: 0.5841 - val_auc_17: 0.7830 - val_binary_accuracy: 0.6892\n",
            "Epoch 315/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2736 - auc_17: 0.9486 - binary_accuracy: 0.8581 - val_loss: 0.6038 - val_auc_17: 0.7745 - val_binary_accuracy: 0.6892\n",
            "Epoch 316/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2998 - auc_17: 0.9394 - binary_accuracy: 0.8851 - val_loss: 0.5767 - val_auc_17: 0.7928 - val_binary_accuracy: 0.6892\n",
            "Epoch 317/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2691 - auc_17: 0.9459 - binary_accuracy: 0.8784 - val_loss: 0.5863 - val_auc_17: 0.7988 - val_binary_accuracy: 0.6892\n",
            "Epoch 318/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2443 - auc_17: 0.9637 - binary_accuracy: 0.9088 - val_loss: 0.6078 - val_auc_17: 0.7924 - val_binary_accuracy: 0.6892\n",
            "Epoch 319/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2717 - auc_17: 0.9498 - binary_accuracy: 0.9020 - val_loss: 0.5955 - val_auc_17: 0.7928 - val_binary_accuracy: 0.6892\n",
            "Epoch 320/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2713 - auc_17: 0.9463 - binary_accuracy: 0.8682 - val_loss: 0.6398 - val_auc_17: 0.7668 - val_binary_accuracy: 0.6892\n",
            "Epoch 321/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2679 - auc_17: 0.9523 - binary_accuracy: 0.8885 - val_loss: 0.6258 - val_auc_17: 0.7809 - val_binary_accuracy: 0.6892\n",
            "Epoch 322/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2787 - auc_17: 0.9435 - binary_accuracy: 0.8750 - val_loss: 0.6076 - val_auc_17: 0.7839 - val_binary_accuracy: 0.6757\n",
            "Epoch 323/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3049 - auc_17: 0.9381 - binary_accuracy: 0.8682 - val_loss: 0.6222 - val_auc_17: 0.7762 - val_binary_accuracy: 0.6757\n",
            "Epoch 324/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2647 - auc_17: 0.9516 - binary_accuracy: 0.8919 - val_loss: 0.5902 - val_auc_17: 0.7860 - val_binary_accuracy: 0.6757\n",
            "Epoch 325/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2660 - auc_17: 0.9508 - binary_accuracy: 0.8851 - val_loss: 0.5713 - val_auc_17: 0.7941 - val_binary_accuracy: 0.6892\n",
            "Epoch 326/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2681 - auc_17: 0.9484 - binary_accuracy: 0.8851 - val_loss: 0.6095 - val_auc_17: 0.7877 - val_binary_accuracy: 0.6757\n",
            "Epoch 327/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2620 - auc_17: 0.9564 - binary_accuracy: 0.8851 - val_loss: 0.6252 - val_auc_17: 0.7852 - val_binary_accuracy: 0.7027\n",
            "Epoch 328/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2825 - auc_17: 0.9420 - binary_accuracy: 0.8649 - val_loss: 0.5644 - val_auc_17: 0.8026 - val_binary_accuracy: 0.6757\n",
            "Epoch 329/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2584 - auc_17: 0.9563 - binary_accuracy: 0.9020 - val_loss: 0.5780 - val_auc_17: 0.7907 - val_binary_accuracy: 0.7162\n",
            "Epoch 330/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2771 - auc_17: 0.9522 - binary_accuracy: 0.9122 - val_loss: 0.5679 - val_auc_17: 0.7822 - val_binary_accuracy: 0.6892\n",
            "Epoch 331/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2516 - auc_17: 0.9569 - binary_accuracy: 0.8919 - val_loss: 0.5301 - val_auc_17: 0.8086 - val_binary_accuracy: 0.6757\n",
            "Epoch 332/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2574 - auc_17: 0.9532 - binary_accuracy: 0.8716 - val_loss: 0.5419 - val_auc_17: 0.8056 - val_binary_accuracy: 0.6892\n",
            "Epoch 333/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2632 - auc_17: 0.9511 - binary_accuracy: 0.8682 - val_loss: 0.5602 - val_auc_17: 0.7924 - val_binary_accuracy: 0.6892\n",
            "Epoch 334/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2543 - auc_17: 0.9587 - binary_accuracy: 0.8919 - val_loss: 0.5744 - val_auc_17: 0.7809 - val_binary_accuracy: 0.7027\n",
            "Epoch 335/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2454 - auc_17: 0.9617 - binary_accuracy: 0.8919 - val_loss: 0.5793 - val_auc_17: 0.7771 - val_binary_accuracy: 0.6757\n",
            "Epoch 336/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2886 - auc_17: 0.9417 - binary_accuracy: 0.8750 - val_loss: 0.5733 - val_auc_17: 0.8039 - val_binary_accuracy: 0.7027\n",
            "Epoch 337/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2546 - auc_17: 0.9575 - binary_accuracy: 0.8750 - val_loss: 0.5907 - val_auc_17: 0.7971 - val_binary_accuracy: 0.7162\n",
            "Epoch 338/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2528 - auc_17: 0.9567 - binary_accuracy: 0.8851 - val_loss: 0.5844 - val_auc_17: 0.7924 - val_binary_accuracy: 0.7162\n",
            "Epoch 339/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2662 - auc_17: 0.9489 - binary_accuracy: 0.8649 - val_loss: 0.5739 - val_auc_17: 0.8073 - val_binary_accuracy: 0.6892\n",
            "Epoch 340/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2629 - auc_17: 0.9530 - binary_accuracy: 0.8919 - val_loss: 0.5571 - val_auc_17: 0.8086 - val_binary_accuracy: 0.7162\n",
            "Epoch 341/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2330 - auc_17: 0.9646 - binary_accuracy: 0.9054 - val_loss: 0.5742 - val_auc_17: 0.8009 - val_binary_accuracy: 0.6892\n",
            "Epoch 342/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2505 - auc_17: 0.9557 - binary_accuracy: 0.8851 - val_loss: 0.5665 - val_auc_17: 0.8026 - val_binary_accuracy: 0.7027\n",
            "Epoch 343/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2950 - auc_17: 0.9445 - binary_accuracy: 0.8818 - val_loss: 0.6023 - val_auc_17: 0.7839 - val_binary_accuracy: 0.7027\n",
            "Epoch 344/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2779 - auc_17: 0.9574 - binary_accuracy: 0.8682 - val_loss: 0.6645 - val_auc_17: 0.7515 - val_binary_accuracy: 0.6892\n",
            "Epoch 345/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2754 - auc_17: 0.9461 - binary_accuracy: 0.8885 - val_loss: 0.5922 - val_auc_17: 0.7886 - val_binary_accuracy: 0.6757\n",
            "Epoch 346/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2636 - auc_17: 0.9493 - binary_accuracy: 0.8885 - val_loss: 0.5849 - val_auc_17: 0.8014 - val_binary_accuracy: 0.6892\n",
            "Epoch 347/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2649 - auc_17: 0.9509 - binary_accuracy: 0.8851 - val_loss: 0.6010 - val_auc_17: 0.7967 - val_binary_accuracy: 0.6757\n",
            "Epoch 348/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2668 - auc_17: 0.9514 - binary_accuracy: 0.8986 - val_loss: 0.5827 - val_auc_17: 0.8065 - val_binary_accuracy: 0.7027\n",
            "Epoch 349/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.2410 - auc_17: 0.9610 - binary_accuracy: 0.8953 - val_loss: 0.5849 - val_auc_17: 0.7941 - val_binary_accuracy: 0.6622\n",
            "Epoch 350/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2592 - auc_17: 0.9527 - binary_accuracy: 0.8750 - val_loss: 0.6140 - val_auc_17: 0.7835 - val_binary_accuracy: 0.7027\n",
            "Epoch 351/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2494 - auc_17: 0.9591 - binary_accuracy: 0.9020 - val_loss: 0.5925 - val_auc_17: 0.8005 - val_binary_accuracy: 0.6892\n",
            "Epoch 352/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2409 - auc_17: 0.9614 - binary_accuracy: 0.9122 - val_loss: 0.6036 - val_auc_17: 0.8031 - val_binary_accuracy: 0.7162\n",
            "Epoch 353/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2761 - auc_17: 0.9475 - binary_accuracy: 0.8750 - val_loss: 0.6270 - val_auc_17: 0.7971 - val_binary_accuracy: 0.7162\n",
            "Epoch 354/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2493 - auc_17: 0.9558 - binary_accuracy: 0.8851 - val_loss: 0.6016 - val_auc_17: 0.7992 - val_binary_accuracy: 0.7027\n",
            "Epoch 355/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2650 - auc_17: 0.9508 - binary_accuracy: 0.9020 - val_loss: 0.5940 - val_auc_17: 0.7962 - val_binary_accuracy: 0.6892\n",
            "Epoch 356/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2322 - auc_17: 0.9675 - binary_accuracy: 0.9088 - val_loss: 0.5930 - val_auc_17: 0.7920 - val_binary_accuracy: 0.6757\n",
            "Epoch 357/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2520 - auc_17: 0.9556 - binary_accuracy: 0.8919 - val_loss: 0.6095 - val_auc_17: 0.7937 - val_binary_accuracy: 0.6892\n",
            "Epoch 358/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2619 - auc_17: 0.9556 - binary_accuracy: 0.8986 - val_loss: 0.6080 - val_auc_17: 0.8035 - val_binary_accuracy: 0.7162\n",
            "Epoch 359/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2338 - auc_17: 0.9615 - binary_accuracy: 0.9088 - val_loss: 0.6288 - val_auc_17: 0.7975 - val_binary_accuracy: 0.6892\n",
            "Epoch 360/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3108 - auc_17: 0.9377 - binary_accuracy: 0.8885 - val_loss: 0.6177 - val_auc_17: 0.7856 - val_binary_accuracy: 0.6757\n",
            "Epoch 361/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2843 - auc_17: 0.9458 - binary_accuracy: 0.8784 - val_loss: 0.5989 - val_auc_17: 0.7732 - val_binary_accuracy: 0.6757\n",
            "Epoch 362/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2466 - auc_17: 0.9565 - binary_accuracy: 0.9088 - val_loss: 0.5946 - val_auc_17: 0.7856 - val_binary_accuracy: 0.7027\n",
            "Epoch 363/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2393 - auc_17: 0.9611 - binary_accuracy: 0.8851 - val_loss: 0.5904 - val_auc_17: 0.7933 - val_binary_accuracy: 0.6892\n",
            "Epoch 364/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2338 - auc_17: 0.9633 - binary_accuracy: 0.9054 - val_loss: 0.5995 - val_auc_17: 0.7975 - val_binary_accuracy: 0.7027\n",
            "Epoch 365/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2422 - auc_17: 0.9608 - binary_accuracy: 0.8986 - val_loss: 0.6201 - val_auc_17: 0.7928 - val_binary_accuracy: 0.6757\n",
            "Epoch 366/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2446 - auc_17: 0.9596 - binary_accuracy: 0.9088 - val_loss: 0.6192 - val_auc_17: 0.7775 - val_binary_accuracy: 0.6486\n",
            "Epoch 367/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2368 - auc_17: 0.9649 - binary_accuracy: 0.9054 - val_loss: 0.6200 - val_auc_17: 0.7856 - val_binary_accuracy: 0.6757\n",
            "Epoch 368/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2572 - auc_17: 0.9523 - binary_accuracy: 0.9054 - val_loss: 0.6126 - val_auc_17: 0.7933 - val_binary_accuracy: 0.6757\n",
            "Epoch 369/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2417 - auc_17: 0.9609 - binary_accuracy: 0.9054 - val_loss: 0.6203 - val_auc_17: 0.7882 - val_binary_accuracy: 0.6892\n",
            "Epoch 370/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2341 - auc_17: 0.9618 - binary_accuracy: 0.9054 - val_loss: 0.6256 - val_auc_17: 0.7839 - val_binary_accuracy: 0.6892\n",
            "Epoch 371/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2289 - auc_17: 0.9683 - binary_accuracy: 0.9054 - val_loss: 0.6445 - val_auc_17: 0.7958 - val_binary_accuracy: 0.7027\n",
            "Epoch 372/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2466 - auc_17: 0.9576 - binary_accuracy: 0.8885 - val_loss: 0.6803 - val_auc_17: 0.7673 - val_binary_accuracy: 0.6757\n",
            "Epoch 373/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2568 - auc_17: 0.9522 - binary_accuracy: 0.8953 - val_loss: 0.6578 - val_auc_17: 0.7600 - val_binary_accuracy: 0.6757\n",
            "Epoch 374/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2357 - auc_17: 0.9625 - binary_accuracy: 0.8919 - val_loss: 0.6252 - val_auc_17: 0.7886 - val_binary_accuracy: 0.6892\n",
            "Epoch 375/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2807 - auc_17: 0.9450 - binary_accuracy: 0.8919 - val_loss: 0.6085 - val_auc_17: 0.7941 - val_binary_accuracy: 0.6757\n",
            "Epoch 376/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2462 - auc_17: 0.9566 - binary_accuracy: 0.8953 - val_loss: 0.6216 - val_auc_17: 0.7903 - val_binary_accuracy: 0.6757\n",
            "Epoch 377/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2301 - auc_17: 0.9660 - binary_accuracy: 0.8953 - val_loss: 0.6467 - val_auc_17: 0.7707 - val_binary_accuracy: 0.6892\n",
            "Epoch 378/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2404 - auc_17: 0.9603 - binary_accuracy: 0.8784 - val_loss: 0.6297 - val_auc_17: 0.7864 - val_binary_accuracy: 0.6757\n",
            "Epoch 379/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2253 - auc_17: 0.9661 - binary_accuracy: 0.8953 - val_loss: 0.6012 - val_auc_17: 0.7916 - val_binary_accuracy: 0.6892\n",
            "Epoch 380/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2512 - auc_17: 0.9575 - binary_accuracy: 0.9020 - val_loss: 0.6022 - val_auc_17: 0.7916 - val_binary_accuracy: 0.6757\n",
            "Epoch 381/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2404 - auc_17: 0.9631 - binary_accuracy: 0.9054 - val_loss: 0.6249 - val_auc_17: 0.7826 - val_binary_accuracy: 0.6757\n",
            "Epoch 382/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2435 - auc_17: 0.9582 - binary_accuracy: 0.9088 - val_loss: 0.5985 - val_auc_17: 0.7886 - val_binary_accuracy: 0.6486\n",
            "Epoch 383/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2611 - auc_17: 0.9542 - binary_accuracy: 0.8784 - val_loss: 0.6110 - val_auc_17: 0.7881 - val_binary_accuracy: 0.6622\n",
            "Epoch 384/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2147 - auc_17: 0.9693 - binary_accuracy: 0.9189 - val_loss: 0.5976 - val_auc_17: 0.7941 - val_binary_accuracy: 0.6622\n",
            "Epoch 385/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2397 - auc_17: 0.9609 - binary_accuracy: 0.8986 - val_loss: 0.6056 - val_auc_17: 0.7873 - val_binary_accuracy: 0.6622\n",
            "Epoch 386/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2298 - auc_17: 0.9687 - binary_accuracy: 0.9257 - val_loss: 0.5940 - val_auc_17: 0.7899 - val_binary_accuracy: 0.6622\n",
            "Epoch 387/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2223 - auc_17: 0.9660 - binary_accuracy: 0.9122 - val_loss: 0.5843 - val_auc_17: 0.7869 - val_binary_accuracy: 0.6486\n",
            "Epoch 388/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2544 - auc_17: 0.9557 - binary_accuracy: 0.9054 - val_loss: 0.6201 - val_auc_17: 0.7843 - val_binary_accuracy: 0.6622\n",
            "Epoch 389/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2330 - auc_17: 0.9648 - binary_accuracy: 0.8953 - val_loss: 0.6390 - val_auc_17: 0.7801 - val_binary_accuracy: 0.6351\n",
            "Epoch 390/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2282 - auc_17: 0.9663 - binary_accuracy: 0.8919 - val_loss: 0.6386 - val_auc_17: 0.7741 - val_binary_accuracy: 0.6622\n",
            "Epoch 391/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2424 - auc_17: 0.9593 - binary_accuracy: 0.8818 - val_loss: 0.6343 - val_auc_17: 0.7813 - val_binary_accuracy: 0.6486\n",
            "Epoch 392/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2456 - auc_17: 0.9609 - binary_accuracy: 0.9088 - val_loss: 0.6067 - val_auc_17: 0.7988 - val_binary_accuracy: 0.6892\n",
            "Epoch 393/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2509 - auc_17: 0.9543 - binary_accuracy: 0.8885 - val_loss: 0.6632 - val_auc_17: 0.7639 - val_binary_accuracy: 0.6757\n",
            "Epoch 394/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2331 - auc_17: 0.9611 - binary_accuracy: 0.9054 - val_loss: 0.6393 - val_auc_17: 0.7737 - val_binary_accuracy: 0.6351\n",
            "Epoch 395/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2429 - auc_17: 0.9601 - binary_accuracy: 0.9020 - val_loss: 0.6416 - val_auc_17: 0.7788 - val_binary_accuracy: 0.6622\n",
            "Epoch 396/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2160 - auc_17: 0.9705 - binary_accuracy: 0.9155 - val_loss: 0.6150 - val_auc_17: 0.7886 - val_binary_accuracy: 0.6757\n",
            "Epoch 397/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2237 - auc_17: 0.9668 - binary_accuracy: 0.9122 - val_loss: 0.6506 - val_auc_17: 0.7822 - val_binary_accuracy: 0.6892\n",
            "Epoch 398/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2279 - auc_17: 0.9638 - binary_accuracy: 0.9122 - val_loss: 0.6420 - val_auc_17: 0.7766 - val_binary_accuracy: 0.6351\n",
            "Epoch 399/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2213 - auc_17: 0.9657 - binary_accuracy: 0.9122 - val_loss: 0.6466 - val_auc_17: 0.7771 - val_binary_accuracy: 0.6351\n",
            "Epoch 400/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2665 - auc_17: 0.9479 - binary_accuracy: 0.8851 - val_loss: 0.6354 - val_auc_17: 0.7766 - val_binary_accuracy: 0.6622\n",
            "Epoch 401/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2552 - auc_17: 0.9524 - binary_accuracy: 0.8885 - val_loss: 0.6176 - val_auc_17: 0.7835 - val_binary_accuracy: 0.6486\n",
            "Epoch 402/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2435 - auc_17: 0.9580 - binary_accuracy: 0.8885 - val_loss: 0.6170 - val_auc_17: 0.7907 - val_binary_accuracy: 0.6622\n",
            "Epoch 403/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2527 - auc_17: 0.9533 - binary_accuracy: 0.8885 - val_loss: 0.6292 - val_auc_17: 0.7809 - val_binary_accuracy: 0.6622\n",
            "Epoch 404/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2573 - auc_17: 0.9520 - binary_accuracy: 0.8818 - val_loss: 0.5939 - val_auc_17: 0.8129 - val_binary_accuracy: 0.6892\n",
            "Epoch 405/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2124 - auc_17: 0.9711 - binary_accuracy: 0.9054 - val_loss: 0.6446 - val_auc_17: 0.7766 - val_binary_accuracy: 0.6757\n",
            "Epoch 406/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2239 - auc_17: 0.9663 - binary_accuracy: 0.9122 - val_loss: 0.6528 - val_auc_17: 0.7847 - val_binary_accuracy: 0.7027\n",
            "Epoch 407/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2516 - auc_17: 0.9554 - binary_accuracy: 0.8919 - val_loss: 0.6289 - val_auc_17: 0.7894 - val_binary_accuracy: 0.6486\n",
            "Epoch 408/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2328 - auc_17: 0.9655 - binary_accuracy: 0.9189 - val_loss: 0.6494 - val_auc_17: 0.7771 - val_binary_accuracy: 0.6757\n",
            "Epoch 409/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2529 - auc_17: 0.9543 - binary_accuracy: 0.8885 - val_loss: 0.6218 - val_auc_17: 0.7877 - val_binary_accuracy: 0.6622\n",
            "Epoch 410/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2123 - auc_17: 0.9698 - binary_accuracy: 0.9155 - val_loss: 0.6302 - val_auc_17: 0.7941 - val_binary_accuracy: 0.6486\n",
            "Epoch 411/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2454 - auc_17: 0.9577 - binary_accuracy: 0.8953 - val_loss: 0.6091 - val_auc_17: 0.8043 - val_binary_accuracy: 0.6757\n",
            "Epoch 412/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2068 - auc_17: 0.9744 - binary_accuracy: 0.9257 - val_loss: 0.6101 - val_auc_17: 0.8001 - val_binary_accuracy: 0.6757\n",
            "Epoch 413/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1936 - auc_17: 0.9764 - binary_accuracy: 0.9358 - val_loss: 0.6049 - val_auc_17: 0.8022 - val_binary_accuracy: 0.6757\n",
            "Epoch 414/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2388 - auc_17: 0.9605 - binary_accuracy: 0.8919 - val_loss: 0.6208 - val_auc_17: 0.7907 - val_binary_accuracy: 0.6486\n",
            "Epoch 415/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2183 - auc_17: 0.9682 - binary_accuracy: 0.9155 - val_loss: 0.6312 - val_auc_17: 0.7852 - val_binary_accuracy: 0.6622\n",
            "Epoch 416/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2201 - auc_17: 0.9688 - binary_accuracy: 0.9189 - val_loss: 0.6554 - val_auc_17: 0.7758 - val_binary_accuracy: 0.6351\n",
            "Epoch 417/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2532 - auc_17: 0.9536 - binary_accuracy: 0.8919 - val_loss: 0.6286 - val_auc_17: 0.7890 - val_binary_accuracy: 0.6892\n",
            "Epoch 418/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2392 - auc_17: 0.9601 - binary_accuracy: 0.9020 - val_loss: 0.6186 - val_auc_17: 0.7890 - val_binary_accuracy: 0.6486\n",
            "Epoch 419/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2297 - auc_17: 0.9671 - binary_accuracy: 0.9155 - val_loss: 0.6722 - val_auc_17: 0.7783 - val_binary_accuracy: 0.7027\n",
            "Epoch 420/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2292 - auc_17: 0.9667 - binary_accuracy: 0.8953 - val_loss: 0.6386 - val_auc_17: 0.7911 - val_binary_accuracy: 0.7027\n",
            "Epoch 421/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2188 - auc_17: 0.9686 - binary_accuracy: 0.8986 - val_loss: 0.6651 - val_auc_17: 0.7835 - val_binary_accuracy: 0.6892\n",
            "Epoch 422/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2276 - auc_17: 0.9646 - binary_accuracy: 0.9088 - val_loss: 0.6905 - val_auc_17: 0.7626 - val_binary_accuracy: 0.6892\n",
            "Epoch 423/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2180 - auc_17: 0.9710 - binary_accuracy: 0.8919 - val_loss: 0.6303 - val_auc_17: 0.8001 - val_binary_accuracy: 0.6892\n",
            "Epoch 424/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2283 - auc_17: 0.9630 - binary_accuracy: 0.8953 - val_loss: 0.6187 - val_auc_17: 0.7916 - val_binary_accuracy: 0.6622\n",
            "Epoch 425/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2094 - auc_17: 0.9712 - binary_accuracy: 0.9088 - val_loss: 0.6321 - val_auc_17: 0.7852 - val_binary_accuracy: 0.6757\n",
            "Epoch 426/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2152 - auc_17: 0.9704 - binary_accuracy: 0.9291 - val_loss: 0.6360 - val_auc_17: 0.7869 - val_binary_accuracy: 0.6892\n",
            "Epoch 427/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2252 - auc_17: 0.9665 - binary_accuracy: 0.9020 - val_loss: 0.6596 - val_auc_17: 0.7899 - val_binary_accuracy: 0.7162\n",
            "Epoch 428/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2133 - auc_17: 0.9679 - binary_accuracy: 0.9189 - val_loss: 0.6250 - val_auc_17: 0.7958 - val_binary_accuracy: 0.6757\n",
            "Epoch 429/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2349 - auc_17: 0.9588 - binary_accuracy: 0.8953 - val_loss: 0.6481 - val_auc_17: 0.7882 - val_binary_accuracy: 0.7027\n",
            "Epoch 430/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1935 - auc_17: 0.9765 - binary_accuracy: 0.9324 - val_loss: 0.6444 - val_auc_17: 0.7869 - val_binary_accuracy: 0.6892\n",
            "Epoch 431/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2347 - auc_17: 0.9591 - binary_accuracy: 0.9155 - val_loss: 0.5996 - val_auc_17: 0.7971 - val_binary_accuracy: 0.6622\n",
            "Epoch 432/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2155 - auc_17: 0.9677 - binary_accuracy: 0.9054 - val_loss: 0.5996 - val_auc_17: 0.7920 - val_binary_accuracy: 0.6757\n",
            "Epoch 433/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2471 - auc_17: 0.9583 - binary_accuracy: 0.9122 - val_loss: 0.6140 - val_auc_17: 0.7950 - val_binary_accuracy: 0.6622\n",
            "Epoch 434/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2233 - auc_17: 0.9668 - binary_accuracy: 0.9088 - val_loss: 0.6163 - val_auc_17: 0.7958 - val_binary_accuracy: 0.6892\n",
            "Epoch 435/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2274 - auc_17: 0.9622 - binary_accuracy: 0.9122 - val_loss: 0.6068 - val_auc_17: 0.7937 - val_binary_accuracy: 0.6757\n",
            "Epoch 436/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2232 - auc_17: 0.9665 - binary_accuracy: 0.9088 - val_loss: 0.6108 - val_auc_17: 0.7958 - val_binary_accuracy: 0.6622\n",
            "Epoch 437/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2210 - auc_17: 0.9677 - binary_accuracy: 0.8953 - val_loss: 0.6274 - val_auc_17: 0.7937 - val_binary_accuracy: 0.6622\n",
            "Epoch 438/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2265 - auc_17: 0.9685 - binary_accuracy: 0.8953 - val_loss: 0.6741 - val_auc_17: 0.7728 - val_binary_accuracy: 0.6757\n",
            "Epoch 439/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2207 - auc_17: 0.9690 - binary_accuracy: 0.9189 - val_loss: 0.6421 - val_auc_17: 0.7877 - val_binary_accuracy: 0.7162\n",
            "Epoch 440/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2381 - auc_17: 0.9623 - binary_accuracy: 0.9122 - val_loss: 0.6557 - val_auc_17: 0.7801 - val_binary_accuracy: 0.6892\n",
            "Epoch 441/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2221 - auc_17: 0.9739 - binary_accuracy: 0.9223 - val_loss: 0.6932 - val_auc_17: 0.7630 - val_binary_accuracy: 0.6892\n",
            "Epoch 442/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2369 - auc_17: 0.9594 - binary_accuracy: 0.9054 - val_loss: 0.6555 - val_auc_17: 0.7673 - val_binary_accuracy: 0.6757\n",
            "Epoch 443/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2108 - auc_17: 0.9699 - binary_accuracy: 0.9054 - val_loss: 0.6674 - val_auc_17: 0.7711 - val_binary_accuracy: 0.6622\n",
            "Epoch 444/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2096 - auc_17: 0.9703 - binary_accuracy: 0.9155 - val_loss: 0.6536 - val_auc_17: 0.7835 - val_binary_accuracy: 0.6892\n",
            "Epoch 445/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2112 - auc_17: 0.9707 - binary_accuracy: 0.9257 - val_loss: 0.6778 - val_auc_17: 0.7762 - val_binary_accuracy: 0.6486\n",
            "Epoch 446/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2074 - auc_17: 0.9734 - binary_accuracy: 0.9088 - val_loss: 0.6695 - val_auc_17: 0.7694 - val_binary_accuracy: 0.6622\n",
            "Epoch 447/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2016 - auc_17: 0.9723 - binary_accuracy: 0.9257 - val_loss: 0.6387 - val_auc_17: 0.7954 - val_binary_accuracy: 0.6757\n",
            "Epoch 448/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2136 - auc_17: 0.9705 - binary_accuracy: 0.9054 - val_loss: 0.6847 - val_auc_17: 0.7754 - val_binary_accuracy: 0.6757\n",
            "Epoch 449/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2236 - auc_17: 0.9645 - binary_accuracy: 0.8986 - val_loss: 0.6544 - val_auc_17: 0.7809 - val_binary_accuracy: 0.6757\n",
            "Epoch 450/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1946 - auc_17: 0.9749 - binary_accuracy: 0.9189 - val_loss: 0.6593 - val_auc_17: 0.7685 - val_binary_accuracy: 0.6486\n",
            "Epoch 451/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2074 - auc_17: 0.9704 - binary_accuracy: 0.9088 - val_loss: 0.6579 - val_auc_17: 0.7737 - val_binary_accuracy: 0.6622\n",
            "Epoch 452/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1960 - auc_17: 0.9748 - binary_accuracy: 0.9189 - val_loss: 0.6430 - val_auc_17: 0.7869 - val_binary_accuracy: 0.6892\n",
            "Epoch 453/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2094 - auc_17: 0.9685 - binary_accuracy: 0.9155 - val_loss: 0.6649 - val_auc_17: 0.7805 - val_binary_accuracy: 0.6757\n",
            "Epoch 454/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1702 - auc_17: 0.9870 - binary_accuracy: 0.9459 - val_loss: 0.6221 - val_auc_17: 0.7788 - val_binary_accuracy: 0.7027\n",
            "Epoch 455/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2113 - auc_17: 0.9698 - binary_accuracy: 0.9088 - val_loss: 0.6487 - val_auc_17: 0.7677 - val_binary_accuracy: 0.6622\n",
            "Epoch 456/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1979 - auc_17: 0.9758 - binary_accuracy: 0.9358 - val_loss: 0.6623 - val_auc_17: 0.7673 - val_binary_accuracy: 0.6757\n",
            "Epoch 457/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2306 - auc_17: 0.9639 - binary_accuracy: 0.9054 - val_loss: 0.6601 - val_auc_17: 0.7873 - val_binary_accuracy: 0.7027\n",
            "Epoch 458/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1990 - auc_17: 0.9741 - binary_accuracy: 0.8986 - val_loss: 0.7000 - val_auc_17: 0.7690 - val_binary_accuracy: 0.6757\n",
            "Epoch 459/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1988 - auc_17: 0.9751 - binary_accuracy: 0.9291 - val_loss: 0.7088 - val_auc_17: 0.7702 - val_binary_accuracy: 0.6622\n",
            "Epoch 460/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2083 - auc_17: 0.9710 - binary_accuracy: 0.9088 - val_loss: 0.6864 - val_auc_17: 0.7843 - val_binary_accuracy: 0.6892\n",
            "Epoch 461/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2052 - auc_17: 0.9715 - binary_accuracy: 0.9189 - val_loss: 0.6799 - val_auc_17: 0.7860 - val_binary_accuracy: 0.6757\n",
            "Epoch 462/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1975 - auc_17: 0.9745 - binary_accuracy: 0.9122 - val_loss: 0.7399 - val_auc_17: 0.7766 - val_binary_accuracy: 0.6757\n",
            "Epoch 463/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1894 - auc_17: 0.9769 - binary_accuracy: 0.9257 - val_loss: 0.7350 - val_auc_17: 0.7664 - val_binary_accuracy: 0.6757\n",
            "Epoch 464/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1709 - auc_17: 0.9837 - binary_accuracy: 0.9358 - val_loss: 0.7037 - val_auc_17: 0.7720 - val_binary_accuracy: 0.6622\n",
            "Epoch 465/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1955 - auc_17: 0.9727 - binary_accuracy: 0.9291 - val_loss: 0.6865 - val_auc_17: 0.7796 - val_binary_accuracy: 0.6757\n",
            "Epoch 466/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2043 - auc_17: 0.9724 - binary_accuracy: 0.9189 - val_loss: 0.7077 - val_auc_17: 0.7741 - val_binary_accuracy: 0.6757\n",
            "Epoch 467/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2323 - auc_17: 0.9679 - binary_accuracy: 0.8986 - val_loss: 0.7237 - val_auc_17: 0.7630 - val_binary_accuracy: 0.6892\n",
            "Epoch 468/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2128 - auc_17: 0.9706 - binary_accuracy: 0.9020 - val_loss: 0.6743 - val_auc_17: 0.7860 - val_binary_accuracy: 0.6892\n",
            "Epoch 469/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1914 - auc_17: 0.9772 - binary_accuracy: 0.9189 - val_loss: 0.7244 - val_auc_17: 0.7796 - val_binary_accuracy: 0.6757\n",
            "Epoch 470/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1857 - auc_17: 0.9781 - binary_accuracy: 0.9291 - val_loss: 0.7073 - val_auc_17: 0.7847 - val_binary_accuracy: 0.6892\n",
            "Epoch 471/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2042 - auc_17: 0.9739 - binary_accuracy: 0.9122 - val_loss: 0.6955 - val_auc_17: 0.7801 - val_binary_accuracy: 0.6892\n",
            "Epoch 472/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2090 - auc_17: 0.9712 - binary_accuracy: 0.9122 - val_loss: 0.7352 - val_auc_17: 0.7664 - val_binary_accuracy: 0.6892\n",
            "Epoch 473/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2076 - auc_17: 0.9729 - binary_accuracy: 0.9155 - val_loss: 0.7142 - val_auc_17: 0.7737 - val_binary_accuracy: 0.6892\n",
            "Epoch 474/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2159 - auc_17: 0.9679 - binary_accuracy: 0.9291 - val_loss: 0.6948 - val_auc_17: 0.7877 - val_binary_accuracy: 0.6892\n",
            "Epoch 475/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1756 - auc_17: 0.9847 - binary_accuracy: 0.9459 - val_loss: 0.7105 - val_auc_17: 0.7873 - val_binary_accuracy: 0.6757\n",
            "Epoch 476/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1869 - auc_17: 0.9787 - binary_accuracy: 0.9358 - val_loss: 0.7021 - val_auc_17: 0.7864 - val_binary_accuracy: 0.6757\n",
            "Epoch 477/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2059 - auc_17: 0.9715 - binary_accuracy: 0.9054 - val_loss: 0.7209 - val_auc_17: 0.7869 - val_binary_accuracy: 0.6892\n",
            "Epoch 478/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1892 - auc_17: 0.9761 - binary_accuracy: 0.9155 - val_loss: 0.7685 - val_auc_17: 0.7775 - val_binary_accuracy: 0.6892\n",
            "Epoch 479/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2011 - auc_17: 0.9726 - binary_accuracy: 0.9088 - val_loss: 0.7494 - val_auc_17: 0.7745 - val_binary_accuracy: 0.6622\n",
            "Epoch 480/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2040 - auc_17: 0.9719 - binary_accuracy: 0.9257 - val_loss: 0.7227 - val_auc_17: 0.7847 - val_binary_accuracy: 0.6892\n",
            "Epoch 481/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2413 - auc_17: 0.9605 - binary_accuracy: 0.8885 - val_loss: 0.7549 - val_auc_17: 0.7715 - val_binary_accuracy: 0.6622\n",
            "Epoch 482/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2054 - auc_17: 0.9729 - binary_accuracy: 0.9122 - val_loss: 0.7439 - val_auc_17: 0.7715 - val_binary_accuracy: 0.6757\n",
            "Epoch 483/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1889 - auc_17: 0.9789 - binary_accuracy: 0.9257 - val_loss: 0.7162 - val_auc_17: 0.7826 - val_binary_accuracy: 0.6757\n",
            "Epoch 484/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1701 - auc_17: 0.9833 - binary_accuracy: 0.9257 - val_loss: 0.7453 - val_auc_17: 0.7792 - val_binary_accuracy: 0.7027\n",
            "Epoch 485/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2082 - auc_17: 0.9712 - binary_accuracy: 0.9291 - val_loss: 0.7326 - val_auc_17: 0.7826 - val_binary_accuracy: 0.7027\n",
            "Epoch 486/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1767 - auc_17: 0.9828 - binary_accuracy: 0.9291 - val_loss: 0.7424 - val_auc_17: 0.7771 - val_binary_accuracy: 0.6757\n",
            "Epoch 487/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1873 - auc_17: 0.9773 - binary_accuracy: 0.9223 - val_loss: 0.7213 - val_auc_17: 0.7724 - val_binary_accuracy: 0.6757\n",
            "Epoch 488/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2117 - auc_17: 0.9694 - binary_accuracy: 0.9122 - val_loss: 0.7180 - val_auc_17: 0.7609 - val_binary_accuracy: 0.6757\n",
            "Epoch 489/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1839 - auc_17: 0.9777 - binary_accuracy: 0.9223 - val_loss: 0.7332 - val_auc_17: 0.7664 - val_binary_accuracy: 0.6892\n",
            "Epoch 490/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1821 - auc_17: 0.9802 - binary_accuracy: 0.9358 - val_loss: 0.7452 - val_auc_17: 0.7707 - val_binary_accuracy: 0.6757\n",
            "Epoch 491/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1802 - auc_17: 0.9792 - binary_accuracy: 0.9189 - val_loss: 0.7416 - val_auc_17: 0.7749 - val_binary_accuracy: 0.6622\n",
            "Epoch 492/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1788 - auc_17: 0.9807 - binary_accuracy: 0.9358 - val_loss: 0.7138 - val_auc_17: 0.7758 - val_binary_accuracy: 0.6892\n",
            "Epoch 493/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2050 - auc_17: 0.9710 - binary_accuracy: 0.9155 - val_loss: 0.7503 - val_auc_17: 0.7634 - val_binary_accuracy: 0.7162\n",
            "Epoch 494/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2190 - auc_17: 0.9718 - binary_accuracy: 0.9122 - val_loss: 0.7399 - val_auc_17: 0.7830 - val_binary_accuracy: 0.6892\n",
            "Epoch 495/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1889 - auc_17: 0.9778 - binary_accuracy: 0.9257 - val_loss: 0.7571 - val_auc_17: 0.7869 - val_binary_accuracy: 0.7027\n",
            "Epoch 496/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1899 - auc_17: 0.9769 - binary_accuracy: 0.9324 - val_loss: 0.8126 - val_auc_17: 0.7600 - val_binary_accuracy: 0.6757\n",
            "Epoch 497/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2160 - auc_17: 0.9711 - binary_accuracy: 0.9020 - val_loss: 0.7473 - val_auc_17: 0.7711 - val_binary_accuracy: 0.6757\n",
            "Epoch 498/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2014 - auc_17: 0.9726 - binary_accuracy: 0.9223 - val_loss: 0.7290 - val_auc_17: 0.7771 - val_binary_accuracy: 0.6622\n",
            "Epoch 499/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1857 - auc_17: 0.9793 - binary_accuracy: 0.9291 - val_loss: 0.7546 - val_auc_17: 0.7754 - val_binary_accuracy: 0.7027\n",
            "Epoch 500/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2250 - auc_17: 0.9625 - binary_accuracy: 0.9054 - val_loss: 0.7488 - val_auc_17: 0.7771 - val_binary_accuracy: 0.6757\n",
            "Epoch 1/500\n",
            "10/10 [==============================] - 3s 85ms/step - loss: 0.6825 - auc_18: 0.4627 - binary_accuracy: 0.5912 - val_loss: 0.6577 - val_auc_18: 0.6070 - val_binary_accuracy: 0.6622\n",
            "Epoch 2/500\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.6424 - auc_18: 0.6225 - binary_accuracy: 0.6622 - val_loss: 0.6281 - val_auc_18: 0.6249 - val_binary_accuracy: 0.6892\n",
            "Epoch 3/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6122 - auc_18: 0.6602 - binary_accuracy: 0.6791 - val_loss: 0.6117 - val_auc_18: 0.6445 - val_binary_accuracy: 0.6892\n",
            "Epoch 4/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.5891 - auc_18: 0.6737 - binary_accuracy: 0.6757 - val_loss: 0.6078 - val_auc_18: 0.6500 - val_binary_accuracy: 0.6892\n",
            "Epoch 5/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.5800 - auc_18: 0.6897 - binary_accuracy: 0.6892 - val_loss: 0.6101 - val_auc_18: 0.6556 - val_binary_accuracy: 0.6757\n",
            "Epoch 6/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5823 - auc_18: 0.6828 - binary_accuracy: 0.6824 - val_loss: 0.6081 - val_auc_18: 0.6569 - val_binary_accuracy: 0.6892\n",
            "Epoch 7/500\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.5794 - auc_18: 0.6851 - binary_accuracy: 0.6959 - val_loss: 0.6075 - val_auc_18: 0.6552 - val_binary_accuracy: 0.6892\n",
            "Epoch 8/500\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.5721 - auc_18: 0.6997 - binary_accuracy: 0.6824 - val_loss: 0.5994 - val_auc_18: 0.6581 - val_binary_accuracy: 0.7027\n",
            "Epoch 9/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5714 - auc_18: 0.6974 - binary_accuracy: 0.6858 - val_loss: 0.6008 - val_auc_18: 0.6577 - val_binary_accuracy: 0.6892\n",
            "Epoch 10/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5691 - auc_18: 0.7000 - binary_accuracy: 0.7128 - val_loss: 0.6058 - val_auc_18: 0.6607 - val_binary_accuracy: 0.6757\n",
            "Epoch 11/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.5720 - auc_18: 0.6956 - binary_accuracy: 0.6926 - val_loss: 0.5985 - val_auc_18: 0.6598 - val_binary_accuracy: 0.6757\n",
            "Epoch 12/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5621 - auc_18: 0.7119 - binary_accuracy: 0.6926 - val_loss: 0.6036 - val_auc_18: 0.6594 - val_binary_accuracy: 0.6757\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5564 - auc_18: 0.7209 - binary_accuracy: 0.6993 - val_loss: 0.6026 - val_auc_18: 0.6645 - val_binary_accuracy: 0.6892\n",
            "Epoch 14/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5678 - auc_18: 0.7053 - binary_accuracy: 0.6959 - val_loss: 0.6024 - val_auc_18: 0.6598 - val_binary_accuracy: 0.6892\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.5575 - auc_18: 0.7192 - binary_accuracy: 0.7128 - val_loss: 0.5885 - val_auc_18: 0.6739 - val_binary_accuracy: 0.6757\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5666 - auc_18: 0.7030 - binary_accuracy: 0.7061 - val_loss: 0.5827 - val_auc_18: 0.6769 - val_binary_accuracy: 0.6892\n",
            "Epoch 17/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5649 - auc_18: 0.7074 - binary_accuracy: 0.7061 - val_loss: 0.5853 - val_auc_18: 0.6799 - val_binary_accuracy: 0.7027\n",
            "Epoch 18/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5651 - auc_18: 0.7086 - binary_accuracy: 0.6993 - val_loss: 0.5962 - val_auc_18: 0.6598 - val_binary_accuracy: 0.6892\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5633 - auc_18: 0.7153 - binary_accuracy: 0.7095 - val_loss: 0.5760 - val_auc_18: 0.6850 - val_binary_accuracy: 0.6892\n",
            "Epoch 20/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5567 - auc_18: 0.7249 - binary_accuracy: 0.7162 - val_loss: 0.5772 - val_auc_18: 0.6850 - val_binary_accuracy: 0.6892\n",
            "Epoch 21/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5512 - auc_18: 0.7299 - binary_accuracy: 0.6993 - val_loss: 0.5798 - val_auc_18: 0.6858 - val_binary_accuracy: 0.6892\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5588 - auc_18: 0.7154 - binary_accuracy: 0.6926 - val_loss: 0.5927 - val_auc_18: 0.6760 - val_binary_accuracy: 0.6757\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5481 - auc_18: 0.7417 - binary_accuracy: 0.7128 - val_loss: 0.5738 - val_auc_18: 0.6880 - val_binary_accuracy: 0.6892\n",
            "Epoch 24/500\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.5354 - auc_18: 0.7549 - binary_accuracy: 0.7196 - val_loss: 0.5615 - val_auc_18: 0.6991 - val_binary_accuracy: 0.6892\n",
            "Epoch 25/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5460 - auc_18: 0.7384 - binary_accuracy: 0.7128 - val_loss: 0.5640 - val_auc_18: 0.7020 - val_binary_accuracy: 0.6757\n",
            "Epoch 26/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.5404 - auc_18: 0.7487 - binary_accuracy: 0.7230 - val_loss: 0.5573 - val_auc_18: 0.7101 - val_binary_accuracy: 0.6757\n",
            "Epoch 27/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.5328 - auc_18: 0.7502 - binary_accuracy: 0.7297 - val_loss: 0.5542 - val_auc_18: 0.7101 - val_binary_accuracy: 0.6892\n",
            "Epoch 28/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5412 - auc_18: 0.7443 - binary_accuracy: 0.7230 - val_loss: 0.5494 - val_auc_18: 0.7131 - val_binary_accuracy: 0.7027\n",
            "Epoch 29/500\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.5326 - auc_18: 0.7531 - binary_accuracy: 0.7196 - val_loss: 0.5338 - val_auc_18: 0.7430 - val_binary_accuracy: 0.6757\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.5250 - auc_18: 0.7686 - binary_accuracy: 0.7264 - val_loss: 0.5288 - val_auc_18: 0.7511 - val_binary_accuracy: 0.6757\n",
            "Epoch 31/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.5251 - auc_18: 0.7643 - binary_accuracy: 0.7500 - val_loss: 0.5351 - val_auc_18: 0.7413 - val_binary_accuracy: 0.7027\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5099 - auc_18: 0.7810 - binary_accuracy: 0.7365 - val_loss: 0.5241 - val_auc_18: 0.7566 - val_binary_accuracy: 0.7432\n",
            "Epoch 33/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.5300 - auc_18: 0.7516 - binary_accuracy: 0.7162 - val_loss: 0.5150 - val_auc_18: 0.7711 - val_binary_accuracy: 0.7432\n",
            "Epoch 34/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5114 - auc_18: 0.7776 - binary_accuracy: 0.7466 - val_loss: 0.5127 - val_auc_18: 0.7749 - val_binary_accuracy: 0.7162\n",
            "Epoch 35/500\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.5134 - auc_18: 0.7807 - binary_accuracy: 0.7500 - val_loss: 0.5014 - val_auc_18: 0.7830 - val_binary_accuracy: 0.7297\n",
            "Epoch 36/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5140 - auc_18: 0.7653 - binary_accuracy: 0.7264 - val_loss: 0.5278 - val_auc_18: 0.7425 - val_binary_accuracy: 0.6757\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5145 - auc_18: 0.7608 - binary_accuracy: 0.6993 - val_loss: 0.5125 - val_auc_18: 0.7664 - val_binary_accuracy: 0.7297\n",
            "Epoch 38/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5110 - auc_18: 0.7786 - binary_accuracy: 0.7297 - val_loss: 0.5012 - val_auc_18: 0.7813 - val_binary_accuracy: 0.7297\n",
            "Epoch 39/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5021 - auc_18: 0.7931 - binary_accuracy: 0.7534 - val_loss: 0.5098 - val_auc_18: 0.7843 - val_binary_accuracy: 0.7432\n",
            "Epoch 40/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4970 - auc_18: 0.7889 - binary_accuracy: 0.7297 - val_loss: 0.5213 - val_auc_18: 0.7796 - val_binary_accuracy: 0.7432\n",
            "Epoch 41/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4919 - auc_18: 0.7965 - binary_accuracy: 0.7466 - val_loss: 0.5066 - val_auc_18: 0.7903 - val_binary_accuracy: 0.7432\n",
            "Epoch 42/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4877 - auc_18: 0.7991 - binary_accuracy: 0.7365 - val_loss: 0.5036 - val_auc_18: 0.7933 - val_binary_accuracy: 0.7568\n",
            "Epoch 43/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.4836 - auc_18: 0.8055 - binary_accuracy: 0.7331 - val_loss: 0.5003 - val_auc_18: 0.7997 - val_binary_accuracy: 0.7703\n",
            "Epoch 44/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4828 - auc_18: 0.7998 - binary_accuracy: 0.7297 - val_loss: 0.5066 - val_auc_18: 0.8001 - val_binary_accuracy: 0.7568\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.4876 - auc_18: 0.7972 - binary_accuracy: 0.7297 - val_loss: 0.4933 - val_auc_18: 0.7975 - val_binary_accuracy: 0.7432\n",
            "Epoch 46/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4875 - auc_18: 0.7969 - binary_accuracy: 0.7399 - val_loss: 0.4947 - val_auc_18: 0.8069 - val_binary_accuracy: 0.7568\n",
            "Epoch 47/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4821 - auc_18: 0.8055 - binary_accuracy: 0.7568 - val_loss: 0.4851 - val_auc_18: 0.8107 - val_binary_accuracy: 0.7432\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4826 - auc_18: 0.8010 - binary_accuracy: 0.7264 - val_loss: 0.5016 - val_auc_18: 0.8061 - val_binary_accuracy: 0.7432\n",
            "Epoch 49/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4706 - auc_18: 0.8146 - binary_accuracy: 0.7230 - val_loss: 0.4770 - val_auc_18: 0.8244 - val_binary_accuracy: 0.7703\n",
            "Epoch 50/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4667 - auc_18: 0.8239 - binary_accuracy: 0.7297 - val_loss: 0.4842 - val_auc_18: 0.8210 - val_binary_accuracy: 0.7703\n",
            "Epoch 51/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4597 - auc_18: 0.8286 - binary_accuracy: 0.7432 - val_loss: 0.5328 - val_auc_18: 0.7933 - val_binary_accuracy: 0.7432\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4589 - auc_18: 0.8247 - binary_accuracy: 0.7365 - val_loss: 0.5210 - val_auc_18: 0.8035 - val_binary_accuracy: 0.7973\n",
            "Epoch 53/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.4718 - auc_18: 0.8135 - binary_accuracy: 0.7635 - val_loss: 0.5133 - val_auc_18: 0.8056 - val_binary_accuracy: 0.7838\n",
            "Epoch 54/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4692 - auc_18: 0.8092 - binary_accuracy: 0.7399 - val_loss: 0.5488 - val_auc_18: 0.7835 - val_binary_accuracy: 0.7432\n",
            "Epoch 55/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4697 - auc_18: 0.8201 - binary_accuracy: 0.7534 - val_loss: 0.5074 - val_auc_18: 0.8129 - val_binary_accuracy: 0.7973\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4587 - auc_18: 0.8274 - binary_accuracy: 0.7568 - val_loss: 0.5452 - val_auc_18: 0.7950 - val_binary_accuracy: 0.7973\n",
            "Epoch 57/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.4578 - auc_18: 0.8250 - binary_accuracy: 0.7466 - val_loss: 0.5210 - val_auc_18: 0.8103 - val_binary_accuracy: 0.7973\n",
            "Epoch 58/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4532 - auc_18: 0.8330 - binary_accuracy: 0.7703 - val_loss: 0.5392 - val_auc_18: 0.8082 - val_binary_accuracy: 0.7973\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.4473 - auc_18: 0.8341 - binary_accuracy: 0.7466 - val_loss: 0.5526 - val_auc_18: 0.8014 - val_binary_accuracy: 0.7973\n",
            "Epoch 60/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4554 - auc_18: 0.8303 - binary_accuracy: 0.7669 - val_loss: 0.5008 - val_auc_18: 0.8099 - val_binary_accuracy: 0.7973\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4520 - auc_18: 0.8301 - binary_accuracy: 0.7466 - val_loss: 0.5259 - val_auc_18: 0.8073 - val_binary_accuracy: 0.7838\n",
            "Epoch 62/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4585 - auc_18: 0.8253 - binary_accuracy: 0.7534 - val_loss: 0.4986 - val_auc_18: 0.8193 - val_binary_accuracy: 0.7838\n",
            "Epoch 63/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4486 - auc_18: 0.8367 - binary_accuracy: 0.7568 - val_loss: 0.4900 - val_auc_18: 0.8201 - val_binary_accuracy: 0.7973\n",
            "Epoch 64/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.4363 - auc_18: 0.8429 - binary_accuracy: 0.7568 - val_loss: 0.5437 - val_auc_18: 0.8048 - val_binary_accuracy: 0.7838\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4452 - auc_18: 0.8354 - binary_accuracy: 0.7534 - val_loss: 0.5125 - val_auc_18: 0.8150 - val_binary_accuracy: 0.7703\n",
            "Epoch 66/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4374 - auc_18: 0.8557 - binary_accuracy: 0.7939 - val_loss: 0.4862 - val_auc_18: 0.8278 - val_binary_accuracy: 0.7703\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4471 - auc_18: 0.8341 - binary_accuracy: 0.7635 - val_loss: 0.4961 - val_auc_18: 0.8274 - val_binary_accuracy: 0.8108\n",
            "Epoch 68/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4396 - auc_18: 0.8388 - binary_accuracy: 0.7568 - val_loss: 0.5010 - val_auc_18: 0.8227 - val_binary_accuracy: 0.7973\n",
            "Epoch 69/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4289 - auc_18: 0.8510 - binary_accuracy: 0.7669 - val_loss: 0.5190 - val_auc_18: 0.8167 - val_binary_accuracy: 0.7973\n",
            "Epoch 70/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4152 - auc_18: 0.8635 - binary_accuracy: 0.7736 - val_loss: 0.5087 - val_auc_18: 0.8159 - val_binary_accuracy: 0.8108\n",
            "Epoch 71/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4249 - auc_18: 0.8556 - binary_accuracy: 0.7770 - val_loss: 0.5256 - val_auc_18: 0.8133 - val_binary_accuracy: 0.8108\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4551 - auc_18: 0.8249 - binary_accuracy: 0.7568 - val_loss: 0.5389 - val_auc_18: 0.8069 - val_binary_accuracy: 0.7703\n",
            "Epoch 73/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4196 - auc_18: 0.8601 - binary_accuracy: 0.7736 - val_loss: 0.5118 - val_auc_18: 0.8171 - val_binary_accuracy: 0.8108\n",
            "Epoch 74/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4195 - auc_18: 0.8617 - binary_accuracy: 0.7770 - val_loss: 0.5154 - val_auc_18: 0.8218 - val_binary_accuracy: 0.7973\n",
            "Epoch 75/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4275 - auc_18: 0.8515 - binary_accuracy: 0.7635 - val_loss: 0.5135 - val_auc_18: 0.8214 - val_binary_accuracy: 0.7838\n",
            "Epoch 76/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4206 - auc_18: 0.8624 - binary_accuracy: 0.7804 - val_loss: 0.5147 - val_auc_18: 0.8193 - val_binary_accuracy: 0.8108\n",
            "Epoch 77/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4400 - auc_18: 0.8402 - binary_accuracy: 0.7534 - val_loss: 0.4854 - val_auc_18: 0.8248 - val_binary_accuracy: 0.7973\n",
            "Epoch 78/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4124 - auc_18: 0.8579 - binary_accuracy: 0.7770 - val_loss: 0.4966 - val_auc_18: 0.8286 - val_binary_accuracy: 0.7838\n",
            "Epoch 79/500\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.4001 - auc_18: 0.8709 - binary_accuracy: 0.7736 - val_loss: 0.4686 - val_auc_18: 0.8397 - val_binary_accuracy: 0.7838\n",
            "Epoch 80/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4159 - auc_18: 0.8601 - binary_accuracy: 0.7635 - val_loss: 0.4971 - val_auc_18: 0.8321 - val_binary_accuracy: 0.7973\n",
            "Epoch 81/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4019 - auc_18: 0.8715 - binary_accuracy: 0.7736 - val_loss: 0.5003 - val_auc_18: 0.8265 - val_binary_accuracy: 0.7432\n",
            "Epoch 82/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.4165 - auc_18: 0.8620 - binary_accuracy: 0.7838 - val_loss: 0.4859 - val_auc_18: 0.8205 - val_binary_accuracy: 0.7297\n",
            "Epoch 83/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.4058 - auc_18: 0.8665 - binary_accuracy: 0.7872 - val_loss: 0.4903 - val_auc_18: 0.8376 - val_binary_accuracy: 0.7973\n",
            "Epoch 84/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4238 - auc_18: 0.8518 - binary_accuracy: 0.7568 - val_loss: 0.4987 - val_auc_18: 0.8223 - val_binary_accuracy: 0.7703\n",
            "Epoch 85/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3953 - auc_18: 0.8776 - binary_accuracy: 0.7804 - val_loss: 0.4821 - val_auc_18: 0.8333 - val_binary_accuracy: 0.7973\n",
            "Epoch 86/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3835 - auc_18: 0.8856 - binary_accuracy: 0.7939 - val_loss: 0.4768 - val_auc_18: 0.8286 - val_binary_accuracy: 0.7973\n",
            "Epoch 87/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3970 - auc_18: 0.8742 - binary_accuracy: 0.8108 - val_loss: 0.5123 - val_auc_18: 0.8240 - val_binary_accuracy: 0.7973\n",
            "Epoch 88/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3976 - auc_18: 0.8777 - binary_accuracy: 0.7838 - val_loss: 0.5153 - val_auc_18: 0.8261 - val_binary_accuracy: 0.8243\n",
            "Epoch 89/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3977 - auc_18: 0.8731 - binary_accuracy: 0.8007 - val_loss: 0.5290 - val_auc_18: 0.8188 - val_binary_accuracy: 0.7838\n",
            "Epoch 90/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3665 - auc_18: 0.8983 - binary_accuracy: 0.8345 - val_loss: 0.5458 - val_auc_18: 0.8124 - val_binary_accuracy: 0.7973\n",
            "Epoch 91/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.4039 - auc_18: 0.8689 - binary_accuracy: 0.7838 - val_loss: 0.5692 - val_auc_18: 0.8167 - val_binary_accuracy: 0.7568\n",
            "Epoch 92/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3861 - auc_18: 0.8880 - binary_accuracy: 0.8176 - val_loss: 0.5183 - val_auc_18: 0.8278 - val_binary_accuracy: 0.7973\n",
            "Epoch 93/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3891 - auc_18: 0.8753 - binary_accuracy: 0.7736 - val_loss: 0.5470 - val_auc_18: 0.8163 - val_binary_accuracy: 0.7432\n",
            "Epoch 94/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3782 - auc_18: 0.8851 - binary_accuracy: 0.8074 - val_loss: 0.5358 - val_auc_18: 0.8210 - val_binary_accuracy: 0.7703\n",
            "Epoch 95/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3899 - auc_18: 0.8784 - binary_accuracy: 0.7804 - val_loss: 0.5100 - val_auc_18: 0.8099 - val_binary_accuracy: 0.7568\n",
            "Epoch 96/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3953 - auc_18: 0.8741 - binary_accuracy: 0.7838 - val_loss: 0.5762 - val_auc_18: 0.8065 - val_binary_accuracy: 0.7838\n",
            "Epoch 97/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3994 - auc_18: 0.8717 - binary_accuracy: 0.7905 - val_loss: 0.5765 - val_auc_18: 0.8112 - val_binary_accuracy: 0.7703\n",
            "Epoch 98/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3928 - auc_18: 0.8812 - binary_accuracy: 0.8041 - val_loss: 0.5107 - val_auc_18: 0.8137 - val_binary_accuracy: 0.7973\n",
            "Epoch 99/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.4074 - auc_18: 0.8690 - binary_accuracy: 0.7905 - val_loss: 0.5100 - val_auc_18: 0.8265 - val_binary_accuracy: 0.7973\n",
            "Epoch 100/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3792 - auc_18: 0.8807 - binary_accuracy: 0.7905 - val_loss: 0.5693 - val_auc_18: 0.8001 - val_binary_accuracy: 0.7027\n",
            "Epoch 101/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3779 - auc_18: 0.8935 - binary_accuracy: 0.8142 - val_loss: 0.4750 - val_auc_18: 0.8282 - val_binary_accuracy: 0.7838\n",
            "Epoch 102/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3905 - auc_18: 0.8751 - binary_accuracy: 0.7804 - val_loss: 0.5791 - val_auc_18: 0.7997 - val_binary_accuracy: 0.7703\n",
            "Epoch 103/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.4087 - auc_18: 0.8645 - binary_accuracy: 0.7939 - val_loss: 0.5202 - val_auc_18: 0.8099 - val_binary_accuracy: 0.7297\n",
            "Epoch 104/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3810 - auc_18: 0.8921 - binary_accuracy: 0.7973 - val_loss: 0.4671 - val_auc_18: 0.8431 - val_binary_accuracy: 0.8243\n",
            "Epoch 105/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3868 - auc_18: 0.8827 - binary_accuracy: 0.7838 - val_loss: 0.5034 - val_auc_18: 0.8338 - val_binary_accuracy: 0.8243\n",
            "Epoch 106/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3588 - auc_18: 0.9008 - binary_accuracy: 0.8176 - val_loss: 0.4938 - val_auc_18: 0.8218 - val_binary_accuracy: 0.7568\n",
            "Epoch 107/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3924 - auc_18: 0.8801 - binary_accuracy: 0.8007 - val_loss: 0.5597 - val_auc_18: 0.8252 - val_binary_accuracy: 0.7838\n",
            "Epoch 108/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3751 - auc_18: 0.8866 - binary_accuracy: 0.7905 - val_loss: 0.5651 - val_auc_18: 0.8154 - val_binary_accuracy: 0.7973\n",
            "Epoch 109/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3843 - auc_18: 0.8838 - binary_accuracy: 0.7939 - val_loss: 0.5420 - val_auc_18: 0.8150 - val_binary_accuracy: 0.7973\n",
            "Epoch 110/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3954 - auc_18: 0.8784 - binary_accuracy: 0.7973 - val_loss: 0.5432 - val_auc_18: 0.8086 - val_binary_accuracy: 0.7703\n",
            "Epoch 111/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3677 - auc_18: 0.8986 - binary_accuracy: 0.8209 - val_loss: 0.5137 - val_auc_18: 0.8316 - val_binary_accuracy: 0.7973\n",
            "Epoch 112/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3489 - auc_18: 0.9053 - binary_accuracy: 0.8243 - val_loss: 0.5591 - val_auc_18: 0.8133 - val_binary_accuracy: 0.7703\n",
            "Epoch 113/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.3618 - auc_18: 0.8975 - binary_accuracy: 0.7973 - val_loss: 0.5819 - val_auc_18: 0.8107 - val_binary_accuracy: 0.7432\n",
            "Epoch 114/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3714 - auc_18: 0.8861 - binary_accuracy: 0.7905 - val_loss: 0.6052 - val_auc_18: 0.8039 - val_binary_accuracy: 0.7568\n",
            "Epoch 115/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.3653 - auc_18: 0.8969 - binary_accuracy: 0.8108 - val_loss: 0.6320 - val_auc_18: 0.7997 - val_binary_accuracy: 0.7432\n",
            "Epoch 116/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3663 - auc_18: 0.8892 - binary_accuracy: 0.7770 - val_loss: 0.5823 - val_auc_18: 0.8120 - val_binary_accuracy: 0.7973\n",
            "Epoch 117/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3679 - auc_18: 0.8918 - binary_accuracy: 0.8074 - val_loss: 0.5520 - val_auc_18: 0.8142 - val_binary_accuracy: 0.7703\n",
            "Epoch 118/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3635 - auc_18: 0.9048 - binary_accuracy: 0.8108 - val_loss: 0.5872 - val_auc_18: 0.8176 - val_binary_accuracy: 0.8243\n",
            "Epoch 119/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3910 - auc_18: 0.8806 - binary_accuracy: 0.7872 - val_loss: 0.5003 - val_auc_18: 0.8406 - val_binary_accuracy: 0.8243\n",
            "Epoch 120/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3501 - auc_18: 0.9126 - binary_accuracy: 0.8209 - val_loss: 0.5205 - val_auc_18: 0.8470 - val_binary_accuracy: 0.7297\n",
            "Epoch 121/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3476 - auc_18: 0.9096 - binary_accuracy: 0.8243 - val_loss: 0.5211 - val_auc_18: 0.8333 - val_binary_accuracy: 0.7973\n",
            "Epoch 122/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3538 - auc_18: 0.9008 - binary_accuracy: 0.8176 - val_loss: 0.5603 - val_auc_18: 0.8112 - val_binary_accuracy: 0.7973\n",
            "Epoch 123/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3518 - auc_18: 0.9010 - binary_accuracy: 0.8209 - val_loss: 0.5520 - val_auc_18: 0.8065 - val_binary_accuracy: 0.7973\n",
            "Epoch 124/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3363 - auc_18: 0.9171 - binary_accuracy: 0.8311 - val_loss: 0.5376 - val_auc_18: 0.8176 - val_binary_accuracy: 0.7838\n",
            "Epoch 125/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3415 - auc_18: 0.9136 - binary_accuracy: 0.8345 - val_loss: 0.5049 - val_auc_18: 0.8410 - val_binary_accuracy: 0.7703\n",
            "Epoch 126/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3594 - auc_18: 0.9023 - binary_accuracy: 0.8108 - val_loss: 0.4788 - val_auc_18: 0.8525 - val_binary_accuracy: 0.7838\n",
            "Epoch 127/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3271 - auc_18: 0.9204 - binary_accuracy: 0.8243 - val_loss: 0.4860 - val_auc_18: 0.8504 - val_binary_accuracy: 0.8108\n",
            "Epoch 128/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3604 - auc_18: 0.9036 - binary_accuracy: 0.8311 - val_loss: 0.5439 - val_auc_18: 0.8180 - val_binary_accuracy: 0.7703\n",
            "Epoch 129/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3185 - auc_18: 0.9284 - binary_accuracy: 0.8581 - val_loss: 0.5873 - val_auc_18: 0.7933 - val_binary_accuracy: 0.7432\n",
            "Epoch 130/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3332 - auc_18: 0.9151 - binary_accuracy: 0.8209 - val_loss: 0.5584 - val_auc_18: 0.8103 - val_binary_accuracy: 0.7297\n",
            "Epoch 131/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3597 - auc_18: 0.9032 - binary_accuracy: 0.8243 - val_loss: 0.5104 - val_auc_18: 0.8350 - val_binary_accuracy: 0.7703\n",
            "Epoch 132/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3430 - auc_18: 0.9152 - binary_accuracy: 0.8209 - val_loss: 0.5032 - val_auc_18: 0.8389 - val_binary_accuracy: 0.7973\n",
            "Epoch 133/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3603 - auc_18: 0.8976 - binary_accuracy: 0.8209 - val_loss: 0.5025 - val_auc_18: 0.8495 - val_binary_accuracy: 0.8108\n",
            "Epoch 134/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3438 - auc_18: 0.9065 - binary_accuracy: 0.8209 - val_loss: 0.5486 - val_auc_18: 0.8184 - val_binary_accuracy: 0.7297\n",
            "Epoch 135/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3596 - auc_18: 0.8945 - binary_accuracy: 0.8142 - val_loss: 0.5693 - val_auc_18: 0.8120 - val_binary_accuracy: 0.7568\n",
            "Epoch 136/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3213 - auc_18: 0.9225 - binary_accuracy: 0.8345 - val_loss: 0.5546 - val_auc_18: 0.8218 - val_binary_accuracy: 0.7568\n",
            "Epoch 137/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3132 - auc_18: 0.9277 - binary_accuracy: 0.8446 - val_loss: 0.5292 - val_auc_18: 0.8329 - val_binary_accuracy: 0.7973\n",
            "Epoch 138/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3317 - auc_18: 0.9155 - binary_accuracy: 0.8277 - val_loss: 0.5423 - val_auc_18: 0.8240 - val_binary_accuracy: 0.7568\n",
            "Epoch 139/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3339 - auc_18: 0.9131 - binary_accuracy: 0.8345 - val_loss: 0.5111 - val_auc_18: 0.8465 - val_binary_accuracy: 0.7703\n",
            "Epoch 140/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3569 - auc_18: 0.8984 - binary_accuracy: 0.8176 - val_loss: 0.5254 - val_auc_18: 0.8329 - val_binary_accuracy: 0.7432\n",
            "Epoch 141/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3144 - auc_18: 0.9248 - binary_accuracy: 0.8345 - val_loss: 0.5468 - val_auc_18: 0.8312 - val_binary_accuracy: 0.7568\n",
            "Epoch 142/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3318 - auc_18: 0.9162 - binary_accuracy: 0.8412 - val_loss: 0.5622 - val_auc_18: 0.8150 - val_binary_accuracy: 0.7297\n",
            "Epoch 143/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3479 - auc_18: 0.9053 - binary_accuracy: 0.8176 - val_loss: 0.5473 - val_auc_18: 0.8235 - val_binary_accuracy: 0.7568\n",
            "Epoch 144/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3357 - auc_18: 0.9140 - binary_accuracy: 0.8412 - val_loss: 0.5020 - val_auc_18: 0.8483 - val_binary_accuracy: 0.7973\n",
            "Epoch 145/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3350 - auc_18: 0.9188 - binary_accuracy: 0.8412 - val_loss: 0.5468 - val_auc_18: 0.8257 - val_binary_accuracy: 0.7568\n",
            "Epoch 146/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3447 - auc_18: 0.9065 - binary_accuracy: 0.8277 - val_loss: 0.5261 - val_auc_18: 0.8338 - val_binary_accuracy: 0.7568\n",
            "Epoch 147/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3321 - auc_18: 0.9217 - binary_accuracy: 0.8412 - val_loss: 0.5468 - val_auc_18: 0.8214 - val_binary_accuracy: 0.7297\n",
            "Epoch 148/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3343 - auc_18: 0.9202 - binary_accuracy: 0.8615 - val_loss: 0.5302 - val_auc_18: 0.8231 - val_binary_accuracy: 0.7432\n",
            "Epoch 149/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3301 - auc_18: 0.9118 - binary_accuracy: 0.8142 - val_loss: 0.5366 - val_auc_18: 0.8193 - val_binary_accuracy: 0.7568\n",
            "Epoch 150/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3189 - auc_18: 0.9230 - binary_accuracy: 0.8412 - val_loss: 0.5717 - val_auc_18: 0.8137 - val_binary_accuracy: 0.7568\n",
            "Epoch 151/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3281 - auc_18: 0.9194 - binary_accuracy: 0.8412 - val_loss: 0.6128 - val_auc_18: 0.7975 - val_binary_accuracy: 0.7162\n",
            "Epoch 152/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3258 - auc_18: 0.9177 - binary_accuracy: 0.8243 - val_loss: 0.5871 - val_auc_18: 0.8086 - val_binary_accuracy: 0.7703\n",
            "Epoch 153/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3341 - auc_18: 0.9162 - binary_accuracy: 0.8412 - val_loss: 0.5865 - val_auc_18: 0.8150 - val_binary_accuracy: 0.7297\n",
            "Epoch 154/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3286 - auc_18: 0.9163 - binary_accuracy: 0.8311 - val_loss: 0.5369 - val_auc_18: 0.8303 - val_binary_accuracy: 0.7973\n",
            "Epoch 155/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2908 - auc_18: 0.9410 - binary_accuracy: 0.8514 - val_loss: 0.5474 - val_auc_18: 0.8325 - val_binary_accuracy: 0.7838\n",
            "Epoch 156/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3269 - auc_18: 0.9189 - binary_accuracy: 0.8412 - val_loss: 0.5452 - val_auc_18: 0.8346 - val_binary_accuracy: 0.7432\n",
            "Epoch 157/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3131 - auc_18: 0.9296 - binary_accuracy: 0.8547 - val_loss: 0.5364 - val_auc_18: 0.8419 - val_binary_accuracy: 0.8108\n",
            "Epoch 158/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3048 - auc_18: 0.9281 - binary_accuracy: 0.8412 - val_loss: 0.5595 - val_auc_18: 0.8312 - val_binary_accuracy: 0.7703\n",
            "Epoch 159/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3213 - auc_18: 0.9220 - binary_accuracy: 0.8480 - val_loss: 0.5504 - val_auc_18: 0.8376 - val_binary_accuracy: 0.7703\n",
            "Epoch 160/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.3239 - auc_18: 0.9196 - binary_accuracy: 0.8412 - val_loss: 0.5588 - val_auc_18: 0.8269 - val_binary_accuracy: 0.7432\n",
            "Epoch 161/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3135 - auc_18: 0.9222 - binary_accuracy: 0.8378 - val_loss: 0.5779 - val_auc_18: 0.8052 - val_binary_accuracy: 0.7432\n",
            "Epoch 162/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3260 - auc_18: 0.9191 - binary_accuracy: 0.8378 - val_loss: 0.5248 - val_auc_18: 0.8346 - val_binary_accuracy: 0.7703\n",
            "Epoch 163/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3171 - auc_18: 0.9278 - binary_accuracy: 0.8514 - val_loss: 0.5439 - val_auc_18: 0.8142 - val_binary_accuracy: 0.7432\n",
            "Epoch 164/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3082 - auc_18: 0.9307 - binary_accuracy: 0.8345 - val_loss: 0.5174 - val_auc_18: 0.8376 - val_binary_accuracy: 0.7568\n",
            "Epoch 165/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3145 - auc_18: 0.9263 - binary_accuracy: 0.8480 - val_loss: 0.5272 - val_auc_18: 0.8406 - val_binary_accuracy: 0.7703\n",
            "Epoch 166/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3066 - auc_18: 0.9348 - binary_accuracy: 0.8615 - val_loss: 0.5403 - val_auc_18: 0.8355 - val_binary_accuracy: 0.7568\n",
            "Epoch 167/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3083 - auc_18: 0.9263 - binary_accuracy: 0.8345 - val_loss: 0.5411 - val_auc_18: 0.8436 - val_binary_accuracy: 0.7838\n",
            "Epoch 168/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3019 - auc_18: 0.9394 - binary_accuracy: 0.8649 - val_loss: 0.5419 - val_auc_18: 0.8461 - val_binary_accuracy: 0.7432\n",
            "Epoch 169/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2947 - auc_18: 0.9354 - binary_accuracy: 0.8581 - val_loss: 0.5620 - val_auc_18: 0.8393 - val_binary_accuracy: 0.7838\n",
            "Epoch 170/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.2919 - auc_18: 0.9371 - binary_accuracy: 0.8581 - val_loss: 0.5433 - val_auc_18: 0.8384 - val_binary_accuracy: 0.7838\n",
            "Epoch 171/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3158 - auc_18: 0.9246 - binary_accuracy: 0.8311 - val_loss: 0.6015 - val_auc_18: 0.8184 - val_binary_accuracy: 0.7297\n",
            "Epoch 172/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3288 - auc_18: 0.9243 - binary_accuracy: 0.8345 - val_loss: 0.5545 - val_auc_18: 0.8436 - val_binary_accuracy: 0.7838\n",
            "Epoch 173/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2934 - auc_18: 0.9333 - binary_accuracy: 0.8412 - val_loss: 0.5394 - val_auc_18: 0.8457 - val_binary_accuracy: 0.8108\n",
            "Epoch 174/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2963 - auc_18: 0.9332 - binary_accuracy: 0.8412 - val_loss: 0.5421 - val_auc_18: 0.8436 - val_binary_accuracy: 0.7973\n",
            "Epoch 175/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3122 - auc_18: 0.9235 - binary_accuracy: 0.8446 - val_loss: 0.5267 - val_auc_18: 0.8559 - val_binary_accuracy: 0.7838\n",
            "Epoch 176/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3025 - auc_18: 0.9288 - binary_accuracy: 0.8378 - val_loss: 0.5218 - val_auc_18: 0.8585 - val_binary_accuracy: 0.7703\n",
            "Epoch 177/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.3078 - auc_18: 0.9281 - binary_accuracy: 0.8378 - val_loss: 0.5517 - val_auc_18: 0.8478 - val_binary_accuracy: 0.7838\n",
            "Epoch 178/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2957 - auc_18: 0.9355 - binary_accuracy: 0.8581 - val_loss: 0.5429 - val_auc_18: 0.8521 - val_binary_accuracy: 0.8108\n",
            "Epoch 179/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.3046 - auc_18: 0.9328 - binary_accuracy: 0.8547 - val_loss: 0.5395 - val_auc_18: 0.8517 - val_binary_accuracy: 0.7973\n",
            "Epoch 180/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2965 - auc_18: 0.9442 - binary_accuracy: 0.8784 - val_loss: 0.5090 - val_auc_18: 0.8555 - val_binary_accuracy: 0.7973\n",
            "Epoch 181/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2908 - auc_18: 0.9371 - binary_accuracy: 0.8547 - val_loss: 0.4885 - val_auc_18: 0.8653 - val_binary_accuracy: 0.7973\n",
            "Epoch 182/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2933 - auc_18: 0.9414 - binary_accuracy: 0.8581 - val_loss: 0.5263 - val_auc_18: 0.8555 - val_binary_accuracy: 0.7838\n",
            "Epoch 183/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3090 - auc_18: 0.9297 - binary_accuracy: 0.8378 - val_loss: 0.5826 - val_auc_18: 0.8244 - val_binary_accuracy: 0.7568\n",
            "Epoch 184/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2845 - auc_18: 0.9506 - binary_accuracy: 0.9020 - val_loss: 0.5739 - val_auc_18: 0.8423 - val_binary_accuracy: 0.7973\n",
            "Epoch 185/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3055 - auc_18: 0.9274 - binary_accuracy: 0.8446 - val_loss: 0.5405 - val_auc_18: 0.8564 - val_binary_accuracy: 0.7838\n",
            "Epoch 186/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2805 - auc_18: 0.9450 - binary_accuracy: 0.8615 - val_loss: 0.5509 - val_auc_18: 0.8508 - val_binary_accuracy: 0.7838\n",
            "Epoch 187/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3188 - auc_18: 0.9253 - binary_accuracy: 0.8412 - val_loss: 0.5426 - val_auc_18: 0.8410 - val_binary_accuracy: 0.7703\n",
            "Epoch 188/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2912 - auc_18: 0.9325 - binary_accuracy: 0.8446 - val_loss: 0.5385 - val_auc_18: 0.8474 - val_binary_accuracy: 0.7973\n",
            "Epoch 189/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3011 - auc_18: 0.9317 - binary_accuracy: 0.8547 - val_loss: 0.5204 - val_auc_18: 0.8521 - val_binary_accuracy: 0.7973\n",
            "Epoch 190/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.2777 - auc_18: 0.9478 - binary_accuracy: 0.8615 - val_loss: 0.5415 - val_auc_18: 0.8478 - val_binary_accuracy: 0.7973\n",
            "Epoch 191/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2709 - auc_18: 0.9466 - binary_accuracy: 0.8716 - val_loss: 0.5748 - val_auc_18: 0.8491 - val_binary_accuracy: 0.7703\n",
            "Epoch 192/500\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.2858 - auc_18: 0.9362 - binary_accuracy: 0.8682 - val_loss: 0.5410 - val_auc_18: 0.8461 - val_binary_accuracy: 0.7973\n",
            "Epoch 193/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2597 - auc_18: 0.9499 - binary_accuracy: 0.8750 - val_loss: 0.5593 - val_auc_18: 0.8414 - val_binary_accuracy: 0.7703\n",
            "Epoch 194/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2807 - auc_18: 0.9420 - binary_accuracy: 0.8649 - val_loss: 0.5885 - val_auc_18: 0.8444 - val_binary_accuracy: 0.7568\n",
            "Epoch 195/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2942 - auc_18: 0.9406 - binary_accuracy: 0.8716 - val_loss: 0.5766 - val_auc_18: 0.8470 - val_binary_accuracy: 0.7703\n",
            "Epoch 196/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2663 - auc_18: 0.9494 - binary_accuracy: 0.8649 - val_loss: 0.5703 - val_auc_18: 0.8534 - val_binary_accuracy: 0.7568\n",
            "Epoch 197/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.3031 - auc_18: 0.9405 - binary_accuracy: 0.8851 - val_loss: 0.5663 - val_auc_18: 0.8444 - val_binary_accuracy: 0.7568\n",
            "Epoch 198/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2653 - auc_18: 0.9556 - binary_accuracy: 0.9054 - val_loss: 0.5654 - val_auc_18: 0.8376 - val_binary_accuracy: 0.7838\n",
            "Epoch 199/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2727 - auc_18: 0.9468 - binary_accuracy: 0.8818 - val_loss: 0.5958 - val_auc_18: 0.8440 - val_binary_accuracy: 0.7973\n",
            "Epoch 200/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2750 - auc_18: 0.9510 - binary_accuracy: 0.8784 - val_loss: 0.5855 - val_auc_18: 0.8440 - val_binary_accuracy: 0.8108\n",
            "Epoch 201/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2575 - auc_18: 0.9548 - binary_accuracy: 0.8919 - val_loss: 0.5707 - val_auc_18: 0.8444 - val_binary_accuracy: 0.7973\n",
            "Epoch 202/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2761 - auc_18: 0.9518 - binary_accuracy: 0.8784 - val_loss: 0.5625 - val_auc_18: 0.8478 - val_binary_accuracy: 0.8108\n",
            "Epoch 203/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2748 - auc_18: 0.9486 - binary_accuracy: 0.8750 - val_loss: 0.5639 - val_auc_18: 0.8483 - val_binary_accuracy: 0.8108\n",
            "Epoch 204/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2817 - auc_18: 0.9433 - binary_accuracy: 0.8682 - val_loss: 0.5881 - val_auc_18: 0.8346 - val_binary_accuracy: 0.7703\n",
            "Epoch 205/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2800 - auc_18: 0.9446 - binary_accuracy: 0.8750 - val_loss: 0.5817 - val_auc_18: 0.8393 - val_binary_accuracy: 0.7838\n",
            "Epoch 206/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2553 - auc_18: 0.9542 - binary_accuracy: 0.8851 - val_loss: 0.6146 - val_auc_18: 0.8427 - val_binary_accuracy: 0.7838\n",
            "Epoch 207/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2647 - auc_18: 0.9482 - binary_accuracy: 0.8682 - val_loss: 0.5870 - val_auc_18: 0.8431 - val_binary_accuracy: 0.7973\n",
            "Epoch 208/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2520 - auc_18: 0.9522 - binary_accuracy: 0.8919 - val_loss: 0.5835 - val_auc_18: 0.8376 - val_binary_accuracy: 0.7568\n",
            "Epoch 209/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2683 - auc_18: 0.9466 - binary_accuracy: 0.8818 - val_loss: 0.5541 - val_auc_18: 0.8470 - val_binary_accuracy: 0.7973\n",
            "Epoch 210/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2481 - auc_18: 0.9539 - binary_accuracy: 0.8885 - val_loss: 0.6103 - val_auc_18: 0.8423 - val_binary_accuracy: 0.7568\n",
            "Epoch 211/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2505 - auc_18: 0.9604 - binary_accuracy: 0.8851 - val_loss: 0.5908 - val_auc_18: 0.8431 - val_binary_accuracy: 0.7838\n",
            "Epoch 212/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2365 - auc_18: 0.9582 - binary_accuracy: 0.8716 - val_loss: 0.5775 - val_auc_18: 0.8461 - val_binary_accuracy: 0.7838\n",
            "Epoch 213/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2386 - auc_18: 0.9627 - binary_accuracy: 0.8986 - val_loss: 0.5775 - val_auc_18: 0.8512 - val_binary_accuracy: 0.7703\n",
            "Epoch 214/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2564 - auc_18: 0.9539 - binary_accuracy: 0.8851 - val_loss: 0.5708 - val_auc_18: 0.8470 - val_binary_accuracy: 0.7973\n",
            "Epoch 215/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2508 - auc_18: 0.9591 - binary_accuracy: 0.8851 - val_loss: 0.5646 - val_auc_18: 0.8517 - val_binary_accuracy: 0.7838\n",
            "Epoch 216/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2465 - auc_18: 0.9598 - binary_accuracy: 0.9020 - val_loss: 0.6228 - val_auc_18: 0.8414 - val_binary_accuracy: 0.7973\n",
            "Epoch 217/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2230 - auc_18: 0.9706 - binary_accuracy: 0.9054 - val_loss: 0.6326 - val_auc_18: 0.8521 - val_binary_accuracy: 0.8243\n",
            "Epoch 218/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3051 - auc_18: 0.9305 - binary_accuracy: 0.8547 - val_loss: 0.5917 - val_auc_18: 0.8414 - val_binary_accuracy: 0.7838\n",
            "Epoch 219/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2838 - auc_18: 0.9442 - binary_accuracy: 0.8784 - val_loss: 0.5615 - val_auc_18: 0.8470 - val_binary_accuracy: 0.7703\n",
            "Epoch 220/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2332 - auc_18: 0.9681 - binary_accuracy: 0.9054 - val_loss: 0.5948 - val_auc_18: 0.8406 - val_binary_accuracy: 0.7838\n",
            "Epoch 221/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2696 - auc_18: 0.9550 - binary_accuracy: 0.8682 - val_loss: 0.6397 - val_auc_18: 0.8124 - val_binary_accuracy: 0.7432\n",
            "Epoch 222/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2717 - auc_18: 0.9473 - binary_accuracy: 0.8784 - val_loss: 0.6282 - val_auc_18: 0.8180 - val_binary_accuracy: 0.7568\n",
            "Epoch 223/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2853 - auc_18: 0.9460 - binary_accuracy: 0.8986 - val_loss: 0.5914 - val_auc_18: 0.8316 - val_binary_accuracy: 0.7703\n",
            "Epoch 224/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2492 - auc_18: 0.9602 - binary_accuracy: 0.8750 - val_loss: 0.6109 - val_auc_18: 0.8299 - val_binary_accuracy: 0.7568\n",
            "Epoch 225/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2453 - auc_18: 0.9592 - binary_accuracy: 0.8919 - val_loss: 0.6272 - val_auc_18: 0.8112 - val_binary_accuracy: 0.7297\n",
            "Epoch 226/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2442 - auc_18: 0.9628 - binary_accuracy: 0.9088 - val_loss: 0.6219 - val_auc_18: 0.8282 - val_binary_accuracy: 0.7703\n",
            "Epoch 227/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2300 - auc_18: 0.9650 - binary_accuracy: 0.8851 - val_loss: 0.6269 - val_auc_18: 0.8342 - val_binary_accuracy: 0.7432\n",
            "Epoch 228/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2292 - auc_18: 0.9720 - binary_accuracy: 0.9088 - val_loss: 0.6110 - val_auc_18: 0.8321 - val_binary_accuracy: 0.7973\n",
            "Epoch 229/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2284 - auc_18: 0.9681 - binary_accuracy: 0.8953 - val_loss: 0.6066 - val_auc_18: 0.8325 - val_binary_accuracy: 0.7973\n",
            "Epoch 230/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2319 - auc_18: 0.9687 - binary_accuracy: 0.8919 - val_loss: 0.6342 - val_auc_18: 0.8333 - val_binary_accuracy: 0.7838\n",
            "Epoch 231/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2582 - auc_18: 0.9557 - binary_accuracy: 0.8682 - val_loss: 0.6441 - val_auc_18: 0.8338 - val_binary_accuracy: 0.7838\n",
            "Epoch 232/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2326 - auc_18: 0.9695 - binary_accuracy: 0.9020 - val_loss: 0.6665 - val_auc_18: 0.8214 - val_binary_accuracy: 0.7568\n",
            "Epoch 233/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2727 - auc_18: 0.9458 - binary_accuracy: 0.8784 - val_loss: 0.6231 - val_auc_18: 0.8286 - val_binary_accuracy: 0.7703\n",
            "Epoch 234/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2552 - auc_18: 0.9602 - binary_accuracy: 0.8885 - val_loss: 0.6240 - val_auc_18: 0.8329 - val_binary_accuracy: 0.7973\n",
            "Epoch 235/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2345 - auc_18: 0.9631 - binary_accuracy: 0.8986 - val_loss: 0.6452 - val_auc_18: 0.8278 - val_binary_accuracy: 0.7838\n",
            "Epoch 236/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2642 - auc_18: 0.9538 - binary_accuracy: 0.8851 - val_loss: 0.6645 - val_auc_18: 0.8193 - val_binary_accuracy: 0.7297\n",
            "Epoch 237/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2797 - auc_18: 0.9416 - binary_accuracy: 0.8615 - val_loss: 0.6345 - val_auc_18: 0.8359 - val_binary_accuracy: 0.8108\n",
            "Epoch 238/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2579 - auc_18: 0.9547 - binary_accuracy: 0.8885 - val_loss: 0.5740 - val_auc_18: 0.8448 - val_binary_accuracy: 0.7973\n",
            "Epoch 239/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2369 - auc_18: 0.9616 - binary_accuracy: 0.8919 - val_loss: 0.5587 - val_auc_18: 0.8470 - val_binary_accuracy: 0.7703\n",
            "Epoch 240/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2889 - auc_18: 0.9431 - binary_accuracy: 0.8716 - val_loss: 0.5530 - val_auc_18: 0.8487 - val_binary_accuracy: 0.7703\n",
            "Epoch 241/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2062 - auc_18: 0.9764 - binary_accuracy: 0.9088 - val_loss: 0.6056 - val_auc_18: 0.8402 - val_binary_accuracy: 0.7973\n",
            "Epoch 242/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2481 - auc_18: 0.9578 - binary_accuracy: 0.8986 - val_loss: 0.6291 - val_auc_18: 0.8393 - val_binary_accuracy: 0.7838\n",
            "Epoch 243/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2274 - auc_18: 0.9634 - binary_accuracy: 0.9088 - val_loss: 0.6403 - val_auc_18: 0.8372 - val_binary_accuracy: 0.7973\n",
            "Epoch 244/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2397 - auc_18: 0.9622 - binary_accuracy: 0.9020 - val_loss: 0.6164 - val_auc_18: 0.8402 - val_binary_accuracy: 0.7838\n",
            "Epoch 245/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2311 - auc_18: 0.9683 - binary_accuracy: 0.9020 - val_loss: 0.6161 - val_auc_18: 0.8274 - val_binary_accuracy: 0.7973\n",
            "Epoch 246/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2326 - auc_18: 0.9642 - binary_accuracy: 0.9054 - val_loss: 0.6231 - val_auc_18: 0.8308 - val_binary_accuracy: 0.7432\n",
            "Epoch 247/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.2468 - auc_18: 0.9599 - binary_accuracy: 0.9054 - val_loss: 0.6461 - val_auc_18: 0.8214 - val_binary_accuracy: 0.7432\n",
            "Epoch 248/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2315 - auc_18: 0.9653 - binary_accuracy: 0.9189 - val_loss: 0.6115 - val_auc_18: 0.8329 - val_binary_accuracy: 0.8108\n",
            "Epoch 249/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2391 - auc_18: 0.9617 - binary_accuracy: 0.9020 - val_loss: 0.6077 - val_auc_18: 0.8350 - val_binary_accuracy: 0.7973\n",
            "Epoch 250/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2141 - auc_18: 0.9692 - binary_accuracy: 0.9122 - val_loss: 0.6146 - val_auc_18: 0.8402 - val_binary_accuracy: 0.7973\n",
            "Epoch 251/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2041 - auc_18: 0.9721 - binary_accuracy: 0.9122 - val_loss: 0.6191 - val_auc_18: 0.8389 - val_binary_accuracy: 0.7973\n",
            "Epoch 252/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2351 - auc_18: 0.9622 - binary_accuracy: 0.8986 - val_loss: 0.6092 - val_auc_18: 0.8389 - val_binary_accuracy: 0.8108\n",
            "Epoch 253/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2840 - auc_18: 0.9436 - binary_accuracy: 0.8818 - val_loss: 0.6111 - val_auc_18: 0.8389 - val_binary_accuracy: 0.8243\n",
            "Epoch 254/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2168 - auc_18: 0.9746 - binary_accuracy: 0.9054 - val_loss: 0.6599 - val_auc_18: 0.8295 - val_binary_accuracy: 0.7432\n",
            "Epoch 255/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2189 - auc_18: 0.9684 - binary_accuracy: 0.9122 - val_loss: 0.6395 - val_auc_18: 0.8303 - val_binary_accuracy: 0.7838\n",
            "Epoch 256/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2642 - auc_18: 0.9499 - binary_accuracy: 0.8919 - val_loss: 0.6356 - val_auc_18: 0.8372 - val_binary_accuracy: 0.7297\n",
            "Epoch 257/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2253 - auc_18: 0.9667 - binary_accuracy: 0.9020 - val_loss: 0.6197 - val_auc_18: 0.8257 - val_binary_accuracy: 0.8108\n",
            "Epoch 258/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2454 - auc_18: 0.9577 - binary_accuracy: 0.8885 - val_loss: 0.6288 - val_auc_18: 0.8384 - val_binary_accuracy: 0.7703\n",
            "Epoch 259/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2300 - auc_18: 0.9655 - binary_accuracy: 0.8986 - val_loss: 0.6371 - val_auc_18: 0.8380 - val_binary_accuracy: 0.7973\n",
            "Epoch 260/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2447 - auc_18: 0.9578 - binary_accuracy: 0.8953 - val_loss: 0.6339 - val_auc_18: 0.8436 - val_binary_accuracy: 0.8378\n",
            "Epoch 261/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2120 - auc_18: 0.9735 - binary_accuracy: 0.9257 - val_loss: 0.6607 - val_auc_18: 0.8342 - val_binary_accuracy: 0.7838\n",
            "Epoch 262/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2275 - auc_18: 0.9635 - binary_accuracy: 0.9020 - val_loss: 0.6550 - val_auc_18: 0.8342 - val_binary_accuracy: 0.7973\n",
            "Epoch 263/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2163 - auc_18: 0.9658 - binary_accuracy: 0.9020 - val_loss: 0.6344 - val_auc_18: 0.8367 - val_binary_accuracy: 0.7973\n",
            "Epoch 264/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2481 - auc_18: 0.9606 - binary_accuracy: 0.8986 - val_loss: 0.6351 - val_auc_18: 0.8380 - val_binary_accuracy: 0.7973\n",
            "Epoch 265/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2171 - auc_18: 0.9732 - binary_accuracy: 0.9189 - val_loss: 0.6414 - val_auc_18: 0.8321 - val_binary_accuracy: 0.7568\n",
            "Epoch 266/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2004 - auc_18: 0.9762 - binary_accuracy: 0.9257 - val_loss: 0.6521 - val_auc_18: 0.8363 - val_binary_accuracy: 0.8108\n",
            "Epoch 267/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2311 - auc_18: 0.9660 - binary_accuracy: 0.9054 - val_loss: 0.6408 - val_auc_18: 0.8359 - val_binary_accuracy: 0.7838\n",
            "Epoch 268/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2078 - auc_18: 0.9722 - binary_accuracy: 0.9155 - val_loss: 0.6605 - val_auc_18: 0.8350 - val_binary_accuracy: 0.8108\n",
            "Epoch 269/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2121 - auc_18: 0.9716 - binary_accuracy: 0.9189 - val_loss: 0.6655 - val_auc_18: 0.8333 - val_binary_accuracy: 0.7838\n",
            "Epoch 270/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.2041 - auc_18: 0.9733 - binary_accuracy: 0.9291 - val_loss: 0.6437 - val_auc_18: 0.8342 - val_binary_accuracy: 0.8378\n",
            "Epoch 271/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2006 - auc_18: 0.9754 - binary_accuracy: 0.9257 - val_loss: 0.6593 - val_auc_18: 0.8303 - val_binary_accuracy: 0.7703\n",
            "Epoch 272/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1991 - auc_18: 0.9788 - binary_accuracy: 0.9257 - val_loss: 0.6666 - val_auc_18: 0.8321 - val_binary_accuracy: 0.7838\n",
            "Epoch 273/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2093 - auc_18: 0.9724 - binary_accuracy: 0.9223 - val_loss: 0.6365 - val_auc_18: 0.8457 - val_binary_accuracy: 0.7973\n",
            "Epoch 274/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1968 - auc_18: 0.9735 - binary_accuracy: 0.9189 - val_loss: 0.6406 - val_auc_18: 0.8453 - val_binary_accuracy: 0.8243\n",
            "Epoch 275/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2136 - auc_18: 0.9690 - binary_accuracy: 0.9088 - val_loss: 0.6359 - val_auc_18: 0.8448 - val_binary_accuracy: 0.7973\n",
            "Epoch 276/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2332 - auc_18: 0.9624 - binary_accuracy: 0.8986 - val_loss: 0.6256 - val_auc_18: 0.8431 - val_binary_accuracy: 0.8108\n",
            "Epoch 277/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1704 - auc_18: 0.9850 - binary_accuracy: 0.9324 - val_loss: 0.6230 - val_auc_18: 0.8500 - val_binary_accuracy: 0.7838\n",
            "Epoch 278/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2053 - auc_18: 0.9707 - binary_accuracy: 0.9122 - val_loss: 0.6336 - val_auc_18: 0.8393 - val_binary_accuracy: 0.7973\n",
            "Epoch 279/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2110 - auc_18: 0.9712 - binary_accuracy: 0.9088 - val_loss: 0.6620 - val_auc_18: 0.8329 - val_binary_accuracy: 0.7973\n",
            "Epoch 280/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2009 - auc_18: 0.9722 - binary_accuracy: 0.9122 - val_loss: 0.6781 - val_auc_18: 0.8282 - val_binary_accuracy: 0.7703\n",
            "Epoch 281/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2170 - auc_18: 0.9671 - binary_accuracy: 0.9189 - val_loss: 0.6547 - val_auc_18: 0.8380 - val_binary_accuracy: 0.7838\n",
            "Epoch 282/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1863 - auc_18: 0.9783 - binary_accuracy: 0.9155 - val_loss: 0.6459 - val_auc_18: 0.8325 - val_binary_accuracy: 0.7973\n",
            "Epoch 283/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1886 - auc_18: 0.9770 - binary_accuracy: 0.9324 - val_loss: 0.6495 - val_auc_18: 0.8325 - val_binary_accuracy: 0.7838\n",
            "Epoch 284/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2065 - auc_18: 0.9720 - binary_accuracy: 0.9291 - val_loss: 0.6716 - val_auc_18: 0.8265 - val_binary_accuracy: 0.8108\n",
            "Epoch 285/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1977 - auc_18: 0.9756 - binary_accuracy: 0.9088 - val_loss: 0.6869 - val_auc_18: 0.8167 - val_binary_accuracy: 0.7703\n",
            "Epoch 286/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1972 - auc_18: 0.9740 - binary_accuracy: 0.9122 - val_loss: 0.6445 - val_auc_18: 0.8282 - val_binary_accuracy: 0.7973\n",
            "Epoch 287/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2547 - auc_18: 0.9516 - binary_accuracy: 0.8986 - val_loss: 0.6619 - val_auc_18: 0.8282 - val_binary_accuracy: 0.7703\n",
            "Epoch 288/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2295 - auc_18: 0.9624 - binary_accuracy: 0.9189 - val_loss: 0.6961 - val_auc_18: 0.7894 - val_binary_accuracy: 0.7162\n",
            "Epoch 289/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.2191 - auc_18: 0.9657 - binary_accuracy: 0.9020 - val_loss: 0.6439 - val_auc_18: 0.8248 - val_binary_accuracy: 0.7703\n",
            "Epoch 290/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1739 - auc_18: 0.9843 - binary_accuracy: 0.9291 - val_loss: 0.6532 - val_auc_18: 0.8261 - val_binary_accuracy: 0.7973\n",
            "Epoch 291/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1989 - auc_18: 0.9747 - binary_accuracy: 0.9122 - val_loss: 0.7021 - val_auc_18: 0.8082 - val_binary_accuracy: 0.7703\n",
            "Epoch 292/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1858 - auc_18: 0.9791 - binary_accuracy: 0.9358 - val_loss: 0.6473 - val_auc_18: 0.8265 - val_binary_accuracy: 0.7838\n",
            "Epoch 293/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2180 - auc_18: 0.9702 - binary_accuracy: 0.9054 - val_loss: 0.6398 - val_auc_18: 0.8274 - val_binary_accuracy: 0.7703\n",
            "Epoch 294/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1853 - auc_18: 0.9777 - binary_accuracy: 0.9223 - val_loss: 0.6246 - val_auc_18: 0.8376 - val_binary_accuracy: 0.7703\n",
            "Epoch 295/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1724 - auc_18: 0.9832 - binary_accuracy: 0.9291 - val_loss: 0.6402 - val_auc_18: 0.8252 - val_binary_accuracy: 0.7838\n",
            "Epoch 296/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1968 - auc_18: 0.9735 - binary_accuracy: 0.9257 - val_loss: 0.6635 - val_auc_18: 0.8240 - val_binary_accuracy: 0.7838\n",
            "Epoch 297/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1863 - auc_18: 0.9770 - binary_accuracy: 0.9155 - val_loss: 0.6953 - val_auc_18: 0.8180 - val_binary_accuracy: 0.7838\n",
            "Epoch 298/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1724 - auc_18: 0.9833 - binary_accuracy: 0.9223 - val_loss: 0.6635 - val_auc_18: 0.8269 - val_binary_accuracy: 0.7432\n",
            "Epoch 299/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1768 - auc_18: 0.9806 - binary_accuracy: 0.9223 - val_loss: 0.6263 - val_auc_18: 0.8453 - val_binary_accuracy: 0.7838\n",
            "Epoch 300/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2167 - auc_18: 0.9676 - binary_accuracy: 0.9020 - val_loss: 0.6600 - val_auc_18: 0.8274 - val_binary_accuracy: 0.7432\n",
            "Epoch 301/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2327 - auc_18: 0.9653 - binary_accuracy: 0.8818 - val_loss: 0.6624 - val_auc_18: 0.8325 - val_binary_accuracy: 0.7838\n",
            "Epoch 302/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2104 - auc_18: 0.9741 - binary_accuracy: 0.9020 - val_loss: 0.6776 - val_auc_18: 0.8116 - val_binary_accuracy: 0.7297\n",
            "Epoch 303/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2532 - auc_18: 0.9560 - binary_accuracy: 0.9054 - val_loss: 0.6719 - val_auc_18: 0.8124 - val_binary_accuracy: 0.7703\n",
            "Epoch 304/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2380 - auc_18: 0.9607 - binary_accuracy: 0.9122 - val_loss: 0.6394 - val_auc_18: 0.8380 - val_binary_accuracy: 0.8108\n",
            "Epoch 305/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1871 - auc_18: 0.9779 - binary_accuracy: 0.9189 - val_loss: 0.6436 - val_auc_18: 0.8252 - val_binary_accuracy: 0.7703\n",
            "Epoch 306/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1912 - auc_18: 0.9755 - binary_accuracy: 0.9155 - val_loss: 0.6340 - val_auc_18: 0.8210 - val_binary_accuracy: 0.7838\n",
            "Epoch 307/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1859 - auc_18: 0.9773 - binary_accuracy: 0.9291 - val_loss: 0.6540 - val_auc_18: 0.8231 - val_binary_accuracy: 0.7703\n",
            "Epoch 308/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1793 - auc_18: 0.9817 - binary_accuracy: 0.9291 - val_loss: 0.6788 - val_auc_18: 0.8078 - val_binary_accuracy: 0.7297\n",
            "Epoch 309/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1619 - auc_18: 0.9878 - binary_accuracy: 0.9493 - val_loss: 0.6648 - val_auc_18: 0.8214 - val_binary_accuracy: 0.7838\n",
            "Epoch 310/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1686 - auc_18: 0.9823 - binary_accuracy: 0.9358 - val_loss: 0.6490 - val_auc_18: 0.8248 - val_binary_accuracy: 0.7568\n",
            "Epoch 311/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.2005 - auc_18: 0.9716 - binary_accuracy: 0.9088 - val_loss: 0.6318 - val_auc_18: 0.8244 - val_binary_accuracy: 0.7838\n",
            "Epoch 312/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1817 - auc_18: 0.9790 - binary_accuracy: 0.9155 - val_loss: 0.6517 - val_auc_18: 0.8133 - val_binary_accuracy: 0.7568\n",
            "Epoch 313/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1746 - auc_18: 0.9821 - binary_accuracy: 0.9426 - val_loss: 0.6204 - val_auc_18: 0.8342 - val_binary_accuracy: 0.7703\n",
            "Epoch 314/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1745 - auc_18: 0.9800 - binary_accuracy: 0.9257 - val_loss: 0.6146 - val_auc_18: 0.8389 - val_binary_accuracy: 0.7973\n",
            "Epoch 315/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1864 - auc_18: 0.9776 - binary_accuracy: 0.9392 - val_loss: 0.6778 - val_auc_18: 0.8124 - val_binary_accuracy: 0.7297\n",
            "Epoch 316/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1927 - auc_18: 0.9771 - binary_accuracy: 0.9291 - val_loss: 0.6944 - val_auc_18: 0.8154 - val_binary_accuracy: 0.7568\n",
            "Epoch 317/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1814 - auc_18: 0.9793 - binary_accuracy: 0.9257 - val_loss: 0.6788 - val_auc_18: 0.8235 - val_binary_accuracy: 0.7568\n",
            "Epoch 318/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1654 - auc_18: 0.9829 - binary_accuracy: 0.9527 - val_loss: 0.6387 - val_auc_18: 0.8372 - val_binary_accuracy: 0.7838\n",
            "Epoch 319/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1703 - auc_18: 0.9819 - binary_accuracy: 0.9358 - val_loss: 0.6403 - val_auc_18: 0.8342 - val_binary_accuracy: 0.7973\n",
            "Epoch 320/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1587 - auc_18: 0.9853 - binary_accuracy: 0.9358 - val_loss: 0.6602 - val_auc_18: 0.8205 - val_binary_accuracy: 0.7703\n",
            "Epoch 321/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1644 - auc_18: 0.9829 - binary_accuracy: 0.9493 - val_loss: 0.6606 - val_auc_18: 0.8235 - val_binary_accuracy: 0.7838\n",
            "Epoch 322/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1404 - auc_18: 0.9888 - binary_accuracy: 0.9561 - val_loss: 0.6497 - val_auc_18: 0.8359 - val_binary_accuracy: 0.7838\n",
            "Epoch 323/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1592 - auc_18: 0.9857 - binary_accuracy: 0.9561 - val_loss: 0.6628 - val_auc_18: 0.8329 - val_binary_accuracy: 0.7973\n",
            "Epoch 324/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1613 - auc_18: 0.9841 - binary_accuracy: 0.9358 - val_loss: 0.6613 - val_auc_18: 0.8414 - val_binary_accuracy: 0.8108\n",
            "Epoch 325/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1435 - auc_18: 0.9885 - binary_accuracy: 0.9459 - val_loss: 0.6796 - val_auc_18: 0.8384 - val_binary_accuracy: 0.7703\n",
            "Epoch 326/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1931 - auc_18: 0.9756 - binary_accuracy: 0.9257 - val_loss: 0.7056 - val_auc_18: 0.8240 - val_binary_accuracy: 0.7703\n",
            "Epoch 327/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1870 - auc_18: 0.9825 - binary_accuracy: 0.9189 - val_loss: 0.6708 - val_auc_18: 0.8402 - val_binary_accuracy: 0.7973\n",
            "Epoch 328/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1947 - auc_18: 0.9765 - binary_accuracy: 0.9155 - val_loss: 0.6502 - val_auc_18: 0.8478 - val_binary_accuracy: 0.8108\n",
            "Epoch 329/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2632 - auc_18: 0.9562 - binary_accuracy: 0.9020 - val_loss: 0.7474 - val_auc_18: 0.8129 - val_binary_accuracy: 0.7568\n",
            "Epoch 330/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2565 - auc_18: 0.9528 - binary_accuracy: 0.9088 - val_loss: 0.6424 - val_auc_18: 0.8248 - val_binary_accuracy: 0.8108\n",
            "Epoch 331/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2050 - auc_18: 0.9710 - binary_accuracy: 0.9155 - val_loss: 0.6937 - val_auc_18: 0.8180 - val_binary_accuracy: 0.7838\n",
            "Epoch 332/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1668 - auc_18: 0.9819 - binary_accuracy: 0.9459 - val_loss: 0.7115 - val_auc_18: 0.8214 - val_binary_accuracy: 0.7703\n",
            "Epoch 333/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2155 - auc_18: 0.9697 - binary_accuracy: 0.9223 - val_loss: 0.6665 - val_auc_18: 0.8274 - val_binary_accuracy: 0.7973\n",
            "Epoch 334/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1737 - auc_18: 0.9807 - binary_accuracy: 0.9459 - val_loss: 0.6501 - val_auc_18: 0.8142 - val_binary_accuracy: 0.7703\n",
            "Epoch 335/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1786 - auc_18: 0.9786 - binary_accuracy: 0.9257 - val_loss: 0.6725 - val_auc_18: 0.8231 - val_binary_accuracy: 0.7973\n",
            "Epoch 336/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1667 - auc_18: 0.9814 - binary_accuracy: 0.9223 - val_loss: 0.6685 - val_auc_18: 0.8321 - val_binary_accuracy: 0.8108\n",
            "Epoch 337/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1535 - auc_18: 0.9863 - binary_accuracy: 0.9493 - val_loss: 0.6654 - val_auc_18: 0.8393 - val_binary_accuracy: 0.7973\n",
            "Epoch 338/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1560 - auc_18: 0.9853 - binary_accuracy: 0.9459 - val_loss: 0.6804 - val_auc_18: 0.8338 - val_binary_accuracy: 0.7703\n",
            "Epoch 339/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1636 - auc_18: 0.9829 - binary_accuracy: 0.9426 - val_loss: 0.6809 - val_auc_18: 0.8333 - val_binary_accuracy: 0.7973\n",
            "Epoch 340/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1357 - auc_18: 0.9921 - binary_accuracy: 0.9561 - val_loss: 0.6413 - val_auc_18: 0.8397 - val_binary_accuracy: 0.7703\n",
            "Epoch 341/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1829 - auc_18: 0.9787 - binary_accuracy: 0.9155 - val_loss: 0.6672 - val_auc_18: 0.8342 - val_binary_accuracy: 0.7568\n",
            "Epoch 342/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1385 - auc_18: 0.9884 - binary_accuracy: 0.9493 - val_loss: 0.6683 - val_auc_18: 0.8376 - val_binary_accuracy: 0.7568\n",
            "Epoch 343/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1379 - auc_18: 0.9889 - binary_accuracy: 0.9358 - val_loss: 0.6787 - val_auc_18: 0.8244 - val_binary_accuracy: 0.7568\n",
            "Epoch 344/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1369 - auc_18: 0.9893 - binary_accuracy: 0.9561 - val_loss: 0.6888 - val_auc_18: 0.8286 - val_binary_accuracy: 0.7973\n",
            "Epoch 345/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1695 - auc_18: 0.9793 - binary_accuracy: 0.9223 - val_loss: 0.7305 - val_auc_18: 0.8210 - val_binary_accuracy: 0.7703\n",
            "Epoch 346/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1580 - auc_18: 0.9843 - binary_accuracy: 0.9426 - val_loss: 0.6905 - val_auc_18: 0.8286 - val_binary_accuracy: 0.8108\n",
            "Epoch 347/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1704 - auc_18: 0.9803 - binary_accuracy: 0.9223 - val_loss: 0.6925 - val_auc_18: 0.8257 - val_binary_accuracy: 0.7703\n",
            "Epoch 348/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1138 - auc_18: 0.9938 - binary_accuracy: 0.9662 - val_loss: 0.6733 - val_auc_18: 0.8261 - val_binary_accuracy: 0.7703\n",
            "Epoch 349/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1591 - auc_18: 0.9836 - binary_accuracy: 0.9459 - val_loss: 0.6916 - val_auc_18: 0.8329 - val_binary_accuracy: 0.7838\n",
            "Epoch 350/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1582 - auc_18: 0.9840 - binary_accuracy: 0.9459 - val_loss: 0.6814 - val_auc_18: 0.8274 - val_binary_accuracy: 0.7838\n",
            "Epoch 351/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1372 - auc_18: 0.9868 - binary_accuracy: 0.9628 - val_loss: 0.6876 - val_auc_18: 0.8321 - val_binary_accuracy: 0.7973\n",
            "Epoch 352/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1358 - auc_18: 0.9869 - binary_accuracy: 0.9561 - val_loss: 0.6729 - val_auc_18: 0.8350 - val_binary_accuracy: 0.7973\n",
            "Epoch 353/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1403 - auc_18: 0.9856 - binary_accuracy: 0.9595 - val_loss: 0.6585 - val_auc_18: 0.8333 - val_binary_accuracy: 0.7703\n",
            "Epoch 354/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1472 - auc_18: 0.9856 - binary_accuracy: 0.9595 - val_loss: 0.7280 - val_auc_18: 0.8065 - val_binary_accuracy: 0.7568\n",
            "Epoch 355/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1607 - auc_18: 0.9838 - binary_accuracy: 0.9358 - val_loss: 0.7139 - val_auc_18: 0.7980 - val_binary_accuracy: 0.7297\n",
            "Epoch 356/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1500 - auc_18: 0.9867 - binary_accuracy: 0.9595 - val_loss: 0.6679 - val_auc_18: 0.8142 - val_binary_accuracy: 0.7432\n",
            "Epoch 357/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1093 - auc_18: 0.9952 - binary_accuracy: 0.9730 - val_loss: 0.6737 - val_auc_18: 0.8244 - val_binary_accuracy: 0.7973\n",
            "Epoch 358/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1584 - auc_18: 0.9827 - binary_accuracy: 0.9459 - val_loss: 0.6706 - val_auc_18: 0.8176 - val_binary_accuracy: 0.7703\n",
            "Epoch 359/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1445 - auc_18: 0.9885 - binary_accuracy: 0.9459 - val_loss: 0.6625 - val_auc_18: 0.8142 - val_binary_accuracy: 0.7703\n",
            "Epoch 360/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1686 - auc_18: 0.9805 - binary_accuracy: 0.9358 - val_loss: 0.6947 - val_auc_18: 0.8167 - val_binary_accuracy: 0.7432\n",
            "Epoch 361/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1469 - auc_18: 0.9870 - binary_accuracy: 0.9527 - val_loss: 0.7051 - val_auc_18: 0.8150 - val_binary_accuracy: 0.7838\n",
            "Epoch 362/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1458 - auc_18: 0.9873 - binary_accuracy: 0.9493 - val_loss: 0.6917 - val_auc_18: 0.8201 - val_binary_accuracy: 0.7973\n",
            "Epoch 363/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1746 - auc_18: 0.9788 - binary_accuracy: 0.9223 - val_loss: 0.7211 - val_auc_18: 0.8184 - val_binary_accuracy: 0.7973\n",
            "Epoch 364/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1371 - auc_18: 0.9892 - binary_accuracy: 0.9426 - val_loss: 0.7323 - val_auc_18: 0.8231 - val_binary_accuracy: 0.7973\n",
            "Epoch 365/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1203 - auc_18: 0.9917 - binary_accuracy: 0.9628 - val_loss: 0.7226 - val_auc_18: 0.8214 - val_binary_accuracy: 0.7297\n",
            "Epoch 366/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1482 - auc_18: 0.9877 - binary_accuracy: 0.9426 - val_loss: 0.7337 - val_auc_18: 0.8308 - val_binary_accuracy: 0.7703\n",
            "Epoch 367/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1264 - auc_18: 0.9909 - binary_accuracy: 0.9595 - val_loss: 0.7016 - val_auc_18: 0.8197 - val_binary_accuracy: 0.7703\n",
            "Epoch 368/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1442 - auc_18: 0.9878 - binary_accuracy: 0.9459 - val_loss: 0.6643 - val_auc_18: 0.8278 - val_binary_accuracy: 0.7703\n",
            "Epoch 369/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2002 - auc_18: 0.9706 - binary_accuracy: 0.9291 - val_loss: 0.6737 - val_auc_18: 0.8308 - val_binary_accuracy: 0.7838\n",
            "Epoch 370/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1260 - auc_18: 0.9922 - binary_accuracy: 0.9493 - val_loss: 0.6608 - val_auc_18: 0.8376 - val_binary_accuracy: 0.7973\n",
            "Epoch 371/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1185 - auc_18: 0.9925 - binary_accuracy: 0.9628 - val_loss: 0.7170 - val_auc_18: 0.8372 - val_binary_accuracy: 0.7838\n",
            "Epoch 372/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1760 - auc_18: 0.9758 - binary_accuracy: 0.9459 - val_loss: 0.6929 - val_auc_18: 0.8359 - val_binary_accuracy: 0.7838\n",
            "Epoch 373/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1120 - auc_18: 0.9943 - binary_accuracy: 0.9527 - val_loss: 0.6615 - val_auc_18: 0.8359 - val_binary_accuracy: 0.7973\n",
            "Epoch 374/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1194 - auc_18: 0.9911 - binary_accuracy: 0.9662 - val_loss: 0.6728 - val_auc_18: 0.8325 - val_binary_accuracy: 0.7838\n",
            "Epoch 375/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1242 - auc_18: 0.9888 - binary_accuracy: 0.9595 - val_loss: 0.6919 - val_auc_18: 0.8321 - val_binary_accuracy: 0.7703\n",
            "Epoch 376/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1134 - auc_18: 0.9938 - binary_accuracy: 0.9595 - val_loss: 0.7187 - val_auc_18: 0.8286 - val_binary_accuracy: 0.7838\n",
            "Epoch 377/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1412 - auc_18: 0.9872 - binary_accuracy: 0.9358 - val_loss: 0.7026 - val_auc_18: 0.8248 - val_binary_accuracy: 0.7973\n",
            "Epoch 378/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1483 - auc_18: 0.9859 - binary_accuracy: 0.9493 - val_loss: 0.6653 - val_auc_18: 0.8159 - val_binary_accuracy: 0.7568\n",
            "Epoch 379/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1353 - auc_18: 0.9903 - binary_accuracy: 0.9358 - val_loss: 0.6914 - val_auc_18: 0.8308 - val_binary_accuracy: 0.7703\n",
            "Epoch 380/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1377 - auc_18: 0.9892 - binary_accuracy: 0.9426 - val_loss: 0.6362 - val_auc_18: 0.8402 - val_binary_accuracy: 0.8108\n",
            "Epoch 381/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1369 - auc_18: 0.9892 - binary_accuracy: 0.9459 - val_loss: 0.6243 - val_auc_18: 0.8521 - val_binary_accuracy: 0.7973\n",
            "Epoch 382/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1074 - auc_18: 0.9947 - binary_accuracy: 0.9595 - val_loss: 0.6210 - val_auc_18: 0.8521 - val_binary_accuracy: 0.7838\n",
            "Epoch 383/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1218 - auc_18: 0.9909 - binary_accuracy: 0.9561 - val_loss: 0.5887 - val_auc_18: 0.8440 - val_binary_accuracy: 0.7568\n",
            "Epoch 384/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1405 - auc_18: 0.9878 - binary_accuracy: 0.9358 - val_loss: 0.6190 - val_auc_18: 0.8457 - val_binary_accuracy: 0.7838\n",
            "Epoch 385/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1413 - auc_18: 0.9872 - binary_accuracy: 0.9426 - val_loss: 0.7028 - val_auc_18: 0.8197 - val_binary_accuracy: 0.7703\n",
            "Epoch 386/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1408 - auc_18: 0.9868 - binary_accuracy: 0.9527 - val_loss: 0.7167 - val_auc_18: 0.8188 - val_binary_accuracy: 0.7568\n",
            "Epoch 387/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1441 - auc_18: 0.9880 - binary_accuracy: 0.9459 - val_loss: 0.6615 - val_auc_18: 0.8214 - val_binary_accuracy: 0.7568\n",
            "Epoch 388/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1731 - auc_18: 0.9803 - binary_accuracy: 0.9358 - val_loss: 0.6706 - val_auc_18: 0.8282 - val_binary_accuracy: 0.7703\n",
            "Epoch 389/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1322 - auc_18: 0.9886 - binary_accuracy: 0.9493 - val_loss: 0.6424 - val_auc_18: 0.8465 - val_binary_accuracy: 0.7973\n",
            "Epoch 390/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1418 - auc_18: 0.9860 - binary_accuracy: 0.9493 - val_loss: 0.6466 - val_auc_18: 0.8512 - val_binary_accuracy: 0.7838\n",
            "Epoch 391/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1202 - auc_18: 0.9912 - binary_accuracy: 0.9595 - val_loss: 0.6673 - val_auc_18: 0.8427 - val_binary_accuracy: 0.7973\n",
            "Epoch 392/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1174 - auc_18: 0.9935 - binary_accuracy: 0.9561 - val_loss: 0.6696 - val_auc_18: 0.8346 - val_binary_accuracy: 0.7838\n",
            "Epoch 393/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1269 - auc_18: 0.9895 - binary_accuracy: 0.9730 - val_loss: 0.6588 - val_auc_18: 0.8321 - val_binary_accuracy: 0.7838\n",
            "Epoch 394/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1320 - auc_18: 0.9871 - binary_accuracy: 0.9595 - val_loss: 0.6582 - val_auc_18: 0.8316 - val_binary_accuracy: 0.7838\n",
            "Epoch 395/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1415 - auc_18: 0.9871 - binary_accuracy: 0.9527 - val_loss: 0.6316 - val_auc_18: 0.8380 - val_binary_accuracy: 0.7703\n",
            "Epoch 396/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1410 - auc_18: 0.9866 - binary_accuracy: 0.9595 - val_loss: 0.6846 - val_auc_18: 0.8406 - val_binary_accuracy: 0.7703\n",
            "Epoch 397/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1106 - auc_18: 0.9917 - binary_accuracy: 0.9561 - val_loss: 0.7068 - val_auc_18: 0.8440 - val_binary_accuracy: 0.7703\n",
            "Epoch 398/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1631 - auc_18: 0.9827 - binary_accuracy: 0.9324 - val_loss: 0.6892 - val_auc_18: 0.8265 - val_binary_accuracy: 0.7703\n",
            "Epoch 399/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1306 - auc_18: 0.9882 - binary_accuracy: 0.9527 - val_loss: 0.7167 - val_auc_18: 0.8278 - val_binary_accuracy: 0.8108\n",
            "Epoch 400/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1511 - auc_18: 0.9844 - binary_accuracy: 0.9392 - val_loss: 0.7043 - val_auc_18: 0.8176 - val_binary_accuracy: 0.7973\n",
            "Epoch 401/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1153 - auc_18: 0.9947 - binary_accuracy: 0.9595 - val_loss: 0.6489 - val_auc_18: 0.8299 - val_binary_accuracy: 0.7973\n",
            "Epoch 402/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1127 - auc_18: 0.9934 - binary_accuracy: 0.9527 - val_loss: 0.6218 - val_auc_18: 0.8491 - val_binary_accuracy: 0.7838\n",
            "Epoch 403/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1250 - auc_18: 0.9917 - binary_accuracy: 0.9459 - val_loss: 0.6414 - val_auc_18: 0.8440 - val_binary_accuracy: 0.7973\n",
            "Epoch 404/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1328 - auc_18: 0.9864 - binary_accuracy: 0.9628 - val_loss: 0.6216 - val_auc_18: 0.8427 - val_binary_accuracy: 0.7838\n",
            "Epoch 405/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1102 - auc_18: 0.9952 - binary_accuracy: 0.9662 - val_loss: 0.6194 - val_auc_18: 0.8410 - val_binary_accuracy: 0.7838\n",
            "Epoch 406/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1199 - auc_18: 0.9899 - binary_accuracy: 0.9595 - val_loss: 0.6378 - val_auc_18: 0.8414 - val_binary_accuracy: 0.7703\n",
            "Epoch 407/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1261 - auc_18: 0.9898 - binary_accuracy: 0.9459 - val_loss: 0.6737 - val_auc_18: 0.8355 - val_binary_accuracy: 0.7568\n",
            "Epoch 408/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1250 - auc_18: 0.9904 - binary_accuracy: 0.9561 - val_loss: 0.6885 - val_auc_18: 0.8346 - val_binary_accuracy: 0.7838\n",
            "Epoch 409/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1277 - auc_18: 0.9860 - binary_accuracy: 0.9595 - val_loss: 0.7185 - val_auc_18: 0.8163 - val_binary_accuracy: 0.7568\n",
            "Epoch 410/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1466 - auc_18: 0.9852 - binary_accuracy: 0.9493 - val_loss: 0.7013 - val_auc_18: 0.8235 - val_binary_accuracy: 0.7703\n",
            "Epoch 411/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1471 - auc_18: 0.9851 - binary_accuracy: 0.9493 - val_loss: 0.6725 - val_auc_18: 0.8154 - val_binary_accuracy: 0.7703\n",
            "Epoch 412/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1384 - auc_18: 0.9884 - binary_accuracy: 0.9459 - val_loss: 0.6541 - val_auc_18: 0.8397 - val_binary_accuracy: 0.7973\n",
            "Epoch 413/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1133 - auc_18: 0.9923 - binary_accuracy: 0.9561 - val_loss: 0.6536 - val_auc_18: 0.8470 - val_binary_accuracy: 0.7973\n",
            "Epoch 414/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1256 - auc_18: 0.9885 - binary_accuracy: 0.9595 - val_loss: 0.6615 - val_auc_18: 0.8278 - val_binary_accuracy: 0.7838\n",
            "Epoch 415/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1554 - auc_18: 0.9844 - binary_accuracy: 0.9459 - val_loss: 0.6307 - val_auc_18: 0.8423 - val_binary_accuracy: 0.7838\n",
            "Epoch 416/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1329 - auc_18: 0.9895 - binary_accuracy: 0.9392 - val_loss: 0.6479 - val_auc_18: 0.8470 - val_binary_accuracy: 0.7838\n",
            "Epoch 417/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1313 - auc_18: 0.9879 - binary_accuracy: 0.9561 - val_loss: 0.6951 - val_auc_18: 0.8397 - val_binary_accuracy: 0.7838\n",
            "Epoch 418/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1432 - auc_18: 0.9859 - binary_accuracy: 0.9493 - val_loss: 0.7165 - val_auc_18: 0.8346 - val_binary_accuracy: 0.8108\n",
            "Epoch 419/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1165 - auc_18: 0.9926 - binary_accuracy: 0.9595 - val_loss: 0.7396 - val_auc_18: 0.8180 - val_binary_accuracy: 0.7973\n",
            "Epoch 420/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0967 - auc_18: 0.9947 - binary_accuracy: 0.9662 - val_loss: 0.7220 - val_auc_18: 0.8291 - val_binary_accuracy: 0.7973\n",
            "Epoch 421/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1078 - auc_18: 0.9937 - binary_accuracy: 0.9595 - val_loss: 0.7180 - val_auc_18: 0.8265 - val_binary_accuracy: 0.7973\n",
            "Epoch 422/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1479 - auc_18: 0.9840 - binary_accuracy: 0.9459 - val_loss: 0.7373 - val_auc_18: 0.8223 - val_binary_accuracy: 0.7568\n",
            "Epoch 423/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1075 - auc_18: 0.9943 - binary_accuracy: 0.9628 - val_loss: 0.7137 - val_auc_18: 0.8154 - val_binary_accuracy: 0.7973\n",
            "Epoch 424/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1160 - auc_18: 0.9919 - binary_accuracy: 0.9493 - val_loss: 0.7205 - val_auc_18: 0.8257 - val_binary_accuracy: 0.7838\n",
            "Epoch 425/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1061 - auc_18: 0.9939 - binary_accuracy: 0.9662 - val_loss: 0.7227 - val_auc_18: 0.8316 - val_binary_accuracy: 0.7973\n",
            "Epoch 426/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0801 - auc_18: 0.9974 - binary_accuracy: 0.9764 - val_loss: 0.7279 - val_auc_18: 0.8278 - val_binary_accuracy: 0.7973\n",
            "Epoch 427/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1500 - auc_18: 0.9849 - binary_accuracy: 0.9426 - val_loss: 0.7025 - val_auc_18: 0.8312 - val_binary_accuracy: 0.7973\n",
            "Epoch 428/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1336 - auc_18: 0.9885 - binary_accuracy: 0.9392 - val_loss: 0.6779 - val_auc_18: 0.8380 - val_binary_accuracy: 0.7703\n",
            "Epoch 429/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1357 - auc_18: 0.9869 - binary_accuracy: 0.9493 - val_loss: 0.6618 - val_auc_18: 0.8384 - val_binary_accuracy: 0.7703\n",
            "Epoch 430/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1458 - auc_18: 0.9847 - binary_accuracy: 0.9426 - val_loss: 0.6617 - val_auc_18: 0.8274 - val_binary_accuracy: 0.7838\n",
            "Epoch 431/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1039 - auc_18: 0.9944 - binary_accuracy: 0.9595 - val_loss: 0.7019 - val_auc_18: 0.8240 - val_binary_accuracy: 0.7838\n",
            "Epoch 432/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1060 - auc_18: 0.9937 - binary_accuracy: 0.9561 - val_loss: 0.7139 - val_auc_18: 0.8257 - val_binary_accuracy: 0.7838\n",
            "Epoch 433/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0902 - auc_18: 0.9962 - binary_accuracy: 0.9730 - val_loss: 0.7388 - val_auc_18: 0.8342 - val_binary_accuracy: 0.7973\n",
            "Epoch 434/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1059 - auc_18: 0.9941 - binary_accuracy: 0.9628 - val_loss: 0.7483 - val_auc_18: 0.8410 - val_binary_accuracy: 0.7973\n",
            "Epoch 435/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1234 - auc_18: 0.9889 - binary_accuracy: 0.9493 - val_loss: 0.7099 - val_auc_18: 0.8406 - val_binary_accuracy: 0.7838\n",
            "Epoch 436/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0908 - auc_18: 0.9964 - binary_accuracy: 0.9730 - val_loss: 0.6940 - val_auc_18: 0.8299 - val_binary_accuracy: 0.7973\n",
            "Epoch 437/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0812 - auc_18: 0.9964 - binary_accuracy: 0.9764 - val_loss: 0.7101 - val_auc_18: 0.8329 - val_binary_accuracy: 0.7973\n",
            "Epoch 438/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1121 - auc_18: 0.9914 - binary_accuracy: 0.9628 - val_loss: 0.6978 - val_auc_18: 0.8286 - val_binary_accuracy: 0.7973\n",
            "Epoch 439/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1034 - auc_18: 0.9941 - binary_accuracy: 0.9493 - val_loss: 0.6813 - val_auc_18: 0.8384 - val_binary_accuracy: 0.7838\n",
            "Epoch 440/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0798 - auc_18: 0.9981 - binary_accuracy: 0.9797 - val_loss: 0.6756 - val_auc_18: 0.8495 - val_binary_accuracy: 0.7973\n",
            "Epoch 441/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1040 - auc_18: 0.9938 - binary_accuracy: 0.9628 - val_loss: 0.6938 - val_auc_18: 0.8495 - val_binary_accuracy: 0.7973\n",
            "Epoch 442/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1285 - auc_18: 0.9881 - binary_accuracy: 0.9493 - val_loss: 0.7201 - val_auc_18: 0.8367 - val_binary_accuracy: 0.7838\n",
            "Epoch 443/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1119 - auc_18: 0.9908 - binary_accuracy: 0.9628 - val_loss: 0.7513 - val_auc_18: 0.8274 - val_binary_accuracy: 0.7838\n",
            "Epoch 444/500\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0963 - auc_18: 0.9944 - binary_accuracy: 0.9662 - val_loss: 0.7321 - val_auc_18: 0.8338 - val_binary_accuracy: 0.7973\n",
            "Epoch 445/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0828 - auc_18: 0.9973 - binary_accuracy: 0.9696 - val_loss: 0.7101 - val_auc_18: 0.8171 - val_binary_accuracy: 0.7838\n",
            "Epoch 446/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1054 - auc_18: 0.9934 - binary_accuracy: 0.9561 - val_loss: 0.7415 - val_auc_18: 0.8103 - val_binary_accuracy: 0.7838\n",
            "Epoch 447/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1155 - auc_18: 0.9915 - binary_accuracy: 0.9493 - val_loss: 0.7657 - val_auc_18: 0.8201 - val_binary_accuracy: 0.7973\n",
            "Epoch 448/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0946 - auc_18: 0.9947 - binary_accuracy: 0.9561 - val_loss: 0.7173 - val_auc_18: 0.8303 - val_binary_accuracy: 0.7973\n",
            "Epoch 449/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0842 - auc_18: 0.9968 - binary_accuracy: 0.9662 - val_loss: 0.6959 - val_auc_18: 0.8342 - val_binary_accuracy: 0.7973\n",
            "Epoch 450/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0771 - auc_18: 0.9977 - binary_accuracy: 0.9696 - val_loss: 0.7145 - val_auc_18: 0.8282 - val_binary_accuracy: 0.7703\n",
            "Epoch 451/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1332 - auc_18: 0.9881 - binary_accuracy: 0.9426 - val_loss: 0.7265 - val_auc_18: 0.8244 - val_binary_accuracy: 0.7838\n",
            "Epoch 452/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0830 - auc_18: 0.9966 - binary_accuracy: 0.9764 - val_loss: 0.7032 - val_auc_18: 0.8303 - val_binary_accuracy: 0.7838\n",
            "Epoch 453/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1275 - auc_18: 0.9886 - binary_accuracy: 0.9527 - val_loss: 0.7021 - val_auc_18: 0.8440 - val_binary_accuracy: 0.8243\n",
            "Epoch 454/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1366 - auc_18: 0.9870 - binary_accuracy: 0.9527 - val_loss: 0.7406 - val_auc_18: 0.8244 - val_binary_accuracy: 0.7838\n",
            "Epoch 455/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1142 - auc_18: 0.9911 - binary_accuracy: 0.9595 - val_loss: 0.7371 - val_auc_18: 0.8291 - val_binary_accuracy: 0.7838\n",
            "Epoch 456/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1412 - auc_18: 0.9875 - binary_accuracy: 0.9426 - val_loss: 0.7266 - val_auc_18: 0.8321 - val_binary_accuracy: 0.7703\n",
            "Epoch 457/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1067 - auc_18: 0.9930 - binary_accuracy: 0.9561 - val_loss: 0.7234 - val_auc_18: 0.8223 - val_binary_accuracy: 0.7703\n",
            "Epoch 458/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1198 - auc_18: 0.9904 - binary_accuracy: 0.9527 - val_loss: 0.7388 - val_auc_18: 0.8274 - val_binary_accuracy: 0.8108\n",
            "Epoch 459/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0802 - auc_18: 0.9974 - binary_accuracy: 0.9696 - val_loss: 0.7505 - val_auc_18: 0.8325 - val_binary_accuracy: 0.8108\n",
            "Epoch 460/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0985 - auc_18: 0.9938 - binary_accuracy: 0.9696 - val_loss: 0.7525 - val_auc_18: 0.8142 - val_binary_accuracy: 0.7973\n",
            "Epoch 461/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0930 - auc_18: 0.9959 - binary_accuracy: 0.9595 - val_loss: 0.7727 - val_auc_18: 0.8188 - val_binary_accuracy: 0.7703\n",
            "Epoch 462/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1156 - auc_18: 0.9914 - binary_accuracy: 0.9561 - val_loss: 0.7859 - val_auc_18: 0.8210 - val_binary_accuracy: 0.7973\n",
            "Epoch 463/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0999 - auc_18: 0.9885 - binary_accuracy: 0.9797 - val_loss: 0.7917 - val_auc_18: 0.8116 - val_binary_accuracy: 0.7838\n",
            "Epoch 464/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1188 - auc_18: 0.9893 - binary_accuracy: 0.9628 - val_loss: 0.8094 - val_auc_18: 0.8180 - val_binary_accuracy: 0.7838\n",
            "Epoch 465/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0973 - auc_18: 0.9943 - binary_accuracy: 0.9628 - val_loss: 0.7874 - val_auc_18: 0.8116 - val_binary_accuracy: 0.7703\n",
            "Epoch 466/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1093 - auc_18: 0.9912 - binary_accuracy: 0.9696 - val_loss: 0.7716 - val_auc_18: 0.8159 - val_binary_accuracy: 0.7703\n",
            "Epoch 467/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0964 - auc_18: 0.9931 - binary_accuracy: 0.9696 - val_loss: 0.7595 - val_auc_18: 0.8303 - val_binary_accuracy: 0.7973\n",
            "Epoch 468/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0945 - auc_18: 0.9939 - binary_accuracy: 0.9628 - val_loss: 0.7717 - val_auc_18: 0.8321 - val_binary_accuracy: 0.7703\n",
            "Epoch 469/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0905 - auc_18: 0.9968 - binary_accuracy: 0.9764 - val_loss: 0.7630 - val_auc_18: 0.8261 - val_binary_accuracy: 0.7838\n",
            "Epoch 470/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0892 - auc_18: 0.9955 - binary_accuracy: 0.9696 - val_loss: 0.7570 - val_auc_18: 0.8316 - val_binary_accuracy: 0.7838\n",
            "Epoch 471/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1298 - auc_18: 0.9857 - binary_accuracy: 0.9527 - val_loss: 0.7613 - val_auc_18: 0.8137 - val_binary_accuracy: 0.7703\n",
            "Epoch 472/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1071 - auc_18: 0.9928 - binary_accuracy: 0.9595 - val_loss: 0.7513 - val_auc_18: 0.8252 - val_binary_accuracy: 0.7973\n",
            "Epoch 473/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1157 - auc_18: 0.9921 - binary_accuracy: 0.9527 - val_loss: 0.7395 - val_auc_18: 0.8240 - val_binary_accuracy: 0.7973\n",
            "Epoch 474/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0968 - auc_18: 0.9932 - binary_accuracy: 0.9662 - val_loss: 0.7268 - val_auc_18: 0.8278 - val_binary_accuracy: 0.8108\n",
            "Epoch 475/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0825 - auc_18: 0.9965 - binary_accuracy: 0.9730 - val_loss: 0.7321 - val_auc_18: 0.8218 - val_binary_accuracy: 0.7973\n",
            "Epoch 476/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1055 - auc_18: 0.9920 - binary_accuracy: 0.9527 - val_loss: 0.7867 - val_auc_18: 0.8116 - val_binary_accuracy: 0.7973\n",
            "Epoch 477/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1026 - auc_18: 0.9924 - binary_accuracy: 0.9628 - val_loss: 0.8084 - val_auc_18: 0.8214 - val_binary_accuracy: 0.7973\n",
            "Epoch 478/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0835 - auc_18: 0.9967 - binary_accuracy: 0.9730 - val_loss: 0.8077 - val_auc_18: 0.8197 - val_binary_accuracy: 0.7973\n",
            "Epoch 479/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0683 - auc_18: 0.9974 - binary_accuracy: 0.9831 - val_loss: 0.7997 - val_auc_18: 0.8210 - val_binary_accuracy: 0.8108\n",
            "Epoch 480/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0803 - auc_18: 0.9971 - binary_accuracy: 0.9696 - val_loss: 0.8315 - val_auc_18: 0.8056 - val_binary_accuracy: 0.7973\n",
            "Epoch 481/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1197 - auc_18: 0.9896 - binary_accuracy: 0.9595 - val_loss: 0.7918 - val_auc_18: 0.8112 - val_binary_accuracy: 0.7973\n",
            "Epoch 482/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1047 - auc_18: 0.9923 - binary_accuracy: 0.9561 - val_loss: 0.7801 - val_auc_18: 0.8073 - val_binary_accuracy: 0.8108\n",
            "Epoch 483/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0771 - auc_18: 0.9965 - binary_accuracy: 0.9764 - val_loss: 0.7923 - val_auc_18: 0.8061 - val_binary_accuracy: 0.8108\n",
            "Epoch 484/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1108 - auc_18: 0.9887 - binary_accuracy: 0.9662 - val_loss: 0.7992 - val_auc_18: 0.8112 - val_binary_accuracy: 0.7973\n",
            "Epoch 485/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0785 - auc_18: 0.9973 - binary_accuracy: 0.9662 - val_loss: 0.8039 - val_auc_18: 0.8223 - val_binary_accuracy: 0.7703\n",
            "Epoch 486/500\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0894 - auc_18: 0.9938 - binary_accuracy: 0.9797 - val_loss: 0.8135 - val_auc_18: 0.8193 - val_binary_accuracy: 0.8108\n",
            "Epoch 487/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0806 - auc_18: 0.9968 - binary_accuracy: 0.9797 - val_loss: 0.8225 - val_auc_18: 0.8146 - val_binary_accuracy: 0.7973\n",
            "Epoch 488/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0988 - auc_18: 0.9940 - binary_accuracy: 0.9662 - val_loss: 0.8000 - val_auc_18: 0.8103 - val_binary_accuracy: 0.7838\n",
            "Epoch 489/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0782 - auc_18: 0.9975 - binary_accuracy: 0.9730 - val_loss: 0.8065 - val_auc_18: 0.8069 - val_binary_accuracy: 0.7703\n",
            "Epoch 490/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0712 - auc_18: 0.9973 - binary_accuracy: 0.9730 - val_loss: 0.7971 - val_auc_18: 0.8261 - val_binary_accuracy: 0.7838\n",
            "Epoch 491/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0941 - auc_18: 0.9947 - binary_accuracy: 0.9628 - val_loss: 0.7930 - val_auc_18: 0.8363 - val_binary_accuracy: 0.7838\n",
            "Epoch 492/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1020 - auc_18: 0.9924 - binary_accuracy: 0.9628 - val_loss: 0.7851 - val_auc_18: 0.8325 - val_binary_accuracy: 0.7838\n",
            "Epoch 493/500\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0832 - auc_18: 0.9959 - binary_accuracy: 0.9662 - val_loss: 0.8033 - val_auc_18: 0.8244 - val_binary_accuracy: 0.7838\n",
            "Epoch 494/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0938 - auc_18: 0.9953 - binary_accuracy: 0.9662 - val_loss: 0.8129 - val_auc_18: 0.8321 - val_binary_accuracy: 0.7838\n",
            "Epoch 495/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1041 - auc_18: 0.9890 - binary_accuracy: 0.9595 - val_loss: 0.8334 - val_auc_18: 0.8355 - val_binary_accuracy: 0.7973\n",
            "Epoch 496/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0733 - auc_18: 0.9973 - binary_accuracy: 0.9764 - val_loss: 0.8003 - val_auc_18: 0.8431 - val_binary_accuracy: 0.7838\n",
            "Epoch 497/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1003 - auc_18: 0.9918 - binary_accuracy: 0.9764 - val_loss: 0.8062 - val_auc_18: 0.8380 - val_binary_accuracy: 0.8108\n",
            "Epoch 498/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0994 - auc_18: 0.9934 - binary_accuracy: 0.9628 - val_loss: 0.8018 - val_auc_18: 0.8176 - val_binary_accuracy: 0.7838\n",
            "Epoch 499/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0848 - auc_18: 0.9955 - binary_accuracy: 0.9662 - val_loss: 0.8525 - val_auc_18: 0.8061 - val_binary_accuracy: 0.7703\n",
            "Epoch 500/500\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0763 - auc_18: 0.9976 - binary_accuracy: 0.9595 - val_loss: 0.8377 - val_auc_18: 0.8061 - val_binary_accuracy: 0.7973\n",
            "Epoch 1/500\n",
            "10/10 [==============================] - 4s 95ms/step - loss: 0.6719 - auc_19: 0.6004 - binary_accuracy: 0.6149 - val_loss: 0.6445 - val_auc_19: 0.6522 - val_binary_accuracy: 0.6757\n",
            "Epoch 2/500\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6263 - auc_19: 0.6748 - binary_accuracy: 0.6858 - val_loss: 0.6242 - val_auc_19: 0.6390 - val_binary_accuracy: 0.6892\n",
            "Epoch 3/500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5842 - auc_19: 0.6899 - binary_accuracy: 0.6791 - val_loss: 0.6081 - val_auc_19: 0.6654 - val_binary_accuracy: 0.6622\n",
            "Epoch 4/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.5832 - auc_19: 0.6870 - binary_accuracy: 0.6892 - val_loss: 0.6121 - val_auc_19: 0.6513 - val_binary_accuracy: 0.6892\n",
            "Epoch 5/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.5772 - auc_19: 0.6934 - binary_accuracy: 0.6926 - val_loss: 0.6082 - val_auc_19: 0.6509 - val_binary_accuracy: 0.6892\n",
            "Epoch 6/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.5794 - auc_19: 0.6881 - binary_accuracy: 0.6858 - val_loss: 0.6133 - val_auc_19: 0.6334 - val_binary_accuracy: 0.6892\n",
            "Epoch 7/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.5731 - auc_19: 0.7093 - binary_accuracy: 0.6824 - val_loss: 0.6150 - val_auc_19: 0.6471 - val_binary_accuracy: 0.6892\n",
            "Epoch 8/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.5736 - auc_19: 0.6892 - binary_accuracy: 0.6926 - val_loss: 0.6087 - val_auc_19: 0.6513 - val_binary_accuracy: 0.6757\n",
            "Epoch 9/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5657 - auc_19: 0.7090 - binary_accuracy: 0.6926 - val_loss: 0.5950 - val_auc_19: 0.6543 - val_binary_accuracy: 0.6757\n",
            "Epoch 10/500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5673 - auc_19: 0.7011 - binary_accuracy: 0.6926 - val_loss: 0.6086 - val_auc_19: 0.6462 - val_binary_accuracy: 0.6892\n",
            "Epoch 11/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.5659 - auc_19: 0.7061 - binary_accuracy: 0.6892 - val_loss: 0.6104 - val_auc_19: 0.6509 - val_binary_accuracy: 0.6892\n",
            "Epoch 12/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.5720 - auc_19: 0.6905 - binary_accuracy: 0.6858 - val_loss: 0.5858 - val_auc_19: 0.6633 - val_binary_accuracy: 0.6757\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.5601 - auc_19: 0.7164 - binary_accuracy: 0.7095 - val_loss: 0.5846 - val_auc_19: 0.6637 - val_binary_accuracy: 0.6757\n",
            "Epoch 14/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.5481 - auc_19: 0.7399 - binary_accuracy: 0.6892 - val_loss: 0.5726 - val_auc_19: 0.6914 - val_binary_accuracy: 0.6892\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5503 - auc_19: 0.7357 - binary_accuracy: 0.7095 - val_loss: 0.5503 - val_auc_19: 0.7080 - val_binary_accuracy: 0.6892\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.5562 - auc_19: 0.7168 - binary_accuracy: 0.7196 - val_loss: 0.5728 - val_auc_19: 0.6748 - val_binary_accuracy: 0.6486\n",
            "Epoch 17/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.5419 - auc_19: 0.7397 - binary_accuracy: 0.7264 - val_loss: 0.5533 - val_auc_19: 0.7072 - val_binary_accuracy: 0.6892\n",
            "Epoch 18/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5343 - auc_19: 0.7465 - binary_accuracy: 0.7162 - val_loss: 0.5426 - val_auc_19: 0.7089 - val_binary_accuracy: 0.6892\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.5471 - auc_19: 0.7271 - binary_accuracy: 0.7128 - val_loss: 0.5433 - val_auc_19: 0.7229 - val_binary_accuracy: 0.6486\n",
            "Epoch 20/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5227 - auc_19: 0.7674 - binary_accuracy: 0.7230 - val_loss: 0.5101 - val_auc_19: 0.7903 - val_binary_accuracy: 0.7027\n",
            "Epoch 21/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.5363 - auc_19: 0.7432 - binary_accuracy: 0.7196 - val_loss: 0.5362 - val_auc_19: 0.7310 - val_binary_accuracy: 0.6622\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.5195 - auc_19: 0.7738 - binary_accuracy: 0.7635 - val_loss: 0.5339 - val_auc_19: 0.7272 - val_binary_accuracy: 0.7027\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5269 - auc_19: 0.7576 - binary_accuracy: 0.7331 - val_loss: 0.5791 - val_auc_19: 0.7353 - val_binary_accuracy: 0.6757\n",
            "Epoch 24/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.5136 - auc_19: 0.7728 - binary_accuracy: 0.7399 - val_loss: 0.5362 - val_auc_19: 0.7383 - val_binary_accuracy: 0.6892\n",
            "Epoch 25/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.5149 - auc_19: 0.7719 - binary_accuracy: 0.7399 - val_loss: 0.5577 - val_auc_19: 0.7315 - val_binary_accuracy: 0.6892\n",
            "Epoch 26/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.5040 - auc_19: 0.7779 - binary_accuracy: 0.7264 - val_loss: 0.5245 - val_auc_19: 0.7694 - val_binary_accuracy: 0.7568\n",
            "Epoch 27/500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5011 - auc_19: 0.7836 - binary_accuracy: 0.7500 - val_loss: 0.4754 - val_auc_19: 0.8227 - val_binary_accuracy: 0.7568\n",
            "Epoch 28/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.4931 - auc_19: 0.7965 - binary_accuracy: 0.7568 - val_loss: 0.5141 - val_auc_19: 0.7886 - val_binary_accuracy: 0.7568\n",
            "Epoch 29/500\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4981 - auc_19: 0.7807 - binary_accuracy: 0.7331 - val_loss: 0.5315 - val_auc_19: 0.7911 - val_binary_accuracy: 0.7297\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4926 - auc_19: 0.7892 - binary_accuracy: 0.7297 - val_loss: 0.6065 - val_auc_19: 0.7690 - val_binary_accuracy: 0.7297\n",
            "Epoch 31/500\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4964 - auc_19: 0.7863 - binary_accuracy: 0.7432 - val_loss: 0.5680 - val_auc_19: 0.7596 - val_binary_accuracy: 0.7432\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.4830 - auc_19: 0.8122 - binary_accuracy: 0.7635 - val_loss: 0.5876 - val_auc_19: 0.7801 - val_binary_accuracy: 0.7703\n",
            "Epoch 33/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.4822 - auc_19: 0.8021 - binary_accuracy: 0.7365 - val_loss: 0.5217 - val_auc_19: 0.8018 - val_binary_accuracy: 0.7568\n",
            "Epoch 34/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.5034 - auc_19: 0.7854 - binary_accuracy: 0.7331 - val_loss: 0.5579 - val_auc_19: 0.7754 - val_binary_accuracy: 0.7568\n",
            "Epoch 35/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.5089 - auc_19: 0.7749 - binary_accuracy: 0.7264 - val_loss: 0.5173 - val_auc_19: 0.7997 - val_binary_accuracy: 0.7973\n",
            "Epoch 36/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.4855 - auc_19: 0.7968 - binary_accuracy: 0.7365 - val_loss: 0.4959 - val_auc_19: 0.8039 - val_binary_accuracy: 0.8108\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.4815 - auc_19: 0.8003 - binary_accuracy: 0.7365 - val_loss: 0.5909 - val_auc_19: 0.7570 - val_binary_accuracy: 0.7432\n",
            "Epoch 38/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.4758 - auc_19: 0.8078 - binary_accuracy: 0.7432 - val_loss: 0.5632 - val_auc_19: 0.7668 - val_binary_accuracy: 0.7432\n",
            "Epoch 39/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.4699 - auc_19: 0.8134 - binary_accuracy: 0.7432 - val_loss: 0.5702 - val_auc_19: 0.7822 - val_binary_accuracy: 0.7703\n",
            "Epoch 40/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.4555 - auc_19: 0.8312 - binary_accuracy: 0.7601 - val_loss: 0.6052 - val_auc_19: 0.7852 - val_binary_accuracy: 0.7838\n",
            "Epoch 41/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.4659 - auc_19: 0.8215 - binary_accuracy: 0.7331 - val_loss: 0.5698 - val_auc_19: 0.7992 - val_binary_accuracy: 0.7703\n",
            "Epoch 42/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.4732 - auc_19: 0.8066 - binary_accuracy: 0.7534 - val_loss: 0.5628 - val_auc_19: 0.7954 - val_binary_accuracy: 0.7568\n",
            "Epoch 43/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.4635 - auc_19: 0.8240 - binary_accuracy: 0.7736 - val_loss: 0.5260 - val_auc_19: 0.8146 - val_binary_accuracy: 0.7838\n",
            "Epoch 44/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.4620 - auc_19: 0.8226 - binary_accuracy: 0.7500 - val_loss: 0.5235 - val_auc_19: 0.8039 - val_binary_accuracy: 0.7838\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.4695 - auc_19: 0.8179 - binary_accuracy: 0.7534 - val_loss: 0.5091 - val_auc_19: 0.8201 - val_binary_accuracy: 0.7973\n",
            "Epoch 46/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.4667 - auc_19: 0.8227 - binary_accuracy: 0.7736 - val_loss: 0.5159 - val_auc_19: 0.8061 - val_binary_accuracy: 0.7838\n",
            "Epoch 47/500\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4657 - auc_19: 0.8152 - binary_accuracy: 0.7534 - val_loss: 0.5404 - val_auc_19: 0.8043 - val_binary_accuracy: 0.7838\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.4566 - auc_19: 0.8202 - binary_accuracy: 0.7365 - val_loss: 0.5575 - val_auc_19: 0.7971 - val_binary_accuracy: 0.7568\n",
            "Epoch 49/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.4543 - auc_19: 0.8214 - binary_accuracy: 0.7466 - val_loss: 0.5762 - val_auc_19: 0.8107 - val_binary_accuracy: 0.8108\n",
            "Epoch 50/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.4592 - auc_19: 0.8251 - binary_accuracy: 0.7601 - val_loss: 0.5556 - val_auc_19: 0.8048 - val_binary_accuracy: 0.7838\n",
            "Epoch 51/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.4299 - auc_19: 0.8544 - binary_accuracy: 0.7669 - val_loss: 0.5782 - val_auc_19: 0.8052 - val_binary_accuracy: 0.7973\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.4459 - auc_19: 0.8361 - binary_accuracy: 0.7703 - val_loss: 0.5699 - val_auc_19: 0.8039 - val_binary_accuracy: 0.7973\n",
            "Epoch 53/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.4406 - auc_19: 0.8408 - binary_accuracy: 0.7432 - val_loss: 0.5789 - val_auc_19: 0.8129 - val_binary_accuracy: 0.7973\n",
            "Epoch 54/500\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4177 - auc_19: 0.8624 - binary_accuracy: 0.7872 - val_loss: 0.5691 - val_auc_19: 0.8090 - val_binary_accuracy: 0.7703\n",
            "Epoch 55/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.4493 - auc_19: 0.8272 - binary_accuracy: 0.7534 - val_loss: 0.5398 - val_auc_19: 0.8039 - val_binary_accuracy: 0.7838\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.4282 - auc_19: 0.8591 - binary_accuracy: 0.8074 - val_loss: 0.5570 - val_auc_19: 0.8014 - val_binary_accuracy: 0.7973\n",
            "Epoch 57/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.4761 - auc_19: 0.8089 - binary_accuracy: 0.7331 - val_loss: 0.5146 - val_auc_19: 0.8129 - val_binary_accuracy: 0.7703\n",
            "Epoch 58/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.4260 - auc_19: 0.8556 - binary_accuracy: 0.7703 - val_loss: 0.5046 - val_auc_19: 0.8227 - val_binary_accuracy: 0.7838\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.4335 - auc_19: 0.8439 - binary_accuracy: 0.7568 - val_loss: 0.4999 - val_auc_19: 0.8210 - val_binary_accuracy: 0.7838\n",
            "Epoch 60/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.4084 - auc_19: 0.8647 - binary_accuracy: 0.7736 - val_loss: 0.5255 - val_auc_19: 0.8159 - val_binary_accuracy: 0.7568\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.4179 - auc_19: 0.8546 - binary_accuracy: 0.7736 - val_loss: 0.4965 - val_auc_19: 0.8214 - val_binary_accuracy: 0.8108\n",
            "Epoch 62/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.4215 - auc_19: 0.8533 - binary_accuracy: 0.7770 - val_loss: 0.5333 - val_auc_19: 0.8176 - val_binary_accuracy: 0.7973\n",
            "Epoch 63/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.4154 - auc_19: 0.8603 - binary_accuracy: 0.7905 - val_loss: 0.5124 - val_auc_19: 0.8197 - val_binary_accuracy: 0.7703\n",
            "Epoch 64/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.4134 - auc_19: 0.8598 - binary_accuracy: 0.7534 - val_loss: 0.6079 - val_auc_19: 0.8120 - val_binary_accuracy: 0.7568\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.4340 - auc_19: 0.8484 - binary_accuracy: 0.7568 - val_loss: 0.5421 - val_auc_19: 0.7984 - val_binary_accuracy: 0.7838\n",
            "Epoch 66/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.4123 - auc_19: 0.8629 - binary_accuracy: 0.7804 - val_loss: 0.5313 - val_auc_19: 0.8227 - val_binary_accuracy: 0.7838\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.4017 - auc_19: 0.8690 - binary_accuracy: 0.7905 - val_loss: 0.5284 - val_auc_19: 0.8086 - val_binary_accuracy: 0.8108\n",
            "Epoch 68/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.4096 - auc_19: 0.8692 - binary_accuracy: 0.7770 - val_loss: 0.5216 - val_auc_19: 0.8146 - val_binary_accuracy: 0.7973\n",
            "Epoch 69/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.4073 - auc_19: 0.8658 - binary_accuracy: 0.7736 - val_loss: 0.4940 - val_auc_19: 0.8303 - val_binary_accuracy: 0.7973\n",
            "Epoch 70/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.4334 - auc_19: 0.8528 - binary_accuracy: 0.7872 - val_loss: 0.5025 - val_auc_19: 0.8274 - val_binary_accuracy: 0.7838\n",
            "Epoch 71/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.4101 - auc_19: 0.8663 - binary_accuracy: 0.7872 - val_loss: 0.5507 - val_auc_19: 0.8159 - val_binary_accuracy: 0.7297\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.3848 - auc_19: 0.8823 - binary_accuracy: 0.7939 - val_loss: 0.5255 - val_auc_19: 0.8001 - val_binary_accuracy: 0.7838\n",
            "Epoch 73/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.4062 - auc_19: 0.8623 - binary_accuracy: 0.7635 - val_loss: 0.5331 - val_auc_19: 0.8218 - val_binary_accuracy: 0.7973\n",
            "Epoch 74/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.4047 - auc_19: 0.8688 - binary_accuracy: 0.7804 - val_loss: 0.5320 - val_auc_19: 0.8120 - val_binary_accuracy: 0.7568\n",
            "Epoch 75/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3863 - auc_19: 0.8860 - binary_accuracy: 0.7939 - val_loss: 0.5916 - val_auc_19: 0.8026 - val_binary_accuracy: 0.7703\n",
            "Epoch 76/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.4172 - auc_19: 0.8609 - binary_accuracy: 0.7804 - val_loss: 0.5686 - val_auc_19: 0.7907 - val_binary_accuracy: 0.7703\n",
            "Epoch 77/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.4017 - auc_19: 0.8736 - binary_accuracy: 0.7770 - val_loss: 0.5933 - val_auc_19: 0.8090 - val_binary_accuracy: 0.7973\n",
            "Epoch 78/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.3851 - auc_19: 0.8801 - binary_accuracy: 0.8142 - val_loss: 0.5441 - val_auc_19: 0.8180 - val_binary_accuracy: 0.7838\n",
            "Epoch 79/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3797 - auc_19: 0.8825 - binary_accuracy: 0.8108 - val_loss: 0.5800 - val_auc_19: 0.8052 - val_binary_accuracy: 0.7838\n",
            "Epoch 80/500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.3724 - auc_19: 0.8941 - binary_accuracy: 0.8142 - val_loss: 0.5825 - val_auc_19: 0.7975 - val_binary_accuracy: 0.7838\n",
            "Epoch 81/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.3898 - auc_19: 0.8848 - binary_accuracy: 0.8108 - val_loss: 0.5713 - val_auc_19: 0.8099 - val_binary_accuracy: 0.7703\n",
            "Epoch 82/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.3782 - auc_19: 0.8928 - binary_accuracy: 0.8142 - val_loss: 0.5785 - val_auc_19: 0.8018 - val_binary_accuracy: 0.7297\n",
            "Epoch 83/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3885 - auc_19: 0.8831 - binary_accuracy: 0.8041 - val_loss: 0.5122 - val_auc_19: 0.8107 - val_binary_accuracy: 0.7838\n",
            "Epoch 84/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.4060 - auc_19: 0.8662 - binary_accuracy: 0.7905 - val_loss: 0.5520 - val_auc_19: 0.8043 - val_binary_accuracy: 0.7568\n",
            "Epoch 85/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3961 - auc_19: 0.8751 - binary_accuracy: 0.8074 - val_loss: 0.5661 - val_auc_19: 0.8116 - val_binary_accuracy: 0.7703\n",
            "Epoch 86/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3775 - auc_19: 0.8876 - binary_accuracy: 0.8041 - val_loss: 0.5431 - val_auc_19: 0.8167 - val_binary_accuracy: 0.7838\n",
            "Epoch 87/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.3683 - auc_19: 0.8961 - binary_accuracy: 0.8074 - val_loss: 0.5508 - val_auc_19: 0.8137 - val_binary_accuracy: 0.7838\n",
            "Epoch 88/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3769 - auc_19: 0.8911 - binary_accuracy: 0.7973 - val_loss: 0.5572 - val_auc_19: 0.8167 - val_binary_accuracy: 0.7838\n",
            "Epoch 89/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.4045 - auc_19: 0.8689 - binary_accuracy: 0.7736 - val_loss: 0.5876 - val_auc_19: 0.8069 - val_binary_accuracy: 0.7703\n",
            "Epoch 90/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3898 - auc_19: 0.8839 - binary_accuracy: 0.7838 - val_loss: 0.5177 - val_auc_19: 0.8303 - val_binary_accuracy: 0.8243\n",
            "Epoch 91/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.3594 - auc_19: 0.8965 - binary_accuracy: 0.8074 - val_loss: 0.4862 - val_auc_19: 0.8235 - val_binary_accuracy: 0.7297\n",
            "Epoch 92/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.3431 - auc_19: 0.9142 - binary_accuracy: 0.8277 - val_loss: 0.5565 - val_auc_19: 0.8001 - val_binary_accuracy: 0.7703\n",
            "Epoch 93/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3690 - auc_19: 0.8921 - binary_accuracy: 0.8041 - val_loss: 0.5712 - val_auc_19: 0.8099 - val_binary_accuracy: 0.7703\n",
            "Epoch 94/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3882 - auc_19: 0.8828 - binary_accuracy: 0.8142 - val_loss: 0.4937 - val_auc_19: 0.8159 - val_binary_accuracy: 0.7703\n",
            "Epoch 95/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3831 - auc_19: 0.8825 - binary_accuracy: 0.7872 - val_loss: 0.4793 - val_auc_19: 0.8312 - val_binary_accuracy: 0.7973\n",
            "Epoch 96/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.3525 - auc_19: 0.9062 - binary_accuracy: 0.8311 - val_loss: 0.5248 - val_auc_19: 0.8048 - val_binary_accuracy: 0.7297\n",
            "Epoch 97/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3401 - auc_19: 0.9187 - binary_accuracy: 0.8480 - val_loss: 0.5127 - val_auc_19: 0.7920 - val_binary_accuracy: 0.7027\n",
            "Epoch 98/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3527 - auc_19: 0.9048 - binary_accuracy: 0.8277 - val_loss: 0.5229 - val_auc_19: 0.8274 - val_binary_accuracy: 0.7838\n",
            "Epoch 99/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3882 - auc_19: 0.8864 - binary_accuracy: 0.7770 - val_loss: 0.5040 - val_auc_19: 0.8120 - val_binary_accuracy: 0.7297\n",
            "Epoch 100/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.3818 - auc_19: 0.8822 - binary_accuracy: 0.7973 - val_loss: 0.5356 - val_auc_19: 0.7980 - val_binary_accuracy: 0.7027\n",
            "Epoch 101/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3386 - auc_19: 0.9182 - binary_accuracy: 0.8446 - val_loss: 0.5329 - val_auc_19: 0.8129 - val_binary_accuracy: 0.7703\n",
            "Epoch 102/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3984 - auc_19: 0.8776 - binary_accuracy: 0.7770 - val_loss: 0.5100 - val_auc_19: 0.8350 - val_binary_accuracy: 0.7703\n",
            "Epoch 103/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3444 - auc_19: 0.9119 - binary_accuracy: 0.8209 - val_loss: 0.4747 - val_auc_19: 0.8240 - val_binary_accuracy: 0.7838\n",
            "Epoch 104/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3635 - auc_19: 0.8937 - binary_accuracy: 0.8074 - val_loss: 0.4885 - val_auc_19: 0.8248 - val_binary_accuracy: 0.7703\n",
            "Epoch 105/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.3562 - auc_19: 0.9051 - binary_accuracy: 0.8345 - val_loss: 0.5475 - val_auc_19: 0.8048 - val_binary_accuracy: 0.7432\n",
            "Epoch 106/500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.3478 - auc_19: 0.9086 - binary_accuracy: 0.8311 - val_loss: 0.5062 - val_auc_19: 0.8210 - val_binary_accuracy: 0.7703\n",
            "Epoch 107/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3197 - auc_19: 0.9271 - binary_accuracy: 0.8480 - val_loss: 0.5611 - val_auc_19: 0.8061 - val_binary_accuracy: 0.7432\n",
            "Epoch 108/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3318 - auc_19: 0.9153 - binary_accuracy: 0.8243 - val_loss: 0.5165 - val_auc_19: 0.8193 - val_binary_accuracy: 0.7838\n",
            "Epoch 109/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.3115 - auc_19: 0.9300 - binary_accuracy: 0.8378 - val_loss: 0.5761 - val_auc_19: 0.8005 - val_binary_accuracy: 0.7568\n",
            "Epoch 110/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.3340 - auc_19: 0.9183 - binary_accuracy: 0.8345 - val_loss: 0.5875 - val_auc_19: 0.7984 - val_binary_accuracy: 0.7703\n",
            "Epoch 111/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3186 - auc_19: 0.9248 - binary_accuracy: 0.8277 - val_loss: 0.5421 - val_auc_19: 0.8159 - val_binary_accuracy: 0.7838\n",
            "Epoch 112/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3096 - auc_19: 0.9286 - binary_accuracy: 0.8682 - val_loss: 0.5591 - val_auc_19: 0.8069 - val_binary_accuracy: 0.7432\n",
            "Epoch 113/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.3212 - auc_19: 0.9251 - binary_accuracy: 0.8446 - val_loss: 0.5285 - val_auc_19: 0.8159 - val_binary_accuracy: 0.7703\n",
            "Epoch 114/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3041 - auc_19: 0.9328 - binary_accuracy: 0.8547 - val_loss: 0.5398 - val_auc_19: 0.8176 - val_binary_accuracy: 0.7432\n",
            "Epoch 115/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.3071 - auc_19: 0.9297 - binary_accuracy: 0.8378 - val_loss: 0.5398 - val_auc_19: 0.8167 - val_binary_accuracy: 0.7703\n",
            "Epoch 116/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.3130 - auc_19: 0.9299 - binary_accuracy: 0.8480 - val_loss: 0.5500 - val_auc_19: 0.8107 - val_binary_accuracy: 0.7432\n",
            "Epoch 117/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.3255 - auc_19: 0.9149 - binary_accuracy: 0.8142 - val_loss: 0.6210 - val_auc_19: 0.7950 - val_binary_accuracy: 0.7838\n",
            "Epoch 118/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.3228 - auc_19: 0.9194 - binary_accuracy: 0.8277 - val_loss: 0.6070 - val_auc_19: 0.7911 - val_binary_accuracy: 0.7703\n",
            "Epoch 119/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.3193 - auc_19: 0.9257 - binary_accuracy: 0.8615 - val_loss: 0.5534 - val_auc_19: 0.7809 - val_binary_accuracy: 0.7162\n",
            "Epoch 120/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3133 - auc_19: 0.9314 - binary_accuracy: 0.8514 - val_loss: 0.5822 - val_auc_19: 0.7668 - val_binary_accuracy: 0.7297\n",
            "Epoch 121/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2949 - auc_19: 0.9336 - binary_accuracy: 0.8649 - val_loss: 0.6107 - val_auc_19: 0.7826 - val_binary_accuracy: 0.7297\n",
            "Epoch 122/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.3045 - auc_19: 0.9296 - binary_accuracy: 0.8581 - val_loss: 0.5932 - val_auc_19: 0.7903 - val_binary_accuracy: 0.7297\n",
            "Epoch 123/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3127 - auc_19: 0.9252 - binary_accuracy: 0.8547 - val_loss: 0.6102 - val_auc_19: 0.7984 - val_binary_accuracy: 0.7703\n",
            "Epoch 124/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.3073 - auc_19: 0.9288 - binary_accuracy: 0.8446 - val_loss: 0.6064 - val_auc_19: 0.8031 - val_binary_accuracy: 0.7297\n",
            "Epoch 125/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.3316 - auc_19: 0.9222 - binary_accuracy: 0.8176 - val_loss: 0.5831 - val_auc_19: 0.8056 - val_binary_accuracy: 0.7297\n",
            "Epoch 126/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3079 - auc_19: 0.9336 - binary_accuracy: 0.8615 - val_loss: 0.5620 - val_auc_19: 0.8210 - val_binary_accuracy: 0.7568\n",
            "Epoch 127/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2930 - auc_19: 0.9370 - binary_accuracy: 0.8615 - val_loss: 0.6244 - val_auc_19: 0.7975 - val_binary_accuracy: 0.7568\n",
            "Epoch 128/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.3022 - auc_19: 0.9351 - binary_accuracy: 0.8514 - val_loss: 0.5862 - val_auc_19: 0.8048 - val_binary_accuracy: 0.7568\n",
            "Epoch 129/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3044 - auc_19: 0.9282 - binary_accuracy: 0.8345 - val_loss: 0.4997 - val_auc_19: 0.8116 - val_binary_accuracy: 0.7432\n",
            "Epoch 130/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.3160 - auc_19: 0.9297 - binary_accuracy: 0.8412 - val_loss: 0.5174 - val_auc_19: 0.8154 - val_binary_accuracy: 0.7703\n",
            "Epoch 131/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.3021 - auc_19: 0.9336 - binary_accuracy: 0.8649 - val_loss: 0.4572 - val_auc_19: 0.8589 - val_binary_accuracy: 0.8108\n",
            "Epoch 132/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2878 - auc_19: 0.9402 - binary_accuracy: 0.8514 - val_loss: 0.4947 - val_auc_19: 0.8355 - val_binary_accuracy: 0.7432\n",
            "Epoch 133/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.2753 - auc_19: 0.9478 - binary_accuracy: 0.8716 - val_loss: 0.5340 - val_auc_19: 0.8227 - val_binary_accuracy: 0.7297\n",
            "Epoch 134/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.3111 - auc_19: 0.9378 - binary_accuracy: 0.8615 - val_loss: 0.5164 - val_auc_19: 0.8269 - val_binary_accuracy: 0.7162\n",
            "Epoch 135/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.3043 - auc_19: 0.9265 - binary_accuracy: 0.8547 - val_loss: 0.5267 - val_auc_19: 0.8240 - val_binary_accuracy: 0.7703\n",
            "Epoch 136/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.3297 - auc_19: 0.9110 - binary_accuracy: 0.8277 - val_loss: 0.5343 - val_auc_19: 0.8099 - val_binary_accuracy: 0.7297\n",
            "Epoch 137/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2886 - auc_19: 0.9529 - binary_accuracy: 0.8649 - val_loss: 0.5621 - val_auc_19: 0.7788 - val_binary_accuracy: 0.7297\n",
            "Epoch 138/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.3343 - auc_19: 0.9253 - binary_accuracy: 0.8547 - val_loss: 0.5344 - val_auc_19: 0.7984 - val_binary_accuracy: 0.7432\n",
            "Epoch 139/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.3058 - auc_19: 0.9312 - binary_accuracy: 0.8649 - val_loss: 0.5140 - val_auc_19: 0.8188 - val_binary_accuracy: 0.7973\n",
            "Epoch 140/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2888 - auc_19: 0.9421 - binary_accuracy: 0.8682 - val_loss: 0.5321 - val_auc_19: 0.8163 - val_binary_accuracy: 0.7568\n",
            "Epoch 141/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2807 - auc_19: 0.9443 - binary_accuracy: 0.8682 - val_loss: 0.5354 - val_auc_19: 0.8120 - val_binary_accuracy: 0.7432\n",
            "Epoch 142/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2838 - auc_19: 0.9460 - binary_accuracy: 0.8716 - val_loss: 0.5065 - val_auc_19: 0.8257 - val_binary_accuracy: 0.7568\n",
            "Epoch 143/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2759 - auc_19: 0.9485 - binary_accuracy: 0.8818 - val_loss: 0.5273 - val_auc_19: 0.8154 - val_binary_accuracy: 0.7703\n",
            "Epoch 144/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2789 - auc_19: 0.9469 - binary_accuracy: 0.8750 - val_loss: 0.5412 - val_auc_19: 0.8188 - val_binary_accuracy: 0.7568\n",
            "Epoch 145/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2694 - auc_19: 0.9484 - binary_accuracy: 0.8649 - val_loss: 0.5336 - val_auc_19: 0.8159 - val_binary_accuracy: 0.7568\n",
            "Epoch 146/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.3067 - auc_19: 0.9348 - binary_accuracy: 0.8514 - val_loss: 0.5486 - val_auc_19: 0.8073 - val_binary_accuracy: 0.7568\n",
            "Epoch 147/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.2983 - auc_19: 0.9377 - binary_accuracy: 0.8514 - val_loss: 0.4926 - val_auc_19: 0.8419 - val_binary_accuracy: 0.7703\n",
            "Epoch 148/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.2538 - auc_19: 0.9561 - binary_accuracy: 0.8682 - val_loss: 0.5343 - val_auc_19: 0.8257 - val_binary_accuracy: 0.7568\n",
            "Epoch 149/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.2695 - auc_19: 0.9515 - binary_accuracy: 0.8682 - val_loss: 0.5377 - val_auc_19: 0.8214 - val_binary_accuracy: 0.7703\n",
            "Epoch 150/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2537 - auc_19: 0.9560 - binary_accuracy: 0.8818 - val_loss: 0.5027 - val_auc_19: 0.8261 - val_binary_accuracy: 0.7973\n",
            "Epoch 151/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.3138 - auc_19: 0.9281 - binary_accuracy: 0.8615 - val_loss: 0.5410 - val_auc_19: 0.8107 - val_binary_accuracy: 0.7703\n",
            "Epoch 152/500\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2733 - auc_19: 0.9480 - binary_accuracy: 0.8716 - val_loss: 0.6133 - val_auc_19: 0.7937 - val_binary_accuracy: 0.7162\n",
            "Epoch 153/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2758 - auc_19: 0.9464 - binary_accuracy: 0.8818 - val_loss: 0.5841 - val_auc_19: 0.8150 - val_binary_accuracy: 0.7973\n",
            "Epoch 154/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.2587 - auc_19: 0.9554 - binary_accuracy: 0.8750 - val_loss: 0.5752 - val_auc_19: 0.8112 - val_binary_accuracy: 0.7703\n",
            "Epoch 155/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2562 - auc_19: 0.9535 - binary_accuracy: 0.8953 - val_loss: 0.5344 - val_auc_19: 0.8197 - val_binary_accuracy: 0.7568\n",
            "Epoch 156/500\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.2709 - auc_19: 0.9467 - binary_accuracy: 0.8750 - val_loss: 0.5665 - val_auc_19: 0.8120 - val_binary_accuracy: 0.7568\n",
            "Epoch 157/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2520 - auc_19: 0.9615 - binary_accuracy: 0.8649 - val_loss: 0.5886 - val_auc_19: 0.8116 - val_binary_accuracy: 0.7432\n",
            "Epoch 158/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2660 - auc_19: 0.9561 - binary_accuracy: 0.9088 - val_loss: 0.5425 - val_auc_19: 0.8167 - val_binary_accuracy: 0.7973\n",
            "Epoch 159/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2849 - auc_19: 0.9447 - binary_accuracy: 0.8581 - val_loss: 0.5735 - val_auc_19: 0.8078 - val_binary_accuracy: 0.7297\n",
            "Epoch 160/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2599 - auc_19: 0.9536 - binary_accuracy: 0.8851 - val_loss: 0.6190 - val_auc_19: 0.7928 - val_binary_accuracy: 0.7703\n",
            "Epoch 161/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2498 - auc_19: 0.9593 - binary_accuracy: 0.8953 - val_loss: 0.6442 - val_auc_19: 0.7920 - val_binary_accuracy: 0.7297\n",
            "Epoch 162/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.2450 - auc_19: 0.9612 - binary_accuracy: 0.8851 - val_loss: 0.6007 - val_auc_19: 0.8018 - val_binary_accuracy: 0.7703\n",
            "Epoch 163/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2583 - auc_19: 0.9527 - binary_accuracy: 0.8919 - val_loss: 0.5425 - val_auc_19: 0.8052 - val_binary_accuracy: 0.7568\n",
            "Epoch 164/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2460 - auc_19: 0.9628 - binary_accuracy: 0.8986 - val_loss: 0.6016 - val_auc_19: 0.8137 - val_binary_accuracy: 0.7432\n",
            "Epoch 165/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2484 - auc_19: 0.9581 - binary_accuracy: 0.8851 - val_loss: 0.5675 - val_auc_19: 0.8154 - val_binary_accuracy: 0.7838\n",
            "Epoch 166/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2541 - auc_19: 0.9536 - binary_accuracy: 0.8885 - val_loss: 0.5676 - val_auc_19: 0.8107 - val_binary_accuracy: 0.7432\n",
            "Epoch 167/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2487 - auc_19: 0.9590 - binary_accuracy: 0.8851 - val_loss: 0.5631 - val_auc_19: 0.8035 - val_binary_accuracy: 0.7297\n",
            "Epoch 168/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2460 - auc_19: 0.9625 - binary_accuracy: 0.8919 - val_loss: 0.5947 - val_auc_19: 0.8142 - val_binary_accuracy: 0.7703\n",
            "Epoch 169/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2324 - auc_19: 0.9647 - binary_accuracy: 0.8919 - val_loss: 0.6216 - val_auc_19: 0.8137 - val_binary_accuracy: 0.7432\n",
            "Epoch 170/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.2718 - auc_19: 0.9508 - binary_accuracy: 0.8581 - val_loss: 0.5563 - val_auc_19: 0.8295 - val_binary_accuracy: 0.7838\n",
            "Epoch 171/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2446 - auc_19: 0.9605 - binary_accuracy: 0.8953 - val_loss: 0.6367 - val_auc_19: 0.8086 - val_binary_accuracy: 0.7568\n",
            "Epoch 172/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2332 - auc_19: 0.9679 - binary_accuracy: 0.9054 - val_loss: 0.6818 - val_auc_19: 0.8065 - val_binary_accuracy: 0.7568\n",
            "Epoch 173/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2268 - auc_19: 0.9658 - binary_accuracy: 0.8986 - val_loss: 0.6502 - val_auc_19: 0.8133 - val_binary_accuracy: 0.7973\n",
            "Epoch 174/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2555 - auc_19: 0.9557 - binary_accuracy: 0.8682 - val_loss: 0.6173 - val_auc_19: 0.8227 - val_binary_accuracy: 0.7838\n",
            "Epoch 175/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2359 - auc_19: 0.9603 - binary_accuracy: 0.8919 - val_loss: 0.6109 - val_auc_19: 0.8133 - val_binary_accuracy: 0.7568\n",
            "Epoch 176/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2434 - auc_19: 0.9597 - binary_accuracy: 0.9122 - val_loss: 0.6572 - val_auc_19: 0.7997 - val_binary_accuracy: 0.7568\n",
            "Epoch 177/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2687 - auc_19: 0.9510 - binary_accuracy: 0.8919 - val_loss: 0.6595 - val_auc_19: 0.7907 - val_binary_accuracy: 0.7432\n",
            "Epoch 178/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.1867 - auc_19: 0.9818 - binary_accuracy: 0.9358 - val_loss: 0.6148 - val_auc_19: 0.8159 - val_binary_accuracy: 0.7703\n",
            "Epoch 179/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2137 - auc_19: 0.9696 - binary_accuracy: 0.8919 - val_loss: 0.6272 - val_auc_19: 0.8056 - val_binary_accuracy: 0.7568\n",
            "Epoch 180/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2371 - auc_19: 0.9592 - binary_accuracy: 0.8885 - val_loss: 0.5836 - val_auc_19: 0.8303 - val_binary_accuracy: 0.7703\n",
            "Epoch 181/500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.2257 - auc_19: 0.9662 - binary_accuracy: 0.9054 - val_loss: 0.5752 - val_auc_19: 0.8146 - val_binary_accuracy: 0.7838\n",
            "Epoch 182/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2339 - auc_19: 0.9623 - binary_accuracy: 0.8953 - val_loss: 0.5374 - val_auc_19: 0.8350 - val_binary_accuracy: 0.8108\n",
            "Epoch 183/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2262 - auc_19: 0.9660 - binary_accuracy: 0.9189 - val_loss: 0.5761 - val_auc_19: 0.8329 - val_binary_accuracy: 0.7973\n",
            "Epoch 184/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2200 - auc_19: 0.9672 - binary_accuracy: 0.9020 - val_loss: 0.5947 - val_auc_19: 0.8295 - val_binary_accuracy: 0.7973\n",
            "Epoch 185/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2344 - auc_19: 0.9627 - binary_accuracy: 0.8919 - val_loss: 0.5756 - val_auc_19: 0.8257 - val_binary_accuracy: 0.7838\n",
            "Epoch 186/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1996 - auc_19: 0.9751 - binary_accuracy: 0.9189 - val_loss: 0.5963 - val_auc_19: 0.8235 - val_binary_accuracy: 0.7973\n",
            "Epoch 187/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2187 - auc_19: 0.9682 - binary_accuracy: 0.8953 - val_loss: 0.5882 - val_auc_19: 0.8154 - val_binary_accuracy: 0.7973\n",
            "Epoch 188/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2173 - auc_19: 0.9686 - binary_accuracy: 0.9122 - val_loss: 0.5838 - val_auc_19: 0.8244 - val_binary_accuracy: 0.7838\n",
            "Epoch 189/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.2364 - auc_19: 0.9621 - binary_accuracy: 0.8986 - val_loss: 0.5989 - val_auc_19: 0.8278 - val_binary_accuracy: 0.7973\n",
            "Epoch 190/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2163 - auc_19: 0.9676 - binary_accuracy: 0.9020 - val_loss: 0.6273 - val_auc_19: 0.8240 - val_binary_accuracy: 0.7703\n",
            "Epoch 191/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2327 - auc_19: 0.9623 - binary_accuracy: 0.9088 - val_loss: 0.6111 - val_auc_19: 0.8312 - val_binary_accuracy: 0.8108\n",
            "Epoch 192/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1998 - auc_19: 0.9761 - binary_accuracy: 0.9189 - val_loss: 0.6012 - val_auc_19: 0.8359 - val_binary_accuracy: 0.8108\n",
            "Epoch 193/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2531 - auc_19: 0.9602 - binary_accuracy: 0.8885 - val_loss: 0.6771 - val_auc_19: 0.8073 - val_binary_accuracy: 0.7838\n",
            "Epoch 194/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2593 - auc_19: 0.9553 - binary_accuracy: 0.8885 - val_loss: 0.7236 - val_auc_19: 0.7830 - val_binary_accuracy: 0.7838\n",
            "Epoch 195/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1989 - auc_19: 0.9771 - binary_accuracy: 0.9223 - val_loss: 0.6808 - val_auc_19: 0.7984 - val_binary_accuracy: 0.7838\n",
            "Epoch 196/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1921 - auc_19: 0.9808 - binary_accuracy: 0.9324 - val_loss: 0.6822 - val_auc_19: 0.8154 - val_binary_accuracy: 0.7838\n",
            "Epoch 197/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1820 - auc_19: 0.9819 - binary_accuracy: 0.9324 - val_loss: 0.6487 - val_auc_19: 0.8240 - val_binary_accuracy: 0.7703\n",
            "Epoch 198/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1982 - auc_19: 0.9746 - binary_accuracy: 0.9020 - val_loss: 0.6161 - val_auc_19: 0.8235 - val_binary_accuracy: 0.8108\n",
            "Epoch 199/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1744 - auc_19: 0.9827 - binary_accuracy: 0.9358 - val_loss: 0.6664 - val_auc_19: 0.8265 - val_binary_accuracy: 0.7973\n",
            "Epoch 200/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2399 - auc_19: 0.9664 - binary_accuracy: 0.9020 - val_loss: 0.6518 - val_auc_19: 0.8265 - val_binary_accuracy: 0.7838\n",
            "Epoch 201/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1974 - auc_19: 0.9757 - binary_accuracy: 0.9155 - val_loss: 0.7017 - val_auc_19: 0.8005 - val_binary_accuracy: 0.7703\n",
            "Epoch 202/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2052 - auc_19: 0.9741 - binary_accuracy: 0.9088 - val_loss: 0.6583 - val_auc_19: 0.8061 - val_binary_accuracy: 0.7703\n",
            "Epoch 203/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2135 - auc_19: 0.9683 - binary_accuracy: 0.9122 - val_loss: 0.6968 - val_auc_19: 0.8133 - val_binary_accuracy: 0.7973\n",
            "Epoch 204/500\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.2048 - auc_19: 0.9714 - binary_accuracy: 0.9122 - val_loss: 0.6450 - val_auc_19: 0.8308 - val_binary_accuracy: 0.8108\n",
            "Epoch 205/500\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.1829 - auc_19: 0.9773 - binary_accuracy: 0.9257 - val_loss: 0.6361 - val_auc_19: 0.8269 - val_binary_accuracy: 0.7973\n",
            "Epoch 206/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1835 - auc_19: 0.9793 - binary_accuracy: 0.9324 - val_loss: 0.6482 - val_auc_19: 0.8252 - val_binary_accuracy: 0.7838\n",
            "Epoch 207/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1868 - auc_19: 0.9770 - binary_accuracy: 0.9155 - val_loss: 0.7622 - val_auc_19: 0.7882 - val_binary_accuracy: 0.7703\n",
            "Epoch 208/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2030 - auc_19: 0.9714 - binary_accuracy: 0.9291 - val_loss: 0.7832 - val_auc_19: 0.7933 - val_binary_accuracy: 0.7432\n",
            "Epoch 209/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2121 - auc_19: 0.9707 - binary_accuracy: 0.9122 - val_loss: 0.6693 - val_auc_19: 0.8252 - val_binary_accuracy: 0.7568\n",
            "Epoch 210/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2316 - auc_19: 0.9642 - binary_accuracy: 0.9223 - val_loss: 0.6308 - val_auc_19: 0.8257 - val_binary_accuracy: 0.7568\n",
            "Epoch 211/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.2236 - auc_19: 0.9659 - binary_accuracy: 0.9257 - val_loss: 0.6714 - val_auc_19: 0.8244 - val_binary_accuracy: 0.7703\n",
            "Epoch 212/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1689 - auc_19: 0.9825 - binary_accuracy: 0.9426 - val_loss: 0.7563 - val_auc_19: 0.8095 - val_binary_accuracy: 0.7568\n",
            "Epoch 213/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1821 - auc_19: 0.9786 - binary_accuracy: 0.9189 - val_loss: 0.7603 - val_auc_19: 0.7984 - val_binary_accuracy: 0.7568\n",
            "Epoch 214/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1767 - auc_19: 0.9811 - binary_accuracy: 0.9358 - val_loss: 0.7373 - val_auc_19: 0.8142 - val_binary_accuracy: 0.7568\n",
            "Epoch 215/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1792 - auc_19: 0.9810 - binary_accuracy: 0.9426 - val_loss: 0.6829 - val_auc_19: 0.8129 - val_binary_accuracy: 0.7703\n",
            "Epoch 216/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1785 - auc_19: 0.9814 - binary_accuracy: 0.9324 - val_loss: 0.7574 - val_auc_19: 0.8048 - val_binary_accuracy: 0.7703\n",
            "Epoch 217/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1776 - auc_19: 0.9790 - binary_accuracy: 0.9324 - val_loss: 0.7432 - val_auc_19: 0.8231 - val_binary_accuracy: 0.7838\n",
            "Epoch 218/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1448 - auc_19: 0.9886 - binary_accuracy: 0.9426 - val_loss: 0.7207 - val_auc_19: 0.8214 - val_binary_accuracy: 0.8108\n",
            "Epoch 219/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1637 - auc_19: 0.9837 - binary_accuracy: 0.9257 - val_loss: 0.7204 - val_auc_19: 0.8048 - val_binary_accuracy: 0.7568\n",
            "Epoch 220/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2006 - auc_19: 0.9715 - binary_accuracy: 0.9122 - val_loss: 0.7166 - val_auc_19: 0.8065 - val_binary_accuracy: 0.7568\n",
            "Epoch 221/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1653 - auc_19: 0.9819 - binary_accuracy: 0.9358 - val_loss: 0.7288 - val_auc_19: 0.8095 - val_binary_accuracy: 0.7703\n",
            "Epoch 222/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1686 - auc_19: 0.9810 - binary_accuracy: 0.9358 - val_loss: 0.7896 - val_auc_19: 0.7847 - val_binary_accuracy: 0.7432\n",
            "Epoch 223/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.2041 - auc_19: 0.9755 - binary_accuracy: 0.9155 - val_loss: 0.7624 - val_auc_19: 0.7869 - val_binary_accuracy: 0.7432\n",
            "Epoch 224/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2138 - auc_19: 0.9693 - binary_accuracy: 0.9155 - val_loss: 0.7987 - val_auc_19: 0.8035 - val_binary_accuracy: 0.7703\n",
            "Epoch 225/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.2075 - auc_19: 0.9689 - binary_accuracy: 0.9257 - val_loss: 0.6996 - val_auc_19: 0.8295 - val_binary_accuracy: 0.7838\n",
            "Epoch 226/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.2076 - auc_19: 0.9708 - binary_accuracy: 0.8986 - val_loss: 0.6894 - val_auc_19: 0.8201 - val_binary_accuracy: 0.7703\n",
            "Epoch 227/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1561 - auc_19: 0.9862 - binary_accuracy: 0.9426 - val_loss: 0.7561 - val_auc_19: 0.8099 - val_binary_accuracy: 0.7703\n",
            "Epoch 228/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1528 - auc_19: 0.9850 - binary_accuracy: 0.9459 - val_loss: 0.7566 - val_auc_19: 0.8142 - val_binary_accuracy: 0.7703\n",
            "Epoch 229/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1722 - auc_19: 0.9770 - binary_accuracy: 0.9459 - val_loss: 0.7293 - val_auc_19: 0.8163 - val_binary_accuracy: 0.7838\n",
            "Epoch 230/500\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1853 - auc_19: 0.9769 - binary_accuracy: 0.9426 - val_loss: 0.7725 - val_auc_19: 0.7809 - val_binary_accuracy: 0.7432\n",
            "Epoch 231/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1370 - auc_19: 0.9912 - binary_accuracy: 0.9595 - val_loss: 0.7972 - val_auc_19: 0.7766 - val_binary_accuracy: 0.7162\n",
            "Epoch 232/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1660 - auc_19: 0.9839 - binary_accuracy: 0.9426 - val_loss: 0.7371 - val_auc_19: 0.8035 - val_binary_accuracy: 0.7432\n",
            "Epoch 233/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1801 - auc_19: 0.9765 - binary_accuracy: 0.9426 - val_loss: 0.6686 - val_auc_19: 0.8154 - val_binary_accuracy: 0.7568\n",
            "Epoch 234/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.1532 - auc_19: 0.9871 - binary_accuracy: 0.9392 - val_loss: 0.7245 - val_auc_19: 0.8065 - val_binary_accuracy: 0.7703\n",
            "Epoch 235/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1920 - auc_19: 0.9761 - binary_accuracy: 0.9291 - val_loss: 0.7443 - val_auc_19: 0.8090 - val_binary_accuracy: 0.7568\n",
            "Epoch 236/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1309 - auc_19: 0.9915 - binary_accuracy: 0.9696 - val_loss: 0.7465 - val_auc_19: 0.8031 - val_binary_accuracy: 0.7432\n",
            "Epoch 237/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1486 - auc_19: 0.9874 - binary_accuracy: 0.9493 - val_loss: 0.7566 - val_auc_19: 0.7975 - val_binary_accuracy: 0.7297\n",
            "Epoch 238/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1681 - auc_19: 0.9790 - binary_accuracy: 0.9426 - val_loss: 0.8380 - val_auc_19: 0.7933 - val_binary_accuracy: 0.7297\n",
            "Epoch 239/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1617 - auc_19: 0.9802 - binary_accuracy: 0.9493 - val_loss: 0.8323 - val_auc_19: 0.7847 - val_binary_accuracy: 0.7297\n",
            "Epoch 240/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1389 - auc_19: 0.9895 - binary_accuracy: 0.9561 - val_loss: 0.7774 - val_auc_19: 0.7958 - val_binary_accuracy: 0.7297\n",
            "Epoch 241/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1474 - auc_19: 0.9873 - binary_accuracy: 0.9358 - val_loss: 0.7591 - val_auc_19: 0.8107 - val_binary_accuracy: 0.7432\n",
            "Epoch 242/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1409 - auc_19: 0.9892 - binary_accuracy: 0.9426 - val_loss: 0.7813 - val_auc_19: 0.8026 - val_binary_accuracy: 0.7838\n",
            "Epoch 243/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.2013 - auc_19: 0.9696 - binary_accuracy: 0.9155 - val_loss: 0.7114 - val_auc_19: 0.8193 - val_binary_accuracy: 0.7568\n",
            "Epoch 244/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1996 - auc_19: 0.9724 - binary_accuracy: 0.9358 - val_loss: 0.6717 - val_auc_19: 0.8090 - val_binary_accuracy: 0.7432\n",
            "Epoch 245/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1945 - auc_19: 0.9738 - binary_accuracy: 0.9155 - val_loss: 0.6126 - val_auc_19: 0.8227 - val_binary_accuracy: 0.7568\n",
            "Epoch 246/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1656 - auc_19: 0.9811 - binary_accuracy: 0.9392 - val_loss: 0.6458 - val_auc_19: 0.8291 - val_binary_accuracy: 0.7838\n",
            "Epoch 247/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1457 - auc_19: 0.9873 - binary_accuracy: 0.9459 - val_loss: 0.7095 - val_auc_19: 0.8188 - val_binary_accuracy: 0.7838\n",
            "Epoch 248/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1688 - auc_19: 0.9802 - binary_accuracy: 0.9358 - val_loss: 0.7090 - val_auc_19: 0.8090 - val_binary_accuracy: 0.7568\n",
            "Epoch 249/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1599 - auc_19: 0.9851 - binary_accuracy: 0.9324 - val_loss: 0.6927 - val_auc_19: 0.8299 - val_binary_accuracy: 0.7838\n",
            "Epoch 250/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1373 - auc_19: 0.9893 - binary_accuracy: 0.9527 - val_loss: 0.7125 - val_auc_19: 0.8223 - val_binary_accuracy: 0.7568\n",
            "Epoch 251/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1259 - auc_19: 0.9912 - binary_accuracy: 0.9696 - val_loss: 0.7256 - val_auc_19: 0.8129 - val_binary_accuracy: 0.7838\n",
            "Epoch 252/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1101 - auc_19: 0.9948 - binary_accuracy: 0.9595 - val_loss: 0.7619 - val_auc_19: 0.7997 - val_binary_accuracy: 0.7432\n",
            "Epoch 253/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.1258 - auc_19: 0.9913 - binary_accuracy: 0.9628 - val_loss: 0.7847 - val_auc_19: 0.8018 - val_binary_accuracy: 0.7568\n",
            "Epoch 254/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1419 - auc_19: 0.9879 - binary_accuracy: 0.9493 - val_loss: 0.8569 - val_auc_19: 0.7954 - val_binary_accuracy: 0.7568\n",
            "Epoch 255/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1492 - auc_19: 0.9836 - binary_accuracy: 0.9459 - val_loss: 0.8753 - val_auc_19: 0.8052 - val_binary_accuracy: 0.7432\n",
            "Epoch 256/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1414 - auc_19: 0.9873 - binary_accuracy: 0.9595 - val_loss: 0.8070 - val_auc_19: 0.8137 - val_binary_accuracy: 0.7703\n",
            "Epoch 257/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1349 - auc_19: 0.9890 - binary_accuracy: 0.9392 - val_loss: 0.7947 - val_auc_19: 0.7992 - val_binary_accuracy: 0.7568\n",
            "Epoch 258/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1438 - auc_19: 0.9859 - binary_accuracy: 0.9527 - val_loss: 0.7824 - val_auc_19: 0.8031 - val_binary_accuracy: 0.7568\n",
            "Epoch 259/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1423 - auc_19: 0.9879 - binary_accuracy: 0.9392 - val_loss: 0.7751 - val_auc_19: 0.8022 - val_binary_accuracy: 0.7838\n",
            "Epoch 260/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1659 - auc_19: 0.9818 - binary_accuracy: 0.9426 - val_loss: 0.7271 - val_auc_19: 0.8082 - val_binary_accuracy: 0.7432\n",
            "Epoch 261/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1609 - auc_19: 0.9837 - binary_accuracy: 0.9358 - val_loss: 0.7396 - val_auc_19: 0.8005 - val_binary_accuracy: 0.7568\n",
            "Epoch 262/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1473 - auc_19: 0.9870 - binary_accuracy: 0.9257 - val_loss: 0.7217 - val_auc_19: 0.8124 - val_binary_accuracy: 0.7297\n",
            "Epoch 263/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1186 - auc_19: 0.9925 - binary_accuracy: 0.9527 - val_loss: 0.7476 - val_auc_19: 0.8201 - val_binary_accuracy: 0.7703\n",
            "Epoch 264/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1342 - auc_19: 0.9889 - binary_accuracy: 0.9527 - val_loss: 0.7536 - val_auc_19: 0.8159 - val_binary_accuracy: 0.7432\n",
            "Epoch 265/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1706 - auc_19: 0.9801 - binary_accuracy: 0.9257 - val_loss: 0.7140 - val_auc_19: 0.8210 - val_binary_accuracy: 0.7703\n",
            "Epoch 266/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1090 - auc_19: 0.9927 - binary_accuracy: 0.9628 - val_loss: 0.6971 - val_auc_19: 0.8171 - val_binary_accuracy: 0.7568\n",
            "Epoch 267/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1136 - auc_19: 0.9921 - binary_accuracy: 0.9595 - val_loss: 0.6917 - val_auc_19: 0.8193 - val_binary_accuracy: 0.7703\n",
            "Epoch 268/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1212 - auc_19: 0.9915 - binary_accuracy: 0.9561 - val_loss: 0.7117 - val_auc_19: 0.8218 - val_binary_accuracy: 0.7568\n",
            "Epoch 269/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1482 - auc_19: 0.9863 - binary_accuracy: 0.9459 - val_loss: 0.7308 - val_auc_19: 0.8142 - val_binary_accuracy: 0.7432\n",
            "Epoch 270/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1221 - auc_19: 0.9909 - binary_accuracy: 0.9561 - val_loss: 0.7255 - val_auc_19: 0.8265 - val_binary_accuracy: 0.7703\n",
            "Epoch 271/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.1282 - auc_19: 0.9905 - binary_accuracy: 0.9527 - val_loss: 0.7739 - val_auc_19: 0.8171 - val_binary_accuracy: 0.7703\n",
            "Epoch 272/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1447 - auc_19: 0.9821 - binary_accuracy: 0.9561 - val_loss: 0.7824 - val_auc_19: 0.8197 - val_binary_accuracy: 0.7838\n",
            "Epoch 273/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1399 - auc_19: 0.9852 - binary_accuracy: 0.9527 - val_loss: 0.7682 - val_auc_19: 0.8009 - val_binary_accuracy: 0.7432\n",
            "Epoch 274/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1321 - auc_19: 0.9883 - binary_accuracy: 0.9595 - val_loss: 0.7848 - val_auc_19: 0.7899 - val_binary_accuracy: 0.7162\n",
            "Epoch 275/500\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1081 - auc_19: 0.9923 - binary_accuracy: 0.9662 - val_loss: 0.8363 - val_auc_19: 0.7937 - val_binary_accuracy: 0.7297\n",
            "Epoch 276/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1021 - auc_19: 0.9949 - binary_accuracy: 0.9662 - val_loss: 0.8200 - val_auc_19: 0.7971 - val_binary_accuracy: 0.7432\n",
            "Epoch 277/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1145 - auc_19: 0.9927 - binary_accuracy: 0.9662 - val_loss: 0.8128 - val_auc_19: 0.8103 - val_binary_accuracy: 0.7568\n",
            "Epoch 278/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1030 - auc_19: 0.9943 - binary_accuracy: 0.9561 - val_loss: 0.8075 - val_auc_19: 0.8107 - val_binary_accuracy: 0.7568\n",
            "Epoch 279/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0974 - auc_19: 0.9950 - binary_accuracy: 0.9696 - val_loss: 0.8440 - val_auc_19: 0.7911 - val_binary_accuracy: 0.7568\n",
            "Epoch 280/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.1343 - auc_19: 0.9874 - binary_accuracy: 0.9527 - val_loss: 0.8241 - val_auc_19: 0.8001 - val_binary_accuracy: 0.7432\n",
            "Epoch 281/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1098 - auc_19: 0.9911 - binary_accuracy: 0.9662 - val_loss: 0.8633 - val_auc_19: 0.7924 - val_binary_accuracy: 0.7432\n",
            "Epoch 282/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1320 - auc_19: 0.9901 - binary_accuracy: 0.9392 - val_loss: 0.8438 - val_auc_19: 0.7877 - val_binary_accuracy: 0.7297\n",
            "Epoch 283/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1320 - auc_19: 0.9888 - binary_accuracy: 0.9493 - val_loss: 0.8296 - val_auc_19: 0.7907 - val_binary_accuracy: 0.7432\n",
            "Epoch 284/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1407 - auc_19: 0.9890 - binary_accuracy: 0.9493 - val_loss: 0.8222 - val_auc_19: 0.8009 - val_binary_accuracy: 0.7838\n",
            "Epoch 285/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0981 - auc_19: 0.9948 - binary_accuracy: 0.9662 - val_loss: 0.7211 - val_auc_19: 0.8240 - val_binary_accuracy: 0.7838\n",
            "Epoch 286/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1362 - auc_19: 0.9879 - binary_accuracy: 0.9459 - val_loss: 0.7565 - val_auc_19: 0.8201 - val_binary_accuracy: 0.7703\n",
            "Epoch 287/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1289 - auc_19: 0.9884 - binary_accuracy: 0.9561 - val_loss: 0.7731 - val_auc_19: 0.8018 - val_binary_accuracy: 0.7703\n",
            "Epoch 288/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1177 - auc_19: 0.9921 - binary_accuracy: 0.9527 - val_loss: 0.7619 - val_auc_19: 0.8240 - val_binary_accuracy: 0.7973\n",
            "Epoch 289/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1168 - auc_19: 0.9910 - binary_accuracy: 0.9527 - val_loss: 0.7509 - val_auc_19: 0.8142 - val_binary_accuracy: 0.7568\n",
            "Epoch 290/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0948 - auc_19: 0.9948 - binary_accuracy: 0.9696 - val_loss: 0.7479 - val_auc_19: 0.8171 - val_binary_accuracy: 0.7432\n",
            "Epoch 291/500\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1313 - auc_19: 0.9877 - binary_accuracy: 0.9595 - val_loss: 0.7259 - val_auc_19: 0.8261 - val_binary_accuracy: 0.7703\n",
            "Epoch 292/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1172 - auc_19: 0.9917 - binary_accuracy: 0.9595 - val_loss: 0.7688 - val_auc_19: 0.8257 - val_binary_accuracy: 0.7568\n",
            "Epoch 293/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1176 - auc_19: 0.9904 - binary_accuracy: 0.9595 - val_loss: 0.7859 - val_auc_19: 0.8124 - val_binary_accuracy: 0.7703\n",
            "Epoch 294/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0896 - auc_19: 0.9960 - binary_accuracy: 0.9696 - val_loss: 0.8361 - val_auc_19: 0.7962 - val_binary_accuracy: 0.7568\n",
            "Epoch 295/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1027 - auc_19: 0.9930 - binary_accuracy: 0.9696 - val_loss: 0.8011 - val_auc_19: 0.8142 - val_binary_accuracy: 0.7568\n",
            "Epoch 296/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0869 - auc_19: 0.9953 - binary_accuracy: 0.9696 - val_loss: 0.7950 - val_auc_19: 0.8176 - val_binary_accuracy: 0.7703\n",
            "Epoch 297/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1121 - auc_19: 0.9896 - binary_accuracy: 0.9730 - val_loss: 0.7534 - val_auc_19: 0.8210 - val_binary_accuracy: 0.7973\n",
            "Epoch 298/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1051 - auc_19: 0.9940 - binary_accuracy: 0.9628 - val_loss: 0.7346 - val_auc_19: 0.8282 - val_binary_accuracy: 0.7838\n",
            "Epoch 299/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0839 - auc_19: 0.9968 - binary_accuracy: 0.9730 - val_loss: 0.7736 - val_auc_19: 0.8257 - val_binary_accuracy: 0.7703\n",
            "Epoch 300/500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0928 - auc_19: 0.9958 - binary_accuracy: 0.9628 - val_loss: 0.8077 - val_auc_19: 0.8201 - val_binary_accuracy: 0.7703\n",
            "Epoch 301/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0954 - auc_19: 0.9947 - binary_accuracy: 0.9527 - val_loss: 0.8199 - val_auc_19: 0.8261 - val_binary_accuracy: 0.7838\n",
            "Epoch 302/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1041 - auc_19: 0.9922 - binary_accuracy: 0.9628 - val_loss: 0.8246 - val_auc_19: 0.8197 - val_binary_accuracy: 0.7703\n",
            "Epoch 303/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1148 - auc_19: 0.9902 - binary_accuracy: 0.9628 - val_loss: 0.7915 - val_auc_19: 0.8223 - val_binary_accuracy: 0.7973\n",
            "Epoch 304/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0931 - auc_19: 0.9941 - binary_accuracy: 0.9730 - val_loss: 0.7935 - val_auc_19: 0.8129 - val_binary_accuracy: 0.7568\n",
            "Epoch 305/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1220 - auc_19: 0.9894 - binary_accuracy: 0.9493 - val_loss: 0.8070 - val_auc_19: 0.7997 - val_binary_accuracy: 0.7297\n",
            "Epoch 306/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1017 - auc_19: 0.9944 - binary_accuracy: 0.9662 - val_loss: 0.7976 - val_auc_19: 0.8082 - val_binary_accuracy: 0.7297\n",
            "Epoch 307/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0925 - auc_19: 0.9948 - binary_accuracy: 0.9696 - val_loss: 0.7617 - val_auc_19: 0.8197 - val_binary_accuracy: 0.7432\n",
            "Epoch 308/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1129 - auc_19: 0.9921 - binary_accuracy: 0.9426 - val_loss: 0.7370 - val_auc_19: 0.8338 - val_binary_accuracy: 0.7703\n",
            "Epoch 309/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1116 - auc_19: 0.9921 - binary_accuracy: 0.9561 - val_loss: 0.7524 - val_auc_19: 0.8278 - val_binary_accuracy: 0.7703\n",
            "Epoch 310/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0996 - auc_19: 0.9938 - binary_accuracy: 0.9628 - val_loss: 0.8167 - val_auc_19: 0.8120 - val_binary_accuracy: 0.7703\n",
            "Epoch 311/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1044 - auc_19: 0.9883 - binary_accuracy: 0.9696 - val_loss: 0.7629 - val_auc_19: 0.8359 - val_binary_accuracy: 0.7973\n",
            "Epoch 312/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1022 - auc_19: 0.9937 - binary_accuracy: 0.9662 - val_loss: 0.7691 - val_auc_19: 0.8265 - val_binary_accuracy: 0.7568\n",
            "Epoch 313/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1106 - auc_19: 0.9909 - binary_accuracy: 0.9595 - val_loss: 0.8027 - val_auc_19: 0.8193 - val_binary_accuracy: 0.7703\n",
            "Epoch 314/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0795 - auc_19: 0.9967 - binary_accuracy: 0.9730 - val_loss: 0.8814 - val_auc_19: 0.7975 - val_binary_accuracy: 0.7432\n",
            "Epoch 315/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0953 - auc_19: 0.9937 - binary_accuracy: 0.9595 - val_loss: 0.9024 - val_auc_19: 0.8073 - val_binary_accuracy: 0.7297\n",
            "Epoch 316/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0893 - auc_19: 0.9956 - binary_accuracy: 0.9696 - val_loss: 0.8604 - val_auc_19: 0.8150 - val_binary_accuracy: 0.7703\n",
            "Epoch 317/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0924 - auc_19: 0.9933 - binary_accuracy: 0.9662 - val_loss: 0.7986 - val_auc_19: 0.8218 - val_binary_accuracy: 0.7973\n",
            "Epoch 318/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1197 - auc_19: 0.9904 - binary_accuracy: 0.9426 - val_loss: 0.8402 - val_auc_19: 0.7971 - val_binary_accuracy: 0.7568\n",
            "Epoch 319/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0713 - auc_19: 0.9977 - binary_accuracy: 0.9797 - val_loss: 0.8653 - val_auc_19: 0.7937 - val_binary_accuracy: 0.7432\n",
            "Epoch 320/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0721 - auc_19: 0.9974 - binary_accuracy: 0.9797 - val_loss: 0.8806 - val_auc_19: 0.7967 - val_binary_accuracy: 0.7432\n",
            "Epoch 321/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0970 - auc_19: 0.9942 - binary_accuracy: 0.9662 - val_loss: 0.8803 - val_auc_19: 0.8018 - val_binary_accuracy: 0.7162\n",
            "Epoch 322/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0806 - auc_19: 0.9969 - binary_accuracy: 0.9662 - val_loss: 0.8496 - val_auc_19: 0.8124 - val_binary_accuracy: 0.7432\n",
            "Epoch 323/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0922 - auc_19: 0.9965 - binary_accuracy: 0.9662 - val_loss: 0.8295 - val_auc_19: 0.8210 - val_binary_accuracy: 0.7838\n",
            "Epoch 324/500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0980 - auc_19: 0.9931 - binary_accuracy: 0.9696 - val_loss: 0.8163 - val_auc_19: 0.8218 - val_binary_accuracy: 0.8108\n",
            "Epoch 325/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0891 - auc_19: 0.9943 - binary_accuracy: 0.9696 - val_loss: 0.8503 - val_auc_19: 0.8159 - val_binary_accuracy: 0.7838\n",
            "Epoch 326/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0756 - auc_19: 0.9973 - binary_accuracy: 0.9662 - val_loss: 0.8750 - val_auc_19: 0.8193 - val_binary_accuracy: 0.7973\n",
            "Epoch 327/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0920 - auc_19: 0.9949 - binary_accuracy: 0.9730 - val_loss: 0.8944 - val_auc_19: 0.7933 - val_binary_accuracy: 0.7568\n",
            "Epoch 328/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.1054 - auc_19: 0.9930 - binary_accuracy: 0.9527 - val_loss: 0.8794 - val_auc_19: 0.8078 - val_binary_accuracy: 0.7973\n",
            "Epoch 329/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0912 - auc_19: 0.9951 - binary_accuracy: 0.9696 - val_loss: 0.8841 - val_auc_19: 0.8261 - val_binary_accuracy: 0.7838\n",
            "Epoch 330/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0912 - auc_19: 0.9946 - binary_accuracy: 0.9696 - val_loss: 0.9094 - val_auc_19: 0.8018 - val_binary_accuracy: 0.7703\n",
            "Epoch 331/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0765 - auc_19: 0.9965 - binary_accuracy: 0.9696 - val_loss: 0.9063 - val_auc_19: 0.8137 - val_binary_accuracy: 0.7838\n",
            "Epoch 332/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0886 - auc_19: 0.9942 - binary_accuracy: 0.9730 - val_loss: 0.8740 - val_auc_19: 0.8107 - val_binary_accuracy: 0.8108\n",
            "Epoch 333/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0728 - auc_19: 0.9983 - binary_accuracy: 0.9797 - val_loss: 0.8933 - val_auc_19: 0.8159 - val_binary_accuracy: 0.8108\n",
            "Epoch 334/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0962 - auc_19: 0.9937 - binary_accuracy: 0.9628 - val_loss: 0.9210 - val_auc_19: 0.7997 - val_binary_accuracy: 0.7838\n",
            "Epoch 335/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0784 - auc_19: 0.9957 - binary_accuracy: 0.9730 - val_loss: 0.9247 - val_auc_19: 0.8035 - val_binary_accuracy: 0.7703\n",
            "Epoch 336/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1004 - auc_19: 0.9930 - binary_accuracy: 0.9628 - val_loss: 0.7959 - val_auc_19: 0.8180 - val_binary_accuracy: 0.7838\n",
            "Epoch 337/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1018 - auc_19: 0.9932 - binary_accuracy: 0.9527 - val_loss: 0.6792 - val_auc_19: 0.8500 - val_binary_accuracy: 0.8243\n",
            "Epoch 338/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1025 - auc_19: 0.9936 - binary_accuracy: 0.9527 - val_loss: 0.6581 - val_auc_19: 0.8593 - val_binary_accuracy: 0.8243\n",
            "Epoch 339/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0930 - auc_19: 0.9955 - binary_accuracy: 0.9561 - val_loss: 0.7324 - val_auc_19: 0.8240 - val_binary_accuracy: 0.7703\n",
            "Epoch 340/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1237 - auc_19: 0.9893 - binary_accuracy: 0.9459 - val_loss: 0.7441 - val_auc_19: 0.8402 - val_binary_accuracy: 0.7973\n",
            "Epoch 341/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0783 - auc_19: 0.9963 - binary_accuracy: 0.9797 - val_loss: 0.7240 - val_auc_19: 0.8431 - val_binary_accuracy: 0.8243\n",
            "Epoch 342/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0711 - auc_19: 0.9978 - binary_accuracy: 0.9831 - val_loss: 0.7140 - val_auc_19: 0.8436 - val_binary_accuracy: 0.7838\n",
            "Epoch 343/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0780 - auc_19: 0.9959 - binary_accuracy: 0.9764 - val_loss: 0.7388 - val_auc_19: 0.8338 - val_binary_accuracy: 0.7703\n",
            "Epoch 344/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0785 - auc_19: 0.9949 - binary_accuracy: 0.9696 - val_loss: 0.7652 - val_auc_19: 0.8282 - val_binary_accuracy: 0.7568\n",
            "Epoch 345/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0880 - auc_19: 0.9955 - binary_accuracy: 0.9595 - val_loss: 0.7656 - val_auc_19: 0.8359 - val_binary_accuracy: 0.7568\n",
            "Epoch 346/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0524 - auc_19: 0.9989 - binary_accuracy: 0.9865 - val_loss: 0.7559 - val_auc_19: 0.8325 - val_binary_accuracy: 0.7703\n",
            "Epoch 347/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0913 - auc_19: 0.9930 - binary_accuracy: 0.9696 - val_loss: 0.7922 - val_auc_19: 0.8299 - val_binary_accuracy: 0.7838\n",
            "Epoch 348/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0799 - auc_19: 0.9957 - binary_accuracy: 0.9696 - val_loss: 0.7795 - val_auc_19: 0.8444 - val_binary_accuracy: 0.7568\n",
            "Epoch 349/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0677 - auc_19: 0.9978 - binary_accuracy: 0.9696 - val_loss: 0.7728 - val_auc_19: 0.8291 - val_binary_accuracy: 0.7973\n",
            "Epoch 350/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0743 - auc_19: 0.9966 - binary_accuracy: 0.9696 - val_loss: 0.7939 - val_auc_19: 0.8201 - val_binary_accuracy: 0.7432\n",
            "Epoch 351/500\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1003 - auc_19: 0.9924 - binary_accuracy: 0.9628 - val_loss: 0.7881 - val_auc_19: 0.8342 - val_binary_accuracy: 0.7297\n",
            "Epoch 352/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1012 - auc_19: 0.9916 - binary_accuracy: 0.9696 - val_loss: 0.7504 - val_auc_19: 0.8350 - val_binary_accuracy: 0.7703\n",
            "Epoch 353/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0823 - auc_19: 0.9950 - binary_accuracy: 0.9797 - val_loss: 0.7305 - val_auc_19: 0.8410 - val_binary_accuracy: 0.7703\n",
            "Epoch 354/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0700 - auc_19: 0.9972 - binary_accuracy: 0.9797 - val_loss: 0.7550 - val_auc_19: 0.8457 - val_binary_accuracy: 0.7703\n",
            "Epoch 355/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0716 - auc_19: 0.9979 - binary_accuracy: 0.9696 - val_loss: 0.7499 - val_auc_19: 0.8440 - val_binary_accuracy: 0.7838\n",
            "Epoch 356/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0746 - auc_19: 0.9975 - binary_accuracy: 0.9662 - val_loss: 0.7876 - val_auc_19: 0.8342 - val_binary_accuracy: 0.7838\n",
            "Epoch 357/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1173 - auc_19: 0.9919 - binary_accuracy: 0.9628 - val_loss: 0.7588 - val_auc_19: 0.8470 - val_binary_accuracy: 0.7838\n",
            "Epoch 358/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0661 - auc_19: 0.9979 - binary_accuracy: 0.9696 - val_loss: 0.7432 - val_auc_19: 0.8389 - val_binary_accuracy: 0.8243\n",
            "Epoch 359/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0825 - auc_19: 0.9957 - binary_accuracy: 0.9628 - val_loss: 0.7333 - val_auc_19: 0.8470 - val_binary_accuracy: 0.7973\n",
            "Epoch 360/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0615 - auc_19: 0.9982 - binary_accuracy: 0.9764 - val_loss: 0.7540 - val_auc_19: 0.8406 - val_binary_accuracy: 0.7838\n",
            "Epoch 361/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0536 - auc_19: 0.9983 - binary_accuracy: 0.9932 - val_loss: 0.7717 - val_auc_19: 0.8295 - val_binary_accuracy: 0.7703\n",
            "Epoch 362/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0741 - auc_19: 0.9967 - binary_accuracy: 0.9730 - val_loss: 0.7970 - val_auc_19: 0.8359 - val_binary_accuracy: 0.7838\n",
            "Epoch 363/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0712 - auc_19: 0.9976 - binary_accuracy: 0.9628 - val_loss: 0.7984 - val_auc_19: 0.8427 - val_binary_accuracy: 0.7973\n",
            "Epoch 364/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0750 - auc_19: 0.9951 - binary_accuracy: 0.9831 - val_loss: 0.7714 - val_auc_19: 0.8423 - val_binary_accuracy: 0.7838\n",
            "Epoch 365/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0778 - auc_19: 0.9956 - binary_accuracy: 0.9764 - val_loss: 0.8195 - val_auc_19: 0.8205 - val_binary_accuracy: 0.7838\n",
            "Epoch 366/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0757 - auc_19: 0.9970 - binary_accuracy: 0.9730 - val_loss: 0.7840 - val_auc_19: 0.8308 - val_binary_accuracy: 0.7973\n",
            "Epoch 367/500\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0896 - auc_19: 0.9951 - binary_accuracy: 0.9595 - val_loss: 0.7992 - val_auc_19: 0.8346 - val_binary_accuracy: 0.7703\n",
            "Epoch 368/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0648 - auc_19: 0.9980 - binary_accuracy: 0.9764 - val_loss: 0.7460 - val_auc_19: 0.8380 - val_binary_accuracy: 0.8108\n",
            "Epoch 369/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0892 - auc_19: 0.9950 - binary_accuracy: 0.9561 - val_loss: 0.7712 - val_auc_19: 0.8316 - val_binary_accuracy: 0.7703\n",
            "Epoch 370/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0679 - auc_19: 0.9970 - binary_accuracy: 0.9831 - val_loss: 0.8747 - val_auc_19: 0.8210 - val_binary_accuracy: 0.7838\n",
            "Epoch 371/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0958 - auc_19: 0.9944 - binary_accuracy: 0.9628 - val_loss: 0.8136 - val_auc_19: 0.8197 - val_binary_accuracy: 0.7703\n",
            "Epoch 372/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1199 - auc_19: 0.9907 - binary_accuracy: 0.9257 - val_loss: 0.7577 - val_auc_19: 0.8291 - val_binary_accuracy: 0.7703\n",
            "Epoch 373/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0991 - auc_19: 0.9871 - binary_accuracy: 0.9730 - val_loss: 0.7268 - val_auc_19: 0.8355 - val_binary_accuracy: 0.7973\n",
            "Epoch 374/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0859 - auc_19: 0.9955 - binary_accuracy: 0.9662 - val_loss: 0.7476 - val_auc_19: 0.8240 - val_binary_accuracy: 0.8378\n",
            "Epoch 375/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0750 - auc_19: 0.9964 - binary_accuracy: 0.9696 - val_loss: 0.7398 - val_auc_19: 0.8465 - val_binary_accuracy: 0.8243\n",
            "Epoch 376/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0630 - auc_19: 0.9979 - binary_accuracy: 0.9730 - val_loss: 0.7624 - val_auc_19: 0.8376 - val_binary_accuracy: 0.7703\n",
            "Epoch 377/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0739 - auc_19: 0.9971 - binary_accuracy: 0.9764 - val_loss: 0.7098 - val_auc_19: 0.8564 - val_binary_accuracy: 0.8108\n",
            "Epoch 378/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0852 - auc_19: 0.9914 - binary_accuracy: 0.9730 - val_loss: 0.6827 - val_auc_19: 0.8555 - val_binary_accuracy: 0.8243\n",
            "Epoch 379/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0579 - auc_19: 0.9986 - binary_accuracy: 0.9764 - val_loss: 0.6819 - val_auc_19: 0.8525 - val_binary_accuracy: 0.7973\n",
            "Epoch 380/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0747 - auc_19: 0.9967 - binary_accuracy: 0.9595 - val_loss: 0.6993 - val_auc_19: 0.8495 - val_binary_accuracy: 0.8378\n",
            "Epoch 381/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0692 - auc_19: 0.9971 - binary_accuracy: 0.9730 - val_loss: 0.7200 - val_auc_19: 0.8487 - val_binary_accuracy: 0.8243\n",
            "Epoch 382/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0692 - auc_19: 0.9970 - binary_accuracy: 0.9730 - val_loss: 0.7354 - val_auc_19: 0.8423 - val_binary_accuracy: 0.8243\n",
            "Epoch 383/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0673 - auc_19: 0.9974 - binary_accuracy: 0.9764 - val_loss: 0.8160 - val_auc_19: 0.8129 - val_binary_accuracy: 0.8108\n",
            "Epoch 384/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0662 - auc_19: 0.9970 - binary_accuracy: 0.9730 - val_loss: 0.7744 - val_auc_19: 0.8265 - val_binary_accuracy: 0.7568\n",
            "Epoch 385/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0611 - auc_19: 0.9985 - binary_accuracy: 0.9764 - val_loss: 0.7654 - val_auc_19: 0.8197 - val_binary_accuracy: 0.7568\n",
            "Epoch 386/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0656 - auc_19: 0.9976 - binary_accuracy: 0.9764 - val_loss: 0.7957 - val_auc_19: 0.8444 - val_binary_accuracy: 0.7838\n",
            "Epoch 387/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0541 - auc_19: 0.9997 - binary_accuracy: 0.9831 - val_loss: 0.7635 - val_auc_19: 0.8500 - val_binary_accuracy: 0.8378\n",
            "Epoch 388/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0848 - auc_19: 0.9955 - binary_accuracy: 0.9628 - val_loss: 0.6499 - val_auc_19: 0.8610 - val_binary_accuracy: 0.8378\n",
            "Epoch 389/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0771 - auc_19: 0.9966 - binary_accuracy: 0.9696 - val_loss: 0.6602 - val_auc_19: 0.8593 - val_binary_accuracy: 0.8243\n",
            "Epoch 390/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0924 - auc_19: 0.9917 - binary_accuracy: 0.9696 - val_loss: 0.6652 - val_auc_19: 0.8495 - val_binary_accuracy: 0.8243\n",
            "Epoch 391/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0593 - auc_19: 0.9981 - binary_accuracy: 0.9797 - val_loss: 0.7121 - val_auc_19: 0.8436 - val_binary_accuracy: 0.8243\n",
            "Epoch 392/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0811 - auc_19: 0.9952 - binary_accuracy: 0.9730 - val_loss: 0.7830 - val_auc_19: 0.8397 - val_binary_accuracy: 0.8108\n",
            "Epoch 393/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0666 - auc_19: 0.9976 - binary_accuracy: 0.9764 - val_loss: 0.7925 - val_auc_19: 0.8367 - val_binary_accuracy: 0.7838\n",
            "Epoch 394/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0981 - auc_19: 0.9939 - binary_accuracy: 0.9628 - val_loss: 0.7978 - val_auc_19: 0.8278 - val_binary_accuracy: 0.8243\n",
            "Epoch 395/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0597 - auc_19: 0.9976 - binary_accuracy: 0.9831 - val_loss: 0.7920 - val_auc_19: 0.8389 - val_binary_accuracy: 0.8108\n",
            "Epoch 396/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0782 - auc_19: 0.9955 - binary_accuracy: 0.9764 - val_loss: 0.8042 - val_auc_19: 0.8448 - val_binary_accuracy: 0.8108\n",
            "Epoch 397/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0519 - auc_19: 0.9985 - binary_accuracy: 0.9797 - val_loss: 0.7323 - val_auc_19: 0.8512 - val_binary_accuracy: 0.7973\n",
            "Epoch 398/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0777 - auc_19: 0.9962 - binary_accuracy: 0.9696 - val_loss: 0.7201 - val_auc_19: 0.8457 - val_binary_accuracy: 0.8243\n",
            "Epoch 399/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0754 - auc_19: 0.9969 - binary_accuracy: 0.9628 - val_loss: 0.7912 - val_auc_19: 0.8316 - val_binary_accuracy: 0.7568\n",
            "Epoch 400/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0882 - auc_19: 0.9955 - binary_accuracy: 0.9561 - val_loss: 0.7364 - val_auc_19: 0.8397 - val_binary_accuracy: 0.7838\n",
            "Epoch 401/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0859 - auc_19: 0.9944 - binary_accuracy: 0.9730 - val_loss: 0.7885 - val_auc_19: 0.8359 - val_binary_accuracy: 0.8108\n",
            "Epoch 402/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0771 - auc_19: 0.9960 - binary_accuracy: 0.9764 - val_loss: 0.8398 - val_auc_19: 0.8231 - val_binary_accuracy: 0.7838\n",
            "Epoch 403/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0676 - auc_19: 0.9973 - binary_accuracy: 0.9730 - val_loss: 0.7662 - val_auc_19: 0.8265 - val_binary_accuracy: 0.7568\n",
            "Epoch 404/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0723 - auc_19: 0.9964 - binary_accuracy: 0.9730 - val_loss: 0.7307 - val_auc_19: 0.8564 - val_binary_accuracy: 0.7838\n",
            "Epoch 405/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0702 - auc_19: 0.9976 - binary_accuracy: 0.9696 - val_loss: 0.8039 - val_auc_19: 0.8376 - val_binary_accuracy: 0.7703\n",
            "Epoch 406/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0555 - auc_19: 0.9983 - binary_accuracy: 0.9831 - val_loss: 0.8216 - val_auc_19: 0.8244 - val_binary_accuracy: 0.7568\n",
            "Epoch 407/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0649 - auc_19: 0.9974 - binary_accuracy: 0.9797 - val_loss: 0.8445 - val_auc_19: 0.8201 - val_binary_accuracy: 0.7838\n",
            "Epoch 408/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0828 - auc_19: 0.9954 - binary_accuracy: 0.9595 - val_loss: 0.7536 - val_auc_19: 0.8342 - val_binary_accuracy: 0.7973\n",
            "Epoch 409/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0489 - auc_19: 0.9991 - binary_accuracy: 0.9797 - val_loss: 0.7386 - val_auc_19: 0.8440 - val_binary_accuracy: 0.8108\n",
            "Epoch 410/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0817 - auc_19: 0.9928 - binary_accuracy: 0.9797 - val_loss: 0.7273 - val_auc_19: 0.8389 - val_binary_accuracy: 0.7838\n",
            "Epoch 411/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0756 - auc_19: 0.9958 - binary_accuracy: 0.9696 - val_loss: 0.7086 - val_auc_19: 0.8431 - val_binary_accuracy: 0.7703\n",
            "Epoch 412/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0473 - auc_19: 0.9989 - binary_accuracy: 0.9865 - val_loss: 0.7301 - val_auc_19: 0.8414 - val_binary_accuracy: 0.7703\n",
            "Epoch 413/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0546 - auc_19: 0.9982 - binary_accuracy: 0.9831 - val_loss: 0.7423 - val_auc_19: 0.8299 - val_binary_accuracy: 0.7703\n",
            "Epoch 414/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0562 - auc_19: 0.9979 - binary_accuracy: 0.9764 - val_loss: 0.8155 - val_auc_19: 0.8112 - val_binary_accuracy: 0.7568\n",
            "Epoch 415/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0540 - auc_19: 0.9982 - binary_accuracy: 0.9797 - val_loss: 0.8041 - val_auc_19: 0.8184 - val_binary_accuracy: 0.7432\n",
            "Epoch 416/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0508 - auc_19: 0.9987 - binary_accuracy: 0.9797 - val_loss: 0.7794 - val_auc_19: 0.8325 - val_binary_accuracy: 0.7973\n",
            "Epoch 417/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0485 - auc_19: 0.9980 - binary_accuracy: 0.9865 - val_loss: 0.8121 - val_auc_19: 0.8419 - val_binary_accuracy: 0.8243\n",
            "Epoch 418/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0652 - auc_19: 0.9973 - binary_accuracy: 0.9662 - val_loss: 0.7925 - val_auc_19: 0.8384 - val_binary_accuracy: 0.8108\n",
            "Epoch 419/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0528 - auc_19: 0.9983 - binary_accuracy: 0.9764 - val_loss: 0.8847 - val_auc_19: 0.8137 - val_binary_accuracy: 0.7297\n",
            "Epoch 420/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0891 - auc_19: 0.9949 - binary_accuracy: 0.9662 - val_loss: 0.8757 - val_auc_19: 0.8218 - val_binary_accuracy: 0.7568\n",
            "Epoch 421/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0630 - auc_19: 0.9982 - binary_accuracy: 0.9797 - val_loss: 0.8310 - val_auc_19: 0.8419 - val_binary_accuracy: 0.7973\n",
            "Epoch 422/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0663 - auc_19: 0.9974 - binary_accuracy: 0.9628 - val_loss: 0.7749 - val_auc_19: 0.8342 - val_binary_accuracy: 0.7838\n",
            "Epoch 423/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0479 - auc_19: 0.9987 - binary_accuracy: 0.9899 - val_loss: 0.7585 - val_auc_19: 0.8303 - val_binary_accuracy: 0.7432\n",
            "Epoch 424/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0530 - auc_19: 0.9983 - binary_accuracy: 0.9831 - val_loss: 0.7333 - val_auc_19: 0.8363 - val_binary_accuracy: 0.7703\n",
            "Epoch 425/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0509 - auc_19: 0.9979 - binary_accuracy: 0.9831 - val_loss: 0.7495 - val_auc_19: 0.8436 - val_binary_accuracy: 0.7703\n",
            "Epoch 426/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0485 - auc_19: 0.9990 - binary_accuracy: 0.9730 - val_loss: 0.7863 - val_auc_19: 0.8397 - val_binary_accuracy: 0.7703\n",
            "Epoch 427/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0803 - auc_19: 0.9935 - binary_accuracy: 0.9696 - val_loss: 0.7948 - val_auc_19: 0.8427 - val_binary_accuracy: 0.7838\n",
            "Epoch 428/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0676 - auc_19: 0.9972 - binary_accuracy: 0.9730 - val_loss: 0.8169 - val_auc_19: 0.8329 - val_binary_accuracy: 0.7703\n",
            "Epoch 429/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0498 - auc_19: 0.9988 - binary_accuracy: 0.9797 - val_loss: 0.8465 - val_auc_19: 0.8205 - val_binary_accuracy: 0.7568\n",
            "Epoch 430/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0630 - auc_19: 0.9954 - binary_accuracy: 0.9831 - val_loss: 0.8900 - val_auc_19: 0.8082 - val_binary_accuracy: 0.7432\n",
            "Epoch 431/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0663 - auc_19: 0.9967 - binary_accuracy: 0.9764 - val_loss: 0.9276 - val_auc_19: 0.8261 - val_binary_accuracy: 0.7432\n",
            "Epoch 432/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0485 - auc_19: 0.9989 - binary_accuracy: 0.9797 - val_loss: 0.9899 - val_auc_19: 0.8073 - val_binary_accuracy: 0.7568\n",
            "Epoch 433/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0671 - auc_19: 0.9970 - binary_accuracy: 0.9797 - val_loss: 0.9640 - val_auc_19: 0.8103 - val_binary_accuracy: 0.7838\n",
            "Epoch 434/500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0720 - auc_19: 0.9960 - binary_accuracy: 0.9764 - val_loss: 0.8690 - val_auc_19: 0.8265 - val_binary_accuracy: 0.7973\n",
            "Epoch 435/500\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0653 - auc_19: 0.9988 - binary_accuracy: 0.9696 - val_loss: 0.9106 - val_auc_19: 0.8180 - val_binary_accuracy: 0.7432\n",
            "Epoch 436/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0800 - auc_19: 0.9947 - binary_accuracy: 0.9764 - val_loss: 0.9340 - val_auc_19: 0.8180 - val_binary_accuracy: 0.7432\n",
            "Epoch 437/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0689 - auc_19: 0.9974 - binary_accuracy: 0.9696 - val_loss: 0.8908 - val_auc_19: 0.8376 - val_binary_accuracy: 0.7838\n",
            "Epoch 438/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0794 - auc_19: 0.9953 - binary_accuracy: 0.9730 - val_loss: 0.8952 - val_auc_19: 0.8248 - val_binary_accuracy: 0.7297\n",
            "Epoch 439/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0615 - auc_19: 0.9981 - binary_accuracy: 0.9764 - val_loss: 0.9003 - val_auc_19: 0.8154 - val_binary_accuracy: 0.7432\n",
            "Epoch 440/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0553 - auc_19: 0.9978 - binary_accuracy: 0.9899 - val_loss: 0.8990 - val_auc_19: 0.8295 - val_binary_accuracy: 0.7703\n",
            "Epoch 441/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.1050 - auc_19: 0.9921 - binary_accuracy: 0.9561 - val_loss: 0.8862 - val_auc_19: 0.8205 - val_binary_accuracy: 0.7568\n",
            "Epoch 442/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0563 - auc_19: 0.9976 - binary_accuracy: 0.9865 - val_loss: 0.8704 - val_auc_19: 0.8240 - val_binary_accuracy: 0.7703\n",
            "Epoch 443/500\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0388 - auc_19: 0.9995 - binary_accuracy: 0.9831 - val_loss: 0.8144 - val_auc_19: 0.8384 - val_binary_accuracy: 0.7838\n",
            "Epoch 444/500\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0772 - auc_19: 0.9955 - binary_accuracy: 0.9797 - val_loss: 0.7560 - val_auc_19: 0.8538 - val_binary_accuracy: 0.7973\n",
            "Epoch 445/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0461 - auc_19: 0.9989 - binary_accuracy: 0.9764 - val_loss: 0.7680 - val_auc_19: 0.8487 - val_binary_accuracy: 0.7838\n",
            "Epoch 446/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0832 - auc_19: 0.9914 - binary_accuracy: 0.9730 - val_loss: 0.8342 - val_auc_19: 0.8333 - val_binary_accuracy: 0.7568\n",
            "Epoch 447/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0811 - auc_19: 0.9946 - binary_accuracy: 0.9696 - val_loss: 0.8727 - val_auc_19: 0.8312 - val_binary_accuracy: 0.7838\n",
            "Epoch 448/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0394 - auc_19: 0.9985 - binary_accuracy: 0.9899 - val_loss: 0.9845 - val_auc_19: 0.8159 - val_binary_accuracy: 0.7973\n",
            "Epoch 449/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0552 - auc_19: 0.9978 - binary_accuracy: 0.9865 - val_loss: 0.9664 - val_auc_19: 0.8133 - val_binary_accuracy: 0.7703\n",
            "Epoch 450/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0754 - auc_19: 0.9913 - binary_accuracy: 0.9730 - val_loss: 0.9047 - val_auc_19: 0.8282 - val_binary_accuracy: 0.8108\n",
            "Epoch 451/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0472 - auc_19: 0.9992 - binary_accuracy: 0.9831 - val_loss: 0.8571 - val_auc_19: 0.8308 - val_binary_accuracy: 0.7703\n",
            "Epoch 452/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0628 - auc_19: 0.9974 - binary_accuracy: 0.9797 - val_loss: 0.8809 - val_auc_19: 0.8227 - val_binary_accuracy: 0.7568\n",
            "Epoch 453/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0725 - auc_19: 0.9916 - binary_accuracy: 0.9797 - val_loss: 0.8837 - val_auc_19: 0.8227 - val_binary_accuracy: 0.7432\n",
            "Epoch 454/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0419 - auc_19: 0.9989 - binary_accuracy: 0.9899 - val_loss: 0.8806 - val_auc_19: 0.8197 - val_binary_accuracy: 0.7973\n",
            "Epoch 455/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0618 - auc_19: 0.9931 - binary_accuracy: 0.9865 - val_loss: 0.9490 - val_auc_19: 0.7967 - val_binary_accuracy: 0.7568\n",
            "Epoch 456/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0401 - auc_19: 0.9990 - binary_accuracy: 0.9865 - val_loss: 0.8645 - val_auc_19: 0.8291 - val_binary_accuracy: 0.7703\n",
            "Epoch 457/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0596 - auc_19: 0.9971 - binary_accuracy: 0.9865 - val_loss: 0.8013 - val_auc_19: 0.8282 - val_binary_accuracy: 0.7973\n",
            "Epoch 458/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0706 - auc_19: 0.9966 - binary_accuracy: 0.9730 - val_loss: 0.7954 - val_auc_19: 0.8235 - val_binary_accuracy: 0.7432\n",
            "Epoch 459/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0713 - auc_19: 0.9963 - binary_accuracy: 0.9730 - val_loss: 0.8319 - val_auc_19: 0.8197 - val_binary_accuracy: 0.7973\n",
            "Epoch 460/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0668 - auc_19: 0.9978 - binary_accuracy: 0.9730 - val_loss: 0.8908 - val_auc_19: 0.8039 - val_binary_accuracy: 0.8108\n",
            "Epoch 461/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0641 - auc_19: 0.9980 - binary_accuracy: 0.9764 - val_loss: 0.9321 - val_auc_19: 0.8069 - val_binary_accuracy: 0.7838\n",
            "Epoch 462/500\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0949 - auc_19: 0.9897 - binary_accuracy: 0.9764 - val_loss: 0.9715 - val_auc_19: 0.7877 - val_binary_accuracy: 0.7703\n",
            "Epoch 463/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0892 - auc_19: 0.9934 - binary_accuracy: 0.9730 - val_loss: 0.8903 - val_auc_19: 0.8086 - val_binary_accuracy: 0.7838\n",
            "Epoch 464/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0550 - auc_19: 0.9971 - binary_accuracy: 0.9865 - val_loss: 0.8585 - val_auc_19: 0.8082 - val_binary_accuracy: 0.8108\n",
            "Epoch 465/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0757 - auc_19: 0.9951 - binary_accuracy: 0.9797 - val_loss: 0.8438 - val_auc_19: 0.8103 - val_binary_accuracy: 0.7973\n",
            "Epoch 466/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0435 - auc_19: 0.9993 - binary_accuracy: 0.9865 - val_loss: 0.8554 - val_auc_19: 0.8184 - val_binary_accuracy: 0.7838\n",
            "Epoch 467/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0422 - auc_19: 0.9995 - binary_accuracy: 0.9899 - val_loss: 0.9712 - val_auc_19: 0.7890 - val_binary_accuracy: 0.7162\n",
            "Epoch 468/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0752 - auc_19: 0.9946 - binary_accuracy: 0.9730 - val_loss: 0.9624 - val_auc_19: 0.8005 - val_binary_accuracy: 0.7568\n",
            "Epoch 469/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0375 - auc_19: 0.9990 - binary_accuracy: 0.9899 - val_loss: 0.9685 - val_auc_19: 0.7762 - val_binary_accuracy: 0.7838\n",
            "Epoch 470/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0551 - auc_19: 0.9983 - binary_accuracy: 0.9865 - val_loss: 0.9630 - val_auc_19: 0.8014 - val_binary_accuracy: 0.7432\n",
            "Epoch 471/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0558 - auc_19: 0.9979 - binary_accuracy: 0.9764 - val_loss: 1.0203 - val_auc_19: 0.7835 - val_binary_accuracy: 0.7297\n",
            "Epoch 472/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0676 - auc_19: 0.9944 - binary_accuracy: 0.9831 - val_loss: 1.0009 - val_auc_19: 0.7864 - val_binary_accuracy: 0.7568\n",
            "Epoch 473/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0687 - auc_19: 0.9969 - binary_accuracy: 0.9797 - val_loss: 0.9589 - val_auc_19: 0.8107 - val_binary_accuracy: 0.7838\n",
            "Epoch 474/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0511 - auc_19: 0.9977 - binary_accuracy: 0.9831 - val_loss: 0.9791 - val_auc_19: 0.8116 - val_binary_accuracy: 0.7432\n",
            "Epoch 475/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0386 - auc_19: 0.9995 - binary_accuracy: 0.9899 - val_loss: 1.0093 - val_auc_19: 0.8112 - val_binary_accuracy: 0.7703\n",
            "Epoch 476/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0310 - auc_19: 0.9999 - binary_accuracy: 0.9899 - val_loss: 1.0065 - val_auc_19: 0.8184 - val_binary_accuracy: 0.7973\n",
            "Epoch 477/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0588 - auc_19: 0.9973 - binary_accuracy: 0.9831 - val_loss: 0.9634 - val_auc_19: 0.8001 - val_binary_accuracy: 0.7432\n",
            "Epoch 478/500\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0446 - auc_19: 0.9990 - binary_accuracy: 0.9865 - val_loss: 0.8928 - val_auc_19: 0.8188 - val_binary_accuracy: 0.7568\n",
            "Epoch 479/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0568 - auc_19: 0.9986 - binary_accuracy: 0.9730 - val_loss: 0.8676 - val_auc_19: 0.8333 - val_binary_accuracy: 0.8108\n",
            "Epoch 480/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0686 - auc_19: 0.9966 - binary_accuracy: 0.9797 - val_loss: 0.9840 - val_auc_19: 0.8154 - val_binary_accuracy: 0.7162\n",
            "Epoch 481/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0430 - auc_19: 0.9996 - binary_accuracy: 0.9797 - val_loss: 0.9468 - val_auc_19: 0.8099 - val_binary_accuracy: 0.7703\n",
            "Epoch 482/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0545 - auc_19: 0.9989 - binary_accuracy: 0.9730 - val_loss: 0.9476 - val_auc_19: 0.8116 - val_binary_accuracy: 0.7568\n",
            "Epoch 483/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0533 - auc_19: 0.9983 - binary_accuracy: 0.9730 - val_loss: 0.9582 - val_auc_19: 0.8107 - val_binary_accuracy: 0.7432\n",
            "Epoch 484/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0446 - auc_19: 0.9989 - binary_accuracy: 0.9831 - val_loss: 1.0482 - val_auc_19: 0.7907 - val_binary_accuracy: 0.7432\n",
            "Epoch 485/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0599 - auc_19: 0.9932 - binary_accuracy: 0.9865 - val_loss: 0.9839 - val_auc_19: 0.8035 - val_binary_accuracy: 0.7703\n",
            "Epoch 486/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0483 - auc_19: 0.9987 - binary_accuracy: 0.9899 - val_loss: 0.8647 - val_auc_19: 0.7941 - val_binary_accuracy: 0.7432\n",
            "Epoch 487/500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0562 - auc_19: 0.9976 - binary_accuracy: 0.9764 - val_loss: 0.8777 - val_auc_19: 0.7894 - val_binary_accuracy: 0.7162\n",
            "Epoch 488/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0512 - auc_19: 0.9984 - binary_accuracy: 0.9865 - val_loss: 0.9124 - val_auc_19: 0.7826 - val_binary_accuracy: 0.7162\n",
            "Epoch 489/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0554 - auc_19: 0.9973 - binary_accuracy: 0.9831 - val_loss: 0.9073 - val_auc_19: 0.8022 - val_binary_accuracy: 0.7568\n",
            "Epoch 490/500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0464 - auc_19: 0.9987 - binary_accuracy: 0.9865 - val_loss: 0.9169 - val_auc_19: 0.8073 - val_binary_accuracy: 0.7568\n",
            "Epoch 491/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0462 - auc_19: 0.9987 - binary_accuracy: 0.9831 - val_loss: 0.9593 - val_auc_19: 0.8090 - val_binary_accuracy: 0.7432\n",
            "Epoch 492/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0314 - auc_19: 0.9994 - binary_accuracy: 0.9966 - val_loss: 0.9960 - val_auc_19: 0.8112 - val_binary_accuracy: 0.7703\n",
            "Epoch 493/500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.0782 - auc_19: 0.9953 - binary_accuracy: 0.9764 - val_loss: 0.9188 - val_auc_19: 0.8048 - val_binary_accuracy: 0.7838\n",
            "Epoch 494/500\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0384 - auc_19: 0.9992 - binary_accuracy: 0.9899 - val_loss: 0.9358 - val_auc_19: 0.8086 - val_binary_accuracy: 0.7703\n",
            "Epoch 495/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0413 - auc_19: 0.9991 - binary_accuracy: 0.9865 - val_loss: 0.9669 - val_auc_19: 0.7992 - val_binary_accuracy: 0.7297\n",
            "Epoch 496/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0344 - auc_19: 0.9997 - binary_accuracy: 0.9932 - val_loss: 0.9723 - val_auc_19: 0.8009 - val_binary_accuracy: 0.7432\n",
            "Epoch 497/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0564 - auc_19: 0.9978 - binary_accuracy: 0.9797 - val_loss: 1.0182 - val_auc_19: 0.7860 - val_binary_accuracy: 0.7973\n",
            "Epoch 498/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0790 - auc_19: 0.9959 - binary_accuracy: 0.9730 - val_loss: 0.9897 - val_auc_19: 0.8065 - val_binary_accuracy: 0.7838\n",
            "Epoch 499/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0729 - auc_19: 0.9962 - binary_accuracy: 0.9730 - val_loss: 0.9388 - val_auc_19: 0.8039 - val_binary_accuracy: 0.7568\n",
            "Epoch 500/500\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0597 - auc_19: 0.9979 - binary_accuracy: 0.9730 - val_loss: 1.0035 - val_auc_19: 0.7864 - val_binary_accuracy: 0.7297\n",
            "3/3 [==============================] - 1s 6ms/step - loss: 0.4585 - auc_20: 0.8397 - binary_accuracy: 0.8378\n",
            "3/3 [==============================] - 1s 6ms/step - loss: 0.4782 - auc_21: 0.8282 - binary_accuracy: 0.7973\n",
            "3/3 [==============================] - 1s 10ms/step - loss: 0.4671 - auc_22: 0.8431 - binary_accuracy: 0.8243\n",
            "WARNING:tensorflow:5 out of the last 1510 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd88f1a8050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 1s 8ms/step - loss: 0.4572 - auc_23: 0.8589 - binary_accuracy: 0.8108\n"
          ]
        }
      ],
      "source": [
        "# Conduct the gridsearch over hyperparameters.\n",
        "results_8 = {}\n",
        "\n",
        "for params_i in params_grid:\n",
        "\n",
        "  # Create a LSTM model with the specific parameter setting params_i\n",
        "  time_series_lstm = create_model_lstm_mooc_binary(num_features, 1, params_i)\n",
        "\n",
        "  save_model_name = params_i['best_model_weights'] + \"_\" + str(params_i['recurrent_units']) + \"_\" + str(n)\n",
        "\n",
        "  # Save the best version of the model through the training epochs\n",
        "  ckp_callback = tf.keras.callbacks.ModelCheckpoint(save_model_name, \n",
        "                                                    save_best_only=True, save_weights_only=True)\n",
        "\n",
        "  # Fit the model on the training data with the appropriate parameters  \n",
        "  time_series_lstm.fit(df_x_binary_train_val_8, \n",
        "                        df_y_binary_train_val_8, \n",
        "                        epochs=params_i['epochs'],\n",
        "                        validation_data=(df_x_binary_val_8, df_y_binary_val_8),\n",
        "                        callbacks=[ckp_callback], \n",
        "                        verbose=params_i['verbose'])\n",
        "#Once each model has been fully trained, evaluate their best version on the validation set to choose the best parameter\n",
        "for params_i in params_grid:\n",
        "  time_series_lstm = create_model_lstm_mooc_binary(num_features, 1, params_i)\n",
        "  save_model_name = params_i['best_model_weights'] + \"_\" + str(params_i['recurrent_units']) + \"_\" + str(n)\n",
        "  time_series_lstm.load_weights(save_model_name)\n",
        "  # Evaluate the model performance\n",
        "  results_8[params_i['recurrent_units']] = time_series_lstm.evaluate(df_x_binary_val_8, \n",
        "                                                                    df_y_binary_val_8,\n",
        "                                                                    verbose=params_i['verbose'], \n",
        "                                                                    return_dict=True)"
      ],
      "id": "-HMzpJLZZpKo"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um_bTJ-RZpKo",
        "outputId": "4501d5b5-e161-47b0-e3f9-b730ade6da2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Sort candidate parameters according to their accuracy\n",
        "results_sorted = sorted(results_8.items(), key=lambda x: x[1]['binary_accuracy'], reverse=True)\n",
        "\n",
        "# Obtain the best parameters\n",
        "best_params_8 = results_sorted[0][0]\n",
        "best_params_8"
      ],
      "id": "Um_bTJ-RZpKo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e81Ws-EK69cL"
      },
      "source": [
        "*Your discussion about your model training goes here*"
      ],
      "id": "e81Ws-EK69cL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3c9a655-cec9-4c57-aec7-7a982f57a3af"
      },
      "source": [
        "## Task 3: Model Evaluation\n",
        "In this task, you will use metrics to evaluate your model."
      ],
      "id": "b3c9a655-cec9-4c57-aec7-7a982f57a3af"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5fPYG3Er8n7"
      },
      "source": [
        "##Evaluating the LSTMs models:\n",
        "After training the models and selecting the best hyperparameters, we evaluate the models performances on their respective test set. Note that as the data is sorted, and the splits are done deterministically with a seed, the train-validation-test sets always have the same samples for a given number of week, and so we can compare the models with the decision trees directly."
      ],
      "id": "s5fPYG3Er8n7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLA6J63XsBA6"
      },
      "source": [
        "###Model trained on Week 1:"
      ],
      "id": "jLA6J63XsBA6"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhcsGVJWLNW2",
        "outputId": "617d4c4d-a11a-45f1-a58d-b324ba131d66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced accuracy:  0.5177644947134484\n",
            "AUC:  0.5525808784650261\n",
            "Accuracy:  0.6040533860603065\n",
            "Precision:  0.6438356164383562\n",
            "Recall:  0.057177615571776155\n"
          ]
        }
      ],
      "source": [
        "# Load the best version of the the trained model and evaluate its performance on the test_set.\n",
        "params['recurrent_units'] = best_params_1\n",
        "time_series_lstm = create_model_lstm_mooc_binary(num_features, 1, params)\n",
        "time_series_lstm.load_weights(params['best_model_weights'] + \"_\" + str(best_params_1) + \"_1\")\n",
        "\n",
        "predictions = time_series_lstm.predict(df_x_binary_test_1)\n",
        "bac = balanced_accuracy_score(df_y_binary_test_1, predictions>0.5)\n",
        "auc = roc_auc_score(df_y_binary_test_1,predictions)\n",
        "ac = accuracy_score(df_y_binary_test_1, predictions>0.5)\n",
        "pr = precision_score(df_y_binary_test_1, predictions>0.5)\n",
        "re = recall_score(df_y_binary_test_1, predictions>0.5)\n",
        "print(\"Balanced accuracy: \", bac)\n",
        "print(\"AUC: \", auc)\n",
        "print(\"Accuracy: \", ac)\n",
        "print(\"Precision: \", pr)\n",
        "print(\"Recall: \", re)"
      ],
      "id": "KhcsGVJWLNW2"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOr6IHRkQnqj",
        "outputId": "6fc0467f-16a1-4337-d2b2-907baf93607c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean predictions: 0.4081825613975525\n",
            "Std deviation of  predictions: 0.040732547640800476\n"
          ]
        }
      ],
      "source": [
        "print(\"Mean predictions: {}\".format(predictions.mean()))\n",
        "print(\"Std deviation of  predictions: {}\".format(predictions.std()))"
      ],
      "id": "kOr6IHRkQnqj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0NOVHqgOBI7"
      },
      "source": [
        "###Model trained on Weeks 1 to 4"
      ],
      "id": "M0NOVHqgOBI7"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfUvy-PUODBS",
        "outputId": "c31c6ab5-1f1c-4070-a55c-e018e879019f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced accuracy:  0.5146354112643916\n",
            "AUC:  0.5955606264910278\n",
            "Accuracy:  0.6523605150214592\n",
            "Precision:  0.41025641025641024\n",
            "Recall:  0.1032258064516129\n"
          ]
        }
      ],
      "source": [
        "# Load the best version of the the trained model and evaluate its performance on the test_set.\n",
        "params['recurrent_units'] = best_params_4\n",
        "time_series_lstm = create_model_lstm_mooc_binary(num_features, 1, params)\n",
        "time_series_lstm.load_weights(params['best_model_weights'] + \"_\" + str(best_params_4) + \"_4\")\n",
        "\n",
        "predictions = time_series_lstm.predict(df_x_binary_test_4)\n",
        "bac = balanced_accuracy_score(df_y_binary_test_4, predictions>0.5)\n",
        "auc = roc_auc_score(df_y_binary_test_4,predictions)\n",
        "ac = accuracy_score(df_y_binary_test_4, predictions>0.5)\n",
        "pr = precision_score(df_y_binary_test_4, predictions>0.5)\n",
        "re = recall_score(df_y_binary_test_4, predictions>0.5)\n",
        "\n",
        "print(\"Balanced accuracy: \", bac)\n",
        "print(\"AUC: \", auc)\n",
        "print(\"Accuracy: \", ac)\n",
        "print(\"Precision: \", pr)\n",
        "print(\"Recall: \", re)"
      ],
      "id": "VfUvy-PUODBS"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99cd2c8e-efc5-4ff6-aa54-ec1a37a16ac3",
        "id": "teYFIwOZaRFC"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean predictions: 0.32320526242256165\n",
            "Std deviation of  predictions: 0.131057471036911\n"
          ]
        }
      ],
      "source": [
        "print(\"Mean predictions: {}\".format(predictions.mean()))\n",
        "print(\"Std deviation of  predictions: {}\".format(predictions.std()))"
      ],
      "id": "teYFIwOZaRFC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqqGNS5OZrhF"
      },
      "source": [
        "###Model trained on Weeks 1 to 8"
      ],
      "id": "LqqGNS5OZrhF"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIGn3jywZpKo",
        "outputId": "f7fb58c5-7730-49d4-8253-395b116872c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced accuracy:  0.5942887931034483\n",
            "AUC:  0.7516163793103449\n",
            "Accuracy:  0.6881720430107527\n",
            "Precision:  0.5\n",
            "Recall:  0.3448275862068966\n"
          ]
        }
      ],
      "source": [
        "# Load the best version of the the trained model and evaluate its performance on the test_set.\n",
        "params['recurrent_units'] = best_params_8\n",
        "time_series_lstm = create_model_lstm_mooc_binary(num_features, 1, params)\n",
        "time_series_lstm.load_weights(params['best_model_weights'] + \"_\" + str(best_params_8) + \"_8\")\n",
        "\n",
        "predictions = time_series_lstm.predict(df_x_binary_test_8)\n",
        "bac = balanced_accuracy_score(df_y_binary_test_8, predictions>0.5)\n",
        "auc = roc_auc_score(df_y_binary_test_8,predictions)\n",
        "ac = accuracy_score(df_y_binary_test_8, predictions>0.5)\n",
        "pr = precision_score(df_y_binary_test_8, predictions>0.5)\n",
        "re = recall_score(df_y_binary_test_8, predictions>0.5)\n",
        "\n",
        "print(\"Balanced accuracy: \", bac)\n",
        "print(\"AUC: \", auc)\n",
        "print(\"Accuracy: \", ac)\n",
        "print(\"Precision: \", pr)\n",
        "print(\"Recall: \", re)"
      ],
      "id": "RIGn3jywZpKo"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "053a7ad8-d57a-4e82-db70-9e4a46c56f41",
        "id": "TMWK6qdDaRj0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean predictions: 0.28622785210609436\n",
            "Std deviation of  predictions: 0.22790734469890594\n"
          ]
        }
      ],
      "source": [
        "print(\"Mean predictions: {}\".format(predictions.mean()))\n",
        "print(\"Std deviation of  predictions: {}\".format(predictions.std()))"
      ],
      "id": "TMWK6qdDaRj0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBB3zKD_69cL"
      },
      "source": [
        "###LSTM Models Analysis:\n",
        "Overall, the models didn't perform very well. \n",
        "\n",
        "On week 1, it is barely better than a random model on almost all metrics. It clearly struggles to make confident predictions, as it has a mean prediction very close to the mean data with a low standard deviation. Moreover, the slightly higher precision and accuracy is likely only due to the class imbalance of the dataset. \n",
        "\n",
        "On week 1 to 4, it is slightly better, with better AUC, accuracy and recall, at the cost of precision. "
      ],
      "id": "DBB3zKD_69cL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1FNQ9N61lOOP"
      },
      "outputs": [],
      "source": [
        " #!zip -r weights.zip weights/ "
      ],
      "id": "1FNQ9N61lOOP"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "m4_lernnavi_sciper.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}